<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: open data | Mountain Doodles]]></title>
  <link href="http://doodles.mountainmath.ca/blog/categories/open-data/feed.atom" rel="self"/>
  <link href="http://doodles.mountainmath.ca/"/>
  <updated>2015-12-14T21:53:13-08:00</updated>
  <id>http://doodles.mountainmath.ca/</id>
  <author>
    <name><![CDATA[MountainMath]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Census Drilldown]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2015/10/24/census-drilldown/"/>
    <updated>2015-10-24T20:45:16-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2015/10/24/census-drilldown</id>
    <content type="html"><![CDATA[<h4>Next steps in CensusMapper</h4>

<p>The <a href="http://censusmapper.ca">Census Mapper Project</a> is moving along slowly, public beta unearthed some bugs and we gathered
feedback (thanks to everyone reporting back!). There are still a couple of steps that need to be taken care of before
we can unleash the full map making power to all users. We feel that the complexity of census data requires more guidance
than the current map making system is providing. Anyone who does not mind getting there hands dirty and having to look
up census variable definitions by themselves when making maps is welcome to contact us and we will hook you up with a
beta mapmaking account.</p>

<p>In the meantime we added one important feature to the CensusMapper.</p>

<h5>Content Drilldown</h5>

<p>CensusMapper is a great way to explore single census variables (or a single function built out of census variables)
across many geographic regions and aggregation levels. But sometimes we would like to do the opposite: Drill down into
a specific census region and explore other census variables. We have now added an easy way to do this. To access it
simply select the &ldquo;more&rdquo; button in the basic popup when you select a census region. This brings up the <em>census wheel</em>,
which is our way to navigate through census data.
<img src="/images/wheel.png" alt="Census Wheel" /></p>

<p>Try it out right away on <a href="http://censusmapper.ca">CensusMapper</a> or read on for details on how this works.</p>

<!-- more -->


<p>There are almost 4,000 census variables available, right now we do not offer to split up by gender, which reduces the
available variables to 1,429. To further simplify things we throw out all variables with zero values for the give
geographic area, still leaving a
sizeable number of variables to browse through.
<img src="http://doodles.mountainmath.ca/images/mother_tounge.png" alt="Mother Tounge" style="max-width:400px;margin-right:15px;margin-top:10px;" align="left"/>
Each arc in the census wheel represents a variable, or a category of
variables. Selecting an arc will zoom into that arc and turn it into the &ldquo;center&rdquo; of the wheel, collapsing all other
components. That&rsquo;s the content <em>drilldown</em> process. Once it makes sense to display data as proportions, we switch to the
<em>proportional view</em> which shows the data as hierarchical pie chart.</p>

<p>This gives a visual representation of the proportions of each of the variables. Hovering (or touching) an arc will
display more detailed information, selecting one will drill down further. To reverse that process either select the
center or us the <em>content breadcrumbs</em> at the top that were created during the drilldown process.</p>

<h5>Data Problems</h5>

<p>Census data is messy. Now that all census data for each region is generally accessible in CensusMapper we need to
explain some of the inherent data problems.</p>

<h6>Rounding</h6>

<p>Census Canada will <a href="http://www12.statcan.gc.ca/census-recensement/2011/dp-pd/prof/help-aide/N2.cfm?Lang=E">round</a>
(almost) all data to preserve anonymity and don&rsquo;t create false impressions of accuracy that
the data does not achieve. Data is generally reported in increments of 5, rounding includes randomness to preserve
anonymity. The value of the measured value
is <a href="https://www12.statcan.gc.ca/census-recensement/2011/ref/DQ-QD/conf-eng.cfm">within 4</a> of the reported one. And
remember that even the measured variable is only an estimate of the actual value of the variable.
Rounding may lead to situations where, for example, the sum of all people listed
by age bracket will not add up to the total number of people. Generally, this difference will be small and we ignore it
in our visualization.</p>

<h6>Omitted Data</h6>

<p>Census Canada will at times not report data. This could be due to very low return rates or other problems that make data
so unreliable that it is better not reported at all. Or it could be that releasing the information could compromize
the anonymity of the census data for some people in that area. The latter can take
the form of Census Canada not reporting any data for the region, or Census Canada zeroing out specific variables that
&ldquo;are too low to be reported&rdquo;.
<img src="http://doodles.mountainmath.ca/images/unaccounted.png" alt="Unaccounted" style="max-width:400px;margin-left:15px;margin-top:10px;" align="right"/>
We have not been able to find clear guidelines how the &ldquo;zeroing&rdquo; works, but often this will leave
detectable traces in the data. Looking at the example in the image, looking at &ldquo;Mode of Transport&rdquo; to work only
&ldquo;Driving&rdquo; has non-zero values, the
other options &ldquo;Passenger&rdquo;, &ldquo;Transit&rdquo;, &ldquo;Bike&rdquo;, &ldquo;Walk&rdquo; and &ldquo;Other&rdquo; are all zero. There were 160 people getting to work,
115 are listed as &ldquo;Driver&rdquo;, leaving 45 unaccounted for. This is outside of the range that could be explained by the
rounding of variables. We alert the user by adding in
a grey area for the missing 45. This also ensures that the visual representation remains accurate.</p>

<h6>Multiple Responses</h6>

<p>Some census questions allow for multiple responses. For exaple &ldquo;Language Spoken Most Often At Home&rdquo;. In this particular
case the census variable breaks out single responses and multiple responses and is very transparent to the user. In
other cases, for example &ldquo;Ethnicity&rdquo;, single and multiple responses are not reported separately but responses are all
added up. This leads to the sum of lower level variables being higher than the base variable. We alert the user to this
by overlaying small white dots on the base variable.
<img src="http://doodles.mountainmath.ca/images/multiple_responses.png" alt="Multiple Responses" style="max-width:400px;margin-right:15px;margin-top:10px;" align="left"/>
In this particular case the total for for &ldquo;Ethnic Origin&rdquo; was 12,140 people. But there were 1,430 more responses at the
next level, so up to 1,430 people had given multiple responses to this question listing more than one of the aggregate
(mostly continent level) origins, some possibly listing more than two. The same patter repeats at different ethnic
origin aggregation
levels, for example 2,565 people claimed at least one of the &ldquo;British Island origins&rdquo;, but many listed more than one
resulting in the sum of the individual regions with the British Islands exceeding the British Island count by 1,445.
Again, we alert the user by overlaying dots over the &ldquo;British Island origins&rdquo; arc. Hovering over the arg will display
the exact numbers of the &ldquo;overcounting&rdquo; due to multiple responses.</p>

<p>In these cases where mulitple repsonses are not broken out the dots will aler the user that the proportional
representation in the hierarchical pie chart does not represent proportions out of a total given by the value of the
variable at the centre (or lower level), but as a proportion of all responses which exceeds the value of the
lower level variable.</p>

<h6>Basic Census</h6>

<p>The Basic Census is generally speaking quite reliable, every single person is required to fill it
out and return rates are generally above 95%. Serious problems will only occur if response rates are very low. We alert
the user by shading geographic regions is this has been the case.</p>

<h6>NHS</h6>

<p>The National Household Survey is quite different in nature, it was only
sent out to a smaller portion (~30%) of society and return rates were much lower (~69%). Even with 100% return rates
there are likely to be geographic regions where the results severely misrepresent reality in that region due to sampling
bias. For each region that bias is small, but the probability for bias grows as the number of people in the geographic
region declines. So this is mostly a problem for Dissemination Areas. But even there, the probability of severe sampling
bias in each region is small, but there are many regions and the probability that some of these regions suffer from
sever sampling bias is quite large.</p>

<p>On top of this basic statistical sampling bias, we also have self selection bias due to some deomgraphics being more
likely to return the survey than others. This bias is a product of the decision of scrapping the madatory
&lsquo;long form census&rsquo; and replacing it with the voluntary NHS. The return rates can give some indication of the
likelyhood of self-selection
bias, we shade regions with a non-return rate lower than 50%, the cutoff Census Canada set for reliability of the NHS.
It is especially problematic when trying to detect change in variables (for example poverty) from one census to another
as the differences in the variable over time are often small and similar in magnitude to possible self-selection bias.</p>

<p>The 50% cutoff we highlight in CensusMapper is just a guideline, the exact return rates are displayed on hover or when
selecting regions and should always to be taken into
account when interpreting results,
especially at the Dissemination Area level.</p>

<p>If all this information did not turn you off, head over to <a href="http://censusmapper.ca">CensusMapper</a> and drill down into
some geographic areas.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Census Mapper]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2015/09/28/census-mapper/"/>
    <updated>2015-09-28T09:23:41-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2015/09/28/census-mapper</id>
    <content type="html"><![CDATA[<h5>We are excited to announce CensusMapper public beta launch!</h5>

<p>The project on mapping census data for Canada is entering the next stage. We are now mapping 3875 different
variables from the 2011 census, or any combination of them, across 67215 geographic regions covering all of Canada.</p>

<p>We are opening up the <a href="http://censusmapper.ca">Census Mapper</a> to a limited public beta. Limited means that anyone
can view maps created in CensusMapper, but we are only opening up the map creation tools to selected beta users.</p>

<p>Be aware that the web app makes use of modern web technology and renders large amount of data. It will only work on
modern browsers, best viewed in Chrome or Safari. Firefox works ok, Internet Explorer might grind to a halt and should be avoided.</p>

<p><a href="http://censusmapper.ca"><img src="/images/map-tools.jpg" alt="CenusMap Mapmaker" /></a></p>

<p>We are a little restrictive on creating maps right now for the simple reason that census data is somewhat tricky to
understand and at this point we don&rsquo;t have a comprehensive guide explaining all the variables and warning against many
of the pitfalls. We are planning to slowly integrate this and open up the map creation tools to the general public.</p>

<h3>Why CensusMapper?</h3>

<!-- more -->


<p>Census Canada data is extremely rich and useful in many cirumstances, but it is not being widely used. There are many
reasons for this, the somewhat unmanageable amount of data being one of them, the difficulty of accessing and standardizing
the in principle freely available datasets is another.</p>

<p>Census data is inherently geographic in nature, working with the data without proper visualization tools can be challenging
too. And even for people that have good access to the data and that are well-versed in mapping geographic data, it can
still take quite a bit of time to generate maps visualizing the data. CensusMapper greatly speeds up this process by
allowing straightforward mapping of any function derived from census variables through all geographic aggregation levels
Canada wide.</p>

<h3>Storytelling</h3>

<p>Census mapper does more than just mapping census data. It is designed as a storytelling tool. Few maps are so crisp and
clear that they are self-explanatory. A map of population density might fall into that category. But most census variables
are sufficiently complex that maps derived from them warrant narration. We think of CensusMapper as a storytelling tool
that allows &lsquo;readers&rsquo; of the map to interact with it, zoom in, zoom out, pan around, and jump to other maps linked in the
story provided by the mapmaker.</p>

<h3>Directions</h3>

<p>There are many ways to expand on this. On the map creation side we can offer more diverse coloring tools, allowing user
input and user defined map locations to be used in the mapping function, add data from previous census. We could allow
limited upload of user data to be integrated with census data, statistical and spacial analysis tools, custom mapping projects.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tax Density in Vancouver]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2015/05/31/density-in-vancouver/"/>
    <updated>2015-05-31T22:44:55-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2015/05/31/density-in-vancouver</id>
    <content type="html"><![CDATA[<p>The other day I saw that Downtown brings in 23% of CoV tax revenue but only makes up 5% of the city area. Intrigued by that I decided to
add a &lsquo;Tax Density&rsquo; layer to my <a href="https://mountainmath.ca/map/assessment">Vancouver Assessment Map</a>.
The idea was to try and understand the tax revenue generated by different areas in Vancouver. The data is already available
in the CoV open data property dataset so it would only take half an hour to ad it to my map.</p>

<p><a href="http://mountainmath.ca/map/assessment"><img src="/images/tax_density.jpg" alt="&quot;Tax Density&quot;" /></a></p>

<p>There has been a lot of discussion around density in Vancouver. One aspect of density is that it will generally increase
the tax revenue that the city can collect per square metre. At the same time the city spending for services of the added
density increases at a much lower rate. Leaving a net gain of revenue for the city. As property taxes are
need-based, this means lower property taxes for everyone when density increases. In short, density leads to efficiency
increases that materialize in form of lower property taxes for everyone.</p>

<p>That also points to one possible way to break some of the resistance to density increases that Vancouver currently sees.
If a neighbourhood (or smaller region) accepts density increases, maybe some of the associated benefits
of lower property taxes should be applied locally instead of everything being spread out over the entire city.</p>

<h4>So what exactly does the Tax Density layer show?</h4>

<!-- more -->


<p>The Tax Density I mapped is simply the amount of taxes collected per m&sup2;.
Under that measure, Downtown comes out at $127.1/m&sup2;, followed by the West End at $72.7/m&sup2; and Fairview at
$42.7/m&sup2;. The Vancouver average is $20/m&sup2;, only 6 of the 23 neighbourhoods have an above-average Tax Density.
A complete list of Tax Density by neighbourhood is at the bottom.</p>

<p>For this calculation I did not count the parks doward the area of
the neighbourhoods, but school for example are included. In light of this some of the aggregated data should be viewed
with caution.</p>

<h4>Where to go from here?</h4>

<p>I also thought about mapping the density of housing units, but sadly the data in the CoV open data catalogue is ill-suited to
do this. I can easily extract the number of tax entities and map the density of these. This works great for a traditional
single family home (one tax entity) and for stratas (one tax entity per unit), but it becomes a problem because e.g. laneway
houses and granny suites don&rsquo;t show up as separate tax entities. And it gets really bad with rental apartments, where the
whole building will be a single tax entity with potentially a very large number of units. And then the dataset does not
distinguish between commercial and residential units. That data could be reverse engineered from the tax data, but that&rsquo;s
more work than my usual half hour tolerance level for this kind of side project.</p>

<p>Another option is to use census data and merge the datasets. But that gets messy, the aggregation levels don&rsquo;t match and
this is well beyond a side project time frame.</p>

<p>Similarly, it would be interesting to map the changes in tax density and the changes in unit density in Vancouver, but
again the CoV dataset does hold the necessary information. In particular, when properties get a new tax coordinate (for
example when they get re-developed) the CoV dataset drops the old tax data associated with that physical location. This
makes it impossible to map the changes in tax density that redevelopment has brought.</p>

<p>Long story hort, if you are interested in browsing Vancouver by tax revenue collected per square meter, click through to
the <a href="https://mountainmath.ca/map/assessment">Vancouver Assessment Map</a> and select the Tax Density layer.</p>

<h2>Tax density by neighbourhood</h2>

<ol>
<li>Downtown: $127.1/m&sup2;</li>
<li>West End: $72.7/m&sup2;</li>
<li>Fairview: $42.7/m&sup2;</li>
<li>Kitsilano: $27.8/m&sup2;</li>
<li>Downtown Eastside: $26.4/m&sup2;</li>
<li>Mount Pleasant: $25.4/m&sup2;</li>
<li>Arbutus Ridge: $17.5/m&sup2;</li>
<li>Grandview-Woodland: $16.4/m&sup2;</li>
<li>West Point Grey: $16.3/m&sup2;</li>
<li>Dunbar Southlands: $15.0/m&sup2;</li>
<li>Riley Park: $14.4/m&sup2;</li>
<li>Oakridge: $13.8/m&sup2;</li>
<li>Shaughnessy: $13.5/m&sup2;</li>
<li>Kensington-Cedar Cottage: $12.8/m&sup2;</li>
<li>Renfrew-Collingwood: $12.4/m&sup2;</li>
<li>Strathcona: $12.2/m&sup2;</li>
<li>Kerrisdale: $11.9/m&sup2;</li>
<li>Marpole: $11.8/m&sup2;</li>
<li>South Cambie: $11.7/m&sup2;</li>
<li>Sunset: $11.2/m&sup2;</li>
<li>Hastings-Sunrise: $10.6/m&sup2;</li>
<li>Victoria-Fraserview: $10.0/m&sup2;</li>
<li>Killarney: $7.7/m&sup2;</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vancouver Bike Paths]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2015/04/01/bike-paths/"/>
    <updated>2015-04-01T16:24:34-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2015/04/01/bike-paths</id>
    <content type="html"><![CDATA[<p>Motivated by the excellent <a href="http://www.washingtonpost.com/blogs/wonkblog/wp/2015/04/01/bleak-maps-of-how-cities-look-using-only-their-bike-lanes/">Washington Post Wonkblog</a> I
mapped Vancouver&rsquo;s bike infrastructure. Looks good at first, but when you take out the &lsquo;fake&rsquo; &ldquo;Local Street&rdquo; bikeways more in line with Wonkblog&rsquo;s methodology it&rsquo;s looking pretty
bleak in large portions of the city.</p>

<p>Of course the devil is in the details and infrastructure cannot just be judged by how it&rsquo;s labeled. If one were to look for 8-80 infrastructure, then the separated lanes
would make the cut. Some of the bike lanes would be marginal, but most would probably make the cut. Although I can&rsquo;t say that I would be particularly keen to let an 8yo cycle on
some of them.</p>

<p>Vancouver&rsquo;s &ldquo;Shared Lanes&rdquo; are not for the faint of heart. They have 50 speed limits on multi-lane roadways
and feature sharrows to make it a little easier for cyclists to &lsquo;take the lane&rsquo;. In some cases cyclists share a lane with
the buses, which is a little better.</p>

<p>The local streets are mostly car tunnels like the &lsquo;Off-Broadway&rsquo; and won&rsquo;t qualify as 8-80, but there are some exceptions like
the local street portion of Pt. Grey Rd, where cycling is rather pleasant.</p>

<iframe src="http://doodles.mountainmath.ca/bike_paths.html?fh=50&nh=true" width="100%" height="580"></iframe>


<p><a href="/bike_paths.html">Full screen view</a></p>

<p>Methodology is simple, it&rsquo;s just the city&rsquo;s bike path data from <a href="http://vancouver.ca/your-government/open-data-catalogue.aspx">their open data catalogue</a>. The data
comes with two fields, &lsquo;name&rsquo; and &lsquo;type&rsquo;. The &lsquo;type&rsquo; was used for the checkboxes at the bottom to selectively turn different
bike lane types on or off and the &lsquo;name&rsquo; will be displayed on hover.</p>

<h3>Update</h3>

<h4>Some more <strike>Canadian</strike> cities:</h4>

<p><a href="http://doodles.mountainmath.ca/bike_paths?city=Calgary,street&amp;type=BICYCLE_CL&amp;dataUrl=http://doodles.mountainmath.ca/data/CALGIS_TRAN_BIKEWAY.geojson">Calgary on street</a>,
<a href="http://doodles.mountainmath.ca/bike_paths?city=Calgary,pathways&amp;type=PRIORITY&amp;name=LOCATION_D&amp;dataUrl=http://doodles.mountainmath.ca/data/YYC_Path_BikeRoutes.geojson">Calgary pathways</a>,
<a href="http://doodles.mountainmath.ca/bike_paths?city=Calgary,trails&amp;type=TYPE_DESCR&amp;name=LOCATION_D&amp;dataUrl=http://doodles.mountainmath.ca/data/YYC_Trail_BikeRoutes.geojson">Calgary trails</a>,
<a href="http://doodles.mountainmath.ca/bike_paths?city=Victoria&amp;type=FullDescr&amp;dataUrl=http://doodles.mountainmath.ca/data/VicBikeRoutes.geojson">Victoria</a>,
<a href="http://doodles.mountainmath.ca/bike_paths?city=Montreal&amp;name=PROJET_NOM&amp;dataUrl=http://doodles.mountainmath.ca/data/MontrealBikeRoutes.geojson">Montreal</a>,
<a href="http://doodles.mountainmath.ca/bike_paths?city=Toronto&amp;type=CP_TYPE&amp;dataUrl=http://doodles.mountainmath.ca/data/TorontoBikeRoutes.geojson">Toronto</a>
<a href="http://doodles.mountainmath.ca/bike_paths?city=Portland&amp;type=FACILITYDE&amp;name=SEGMENTNAM&amp;dataUrl=http://doodles.mountainmath.ca/data/PDXBikeRoutes.geojson">Portland</a>
<a href="http://doodles.mountainmath.ca/bike_paths?city=NYC&amp;type=TF_Facilit&amp;name=Street&amp;fh=65&amp;dataUrl=http://doodles.mountainmath.ca/data/NYCBikeRoutes.geojson">NYC</a>
<a href="http://doodles.mountainmath.ca/bike_paths?city=Amsterdam&amp;type=HIGHWAY&amp;name=WIDTH&amp;dataUrl=http://doodles.mountainmath.ca/data/AmsterdamBikeRoutes.geojson">Amsterdam</a>
<a href="http://doodles.mountainmath.ca/bike_paths?city=Taipei&amp;name=RDNAME&amp;dataUrl=http://doodles.mountainmath.ca/data/TPEBikeRoutes.geojson">Taipei</a></p>

<p>A word of caution. I have done zero data cleaning or verification. Some of these maps are missing some type of infrastructure.
I am familiar with cycling conditions in Calgary, and their the extensive network along the river and other areas are missing in their main file.
I added two more separate maps for their trails and pathways, but was too lazy to merge them. For Taipei, I noticed that
the off-street paths along streets are missing, for example the one on Dunhua Bei Lu that I was using a lot a year ago. Not sure if or where these are available.
So some more ground truth is needed for proper interpretation. But fun anyway.</p>

<p>Want to map another city&rsquo;s data? No problem, just read on.</p>

<!-- more -->


<ol>
<li>Locate the city&rsquo;s bikeway data and download it.</li>
<li>Convert the data to geojson, with coordinates in latitude and longitude.</li>
<li>Put the geojson file online somewhere, e.g. your public dropbox folder.</li>
<li>Optionally look at the geojson file for a bikeway type descriptor and bikeway name, if available.</li>
<li>Build a url for your map by using [<a href="http://doodles.mountainmath.ca/bike_paths">http://doodles.mountainmath.ca/bike_paths</a>] as a base url and add query strings

<ul>
<li><code>dataUrl=&lt;url to your geojson&gt;</code></li>
<li><code>city=&lt;city name&gt;</code></li>
<li>optionally <code>type=&lt;bikeway type property&gt;</code></li>
<li>optionally <code>name=&lt;bikeway name property&gt;</code></li>
<li>optionally <code>zoom=true</code> if you want to be able to zoom and pan on the map</li>
</ul>
</li>
</ol>


<p>For example, to map Calgary&rsquo;s bike network you need to <a href="https://data.calgary.ca/opendata/Pages/DatasetListingAlphabetical.aspx#C">got to their open data website</a> and
download the Tranportation Bikeways shapefiles (SHP). To convert them go geojson using <code>ogr2ogr</code></p>

<pre><code>ogr2ogr -f GeoJSON -simplify 1 -s_srs CALGIS_TRAN_BIKEWAY.prj -t_srs "EPSG:4326" CALGIS_TRAN_BIKEWAY.geojson CALGIS_TRAN_BIKEWAY.shp
</code></pre>

<p>from the <a href="http://trac.osgeo.org/gdal/wiki/DownloadingGdalBinaries">GDAL package</a>.</p>

<p>I uploaded the geojson to <code>http://doodles.mountainmath.ca/data/CALGIS_TRAN_BIKEWAY.geojson</code>, so that will be the value of the <code>dataUrl</code> query string.</p>

<p>Looking at the resulting geojson file you will see that the data does not include bikeway names, but it does include
types and the property is called <code>BICYCLE_CL</code>.</p>

<p>The rather lengthy link to the map would then be
<a href="http://doodles.mountainmath.ca/bike_paths?city=Calgary&amp;type=BICYCLE_CL&amp;dataUrl=http://doodles.mountainmath.ca/data/CALGIS_TRAN_BIKEWAY.geojson">http://doodles.mountainmath.ca/bike_paths?city=Calgary&amp;type=BICYCLE_CL&amp;dataUrl=http://doodles.mountainmath.ca/data/CALGIS_TRAN_BIKEWAY.geojson</a></p>

<iframe src="http://doodles.mountainmath.ca/bike_paths?city=Calgary&type=BICYCLE_CL&fh=50&nh=true&dataUrl=http://doodles.mountainmath.ca/data/CALGIS_TRAN_BIKEWAY.geojson" width="100%" height="580"></iframe>


<p>Or if you want to zoom into Calgary&rsquo;s sprawling suburbs, you could also enable zooming (using double-click) and panning
<a href="http://doodles.mountainmath.ca/bike_paths?city=Calgary&amp;type=BICYCLE_CL&amp;zoom=true&amp;dataUrl=http://doodles.mountainmath.ca/data/CALGIS_TRAN_BIKEWAY.geojson">http://doodles.mountainmath.ca/bike_paths?city=Calgary&amp;type=BICYCLE_CL&amp;zoom=true&amp;dataUrl=http://doodles.mountainmath.ca/data/CALGIS_TRAN_BIKEWAY.geojson</a></p>

<p>Happy Mapping!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vancouver Assessment Data]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2015/03/23/vancouver-assessment-data/"/>
    <updated>2015-03-23T16:20:43-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2015/03/23/vancouver-assessment-data</id>
    <content type="html"><![CDATA[<p>The City of Vancouver has recently
updated <a href="http://vancouver.ca/your-government/open-data-catalogue.aspx">their open data catalogue</a> with historic tax
data. We figured that would
be a good time to take our previous rather clumsy attempts to map tax data and polish that up a bit.</p>

<p>This time we put in a couple of evenings to build a more responsive map with multiple options of what to map. Head
straight for <a href="http://mountainmath.ca/map/assessment">&lsquo;the map&rsquo;</a> or read on for some background information, including
some methodology on data cleaning and interpolation.</p>

<p><a href="http://mountainmath.ca/map/assessment"><img src="/images/land_value.jpg" alt="&quot;Land Values&quot;" /></a></p>

<!-- more -->


<p>Our previous <a href="/teardown_map.html">&lsquo;teardown map&rsquo;</a> and <a href="/teardown_map.html">&lsquo;high value map&rsquo;</a> suffered from being a static
websites, and they loaded large amounts of data all at once, 30,000 properties for the teardown map, and display
the all at once. Options were limited for displaying more detailed data when selecting individual properties.
For the viewer this resulted more in an exercise of patience than in an &lsquo;interactive&rsquo; experience.</p>

<p>We decided to remedy this by importing the CoV data into a database and chop the data up dynamically and serve it as vector tiles.
For smaller zoom levels we aggregated data at the block level. There are lots of blocks in Vancouver, 4444 that contain
properties with tax information to be precise. So again the map is a little sluggish on mobile devices and slower machines when zoomed out,
but things get much faster as we zoom in.</p>

<p>Moreover, we now have the ability to easily display more detailed information once the use selects an individual
property or block aggregate. We can display a graph with the development of land and building values and other details.
And we integrated google streetview for good measure.</p>

<p>One issue that came up is that CoV historical data has lots of gaps. For example, when a particular property was
re-developed it gets a new tax number. The tax information for the old property is lost and cannot be connected to the
geographic site using the information provided by CoV. So when we display data showing &lsquo;value change&rsquo; between
2006 and 2014 we color these properties in grey. This problem persists when we aggregate information at the block level.
To avoid greying out lots of blocks we extrapolate the missing data by using citywide averages on growth rates
of land and building values for the properties in question. This will likely underestimate the aggregate growth in building
and land value, but will not have a big impact at the block level if the individual property value in question was
comparatively small. But this was not always the case. Better analysis could solve some of these issues, so does
zooming in to the individual property level.</p>

<p>Another issue is that CoV does not provide historic zoning information. It would be interesting to get historic zoning
and development permit information. Some of this data is already available, albeit not in an easily consumable form.</p>

<p>Other than that a big thanks to the folks maintaining the CoV open data catalogue!</p>
]]></content>
  </entry>
  
</feed>
