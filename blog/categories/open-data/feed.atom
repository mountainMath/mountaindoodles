<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: open data | Mountain Doodles]]></title>
  <link href="http://doodles.mountainmath.ca/blog/categories/open-data/feed.atom" rel="self"/>
  <link href="http://doodles.mountainmath.ca/"/>
  <updated>2017-08-06T22:48:42-07:00</updated>
  <id>http://doodles.mountainmath.ca/</id>
  <author>
    <name><![CDATA[MountainMath]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[RS Population Change]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/03/06/rs-population-change/"/>
    <updated>2017-03-06T11:06:57-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/03/06/rs-population-change</id>
    <content type="html"><![CDATA[<p><a href="https://censusmapper.ca/maps/583"><img src="http://doodles.mountainmath.ca/images/pop_change_ct.png" style="width:50%;float:right;margin-left:10px;"></a>
With reporting on the new census numbers gaining traction, and now
Mayor Robertson
<a href="http://www.cbc.ca/news/canada/british-columbia/gregor-robertson-statement-vancouver-character-homes-review-1.4011100">picking up on single family neighbourhoods losing population</a>
we thought it is time to crunch some numbers.</p>

<p>Why does it need number crunching? All the reporting so far is based on looking at CT (Census Tract) aggregates, like e.g. in the
map shown and linked to the right. But there is actually no
single CT in the City of Vancouver that only contains RS zoning. Deducing results by just looking on CT aggregates can lead
to misleading reporting, like we have seen with unoccupied dwellings in the &ldquo;Marine Gateway Neighbourhood&rdquo;. Given how prominent
this topic has become it is high time to dig into the details.</p>

<h3>TL;DR</h3>

<p>In summary, we can confirm that RS (single family), RT (duplex) and FSD neighbourhoods have been dropping population.
Slightly. Looking separately at the
east and the west side, we notice that population in these neighbourhoods dropped by about 1% on the west side and increased
slightly on the east side.</p>

<p>In all groupings that we looked at the household size dropped and the rate of unoccupied dwellings increased. This was counter-acted
by a growth in dwelling units, mostly confined to RS zones where laneway houses and suites were added (or newly discovered
in the 2016 census).</p>

<p>We split the analysis into <em>core</em> regions, blocks that lie completely within RS, RT and FSD zoning, and <em>fringe</em> regions,
blocks that have RS, RT or FSD zoning as well as other zoning. Fringe regions grew in population and had overall lower rates
of unoccupied units when compared to core regions.</p>

<!-- more -->


<h3>Comparing Censuses</h3>

<p>Comparing data across censuses is hard. For one, definitions change from one census to the next
and thus variables aren&rsquo;t always comparable. Four our immediate goal of comparing
population, private dwellings, and private households between the 2011 and 2016 censuses
that is not a concern.</p>

<p>Comparing data is relatively easy when census geographies are large (i.e. CT, CSD level or higher)
and the census geography matches exactly the area that we are interested in. For CSDs (Municipalities)
this is often the case, but at the sub-municipal level, the CTs (Census Tracts) or other sub-municipal
aggregation levels rarely line up with the regions one is interested in.</p>

<p>For example, if one is interested in changes in population in RS (single family zoned) neighbourhoods in
Vancouver, looking at selected CTs will only give some initial indication. The reason is that
there is actually no CT in the City of Vancouver that is entirely RS zoned. There are several that
come close (the closest one is CT 9330015.01 around 41st and Thyne, which actually
increased population from 5,364 in 2011 to 5,485 in 2016) but it shows how tricky
it is to answer the really simple question how the population changed in RS neighbourhoods.</p>

<p>So how to deal with this issue? The cleanest way is a custom tabulation from StatCan, but that takes
time, costs money, and may still
<a href="https://twitter.com/vb_jens/status/838561779970011136">result in problems when data was not geocoded correctly</a>,
which is next to impossible to detect in custom tabulations.</p>

<p>An alternative way is to compare censuses at finer aggregation levels, that is at DAs (Dissemination Areas) or
DBs (Dissemination Blocks).</p>

<h3>Comparing Censuses at DA or DB levels</h3>

<p>For our concrete example, that means we look for DBs within RS zoning and work with these.</p>

<p>There are several difficulties with this approach. The most important is that the finer data we look at,
the more likely we pick up problems with Census data (yes, there are problems) and mistake them for real world data.
For our case through, we can avoid some of that by aggregating over all DBs within RS zoning to even out some
of these issues. Morever, we can visually inspect the data to look for any particular DB that seems to be problematic
and do some ground-truthing to see if the issues are only in the data or actually on the ground.</p>

<p>The next difficulty is technical in nature. Census geographies, including DBs and DAs, can change from one census to
another and thus may not be comparable. In order to get reliable results we need to make sure that we work with
a common set of geographies for both the 2011 and 2016 censuses. Luckily this is only a technical problem that can be
overcome as census geographies don&rsquo;t just change randomly but still retain some basic comparability.</p>

<p>And it&rsquo;s perfect timing, since we just created a &ldquo;least common denominator&rdquo; tiling derived from 2011 and 2016 DBs and DAs. At
CensusMapper we work with &ldquo;cartographic&rdquo; DBs (so we clip our major bodies of water), which leads to a minor issue where
between 2011 and 2016 things were clipped slightly differently which yielded two DBs in 2011 (with 16 and 17 people in it)
being clipped out (and having no people in it) in 2017, likely a combination of adjusting some tolerances in the StatCan
algorithms as well as some minor changes in geocoding that moved the population into an adjacent DB
(like e.g. happened with 59150971009 and 59150971008 south of King Edward split along Carnarvon). Apart from that, the
result is a tiling of Canada by DB and DA-based geographies that allow for consistent comparisons across the two censuses.</p>

<p>In numbers there were 493,192 cartographic DBs in 2016, 489,676 in 2016, and these resulted in a least common denominator tiling
by 445,953 DB-based geographies.</p>

<h3>RS, RT and FSD Zones and Population Change</h3>

<p><img src="http://doodles.mountainmath.ca/images/filter_all.png" style="width:50%;float:right;margin-left:10px;">
Back to our original question, how did population change in RS zoning. Before we go there, we think it makes more sense to expand
the question to ask for RS, RT (duplex) and FSD (First Shaughnessy) combined as these are about equally restrictive in what
we allow there.</p>

<p>Grabbing the <a href="http://data.vancouver.ca/datacatalogue/zoning.htm">latest available zoning data</a> and uploading it to
CensusMapper makes it easy to download the 2011 and 2016 dissemination blocks that intersect RS, RT and FSD zoning. We removed the RS part
that snakes along the downtown beaches and covers Stanley Park, as well as the sliver creeping up False Creek and covering the marinas there.</p>

<p>When we intersect the census data with the zones, we also compute the overlap each DB has with the zoning and disregard any region
with less than 10% overlap. Moreover we divide the dissemination blocks into <em>core</em> blocks where
the overlap is greater than 99% and <em>fringe</em> blocks, where the overlap is less than 99%.</p>

<p>One should remember that a significant
portion (a majority actually) of RS, RT and FSD dwellings are contained in &ldquo;fringe&rdquo; areas.
So it is best to focus on the rates of change, we would expect the total number of population decline
of all RS, RT and FSD zoned properties to be higher.</p>

<p>Here are the results:</p>

<pre><code>RS, RT, FSD
core: 236 DB, fringe: 475 DB
Population 2011 - 2016
core pop change: -69, fringe pop change: 6673, core total pop: 124916, fringe total pop: 284231
Dwellings 2011 - 2016
core dw change: 2812, fringe dw change: 7142, core total dw: 47008, fringe total dw: 121488
Households 2011 - 2016
core hh change: 1194, fringe hh change: 5127, core total hh: 42298, fringe total hh: 111801
</code></pre>

<p><img src="http://doodles.mountainmath.ca/images/filter_core.png" style="width:50%;float:right;margin-left:10px;">
What we see is that the population in the &ldquo;core&rdquo; DBs did drop. Slightly. At the same time the number of dwellings
increased quite noticeably by 6.3% in the core, with essentially all of the dwelling growth located within RS zones
(as opposed to RT and FSD). So most of that dwelling
growth is due to suites and laneway houses. Note that we only capture 47008 dwellings in the &ldquo;core&rdquo; RS, RT, FSD areas,
which is less
than half of the dwelling units in RS, RT and FSD with the remaining dwellings are located within the &ldquo;fringe&rdquo; regions.</p>

<p><a href="https://censusmapper.ca/maps/596"><img src="http://doodles.mountainmath.ca/images/van_pop_comp.png" style="width:50%;float:left;margin-right:10px;"></a>
Interestingly, the number of households grew much slower than the number of dwellings in the &ldquo;core&rdquo; regions, increasing the rate
of unoccupied units from 7% to 10%. Following our decomposition of population growth <a href="https://censusmapper.ca/maps/596">mapped here</a>
and <a href="http://doodles.mountainmath.ca/blog/2017/02/10/2016-census-data/">explained in more detail in a previous post</a>, we see
that the population growth of -69 in the &ldquo;core&rdquo; regions can be decomposed into:</p>

<ul>
<li>-3,699 due to declining household size,</li>
<li>-4,321 due to increase in unoccupied dwellings, and</li>
<li>7,952 due to increase in dwelling units.</li>
</ul>


<p><img src="http://doodles.mountainmath.ca/images/filter_fringe.png" style="width:50%;float:right;margin-left:10px;">
We can do the same analysis for the &ldquo;fringe&rdquo; areas, where RS, RT and FSD zoning mixes with other zones. Here we get a population
increase by 2.4%, driven by an increase
in dwelling units by 6.2%, and dampened by shrinking household size and a
more modest increase in the rate of unoccupied units from 6.7% in 2011 to 8% in 2016. We note that
the rate of unoccupied units increased significantly less on the fringe when compared to the core.</p>

<p>Breaking up the population growth of 6,673 people as before we have:</p>

<ul>
<li>-6,667 due to declining household size,</li>
<li>-3,996 due to increase in unoccupied dwellings, and</li>
<li>17,336 due to increase in dwelling units.</li>
</ul>


<h4>The West Side</h4>

<p>Lastly, we probably can&rsquo;t talk about this without running a separate analysis for the west side. So here we go.</p>

<pre><code>RS, RT, FSD
core: 88 DB, fringe: 184 DB
Population 2011 - 2016
core pop change: -510, fringe pop change: 1631, core total pop: 42878, fringe total pop: 105309
Dwellings 2011 - 2016
core dw change: 572, fringe dw change: 2426, core total dw: 16735, fringe total dw: 49210
Households 2011 - 2016
core hh change: -18, fringe hh change: 1226, core total hh: 15066, fringe total hh: 44907
</code></pre>

<p>We see that this confirms conventional wisdom that the population decline in the core areas of RS, RT, FSD is stronger
on the west side (and in fact population did increase overall in the core areas on the east side). The rate of unoccupied (by usual residents)
units was quite similar to the overall RS, RT, FSD, climbing from 6.7% in 2011 to 10% in 2016.</p>

<p>Again splitting up the population change of -510 people in the &ldquo;core&rdquo; area into components we get:</p>

<ul>
<li>-458 due to declining household size,</li>
<li>-1,587 due to increase in unoccupied dwellings, and</li>
<li>1,535 due to increase in dwelling units.</li>
</ul>


<p>For the &ldquo;fringe&rdquo; west side areas we again observe that population increased at 1.5%, dwellings by 5.1% and
the rate of unoccupied units grew slower from 6.6% to 8.7%. Splitting up the population change of 1,631 people:</p>

<ul>
<li>-1,278 due to declining household size,</li>
<li>-2,466 due to increase in unoccupied dwellings, and</li>
<li>5,376 due to increase in dwelling units.</li>
</ul>


<h3>Glossary</h3>

<p>We are a little loose with our use of language. In this post &ldquo;unoccupied&rdquo; is always short for &ldquo;not occupied by usual residents&rdquo;,
so in simpler terms &ldquo;not used as primary residence&rdquo;. &ldquo;Occupied&rdquo; refers to &ldquo;used as primary residence&rdquo;.</p>

<p>West side and east side were divided along the longitude for Ontario road.</p>

<p>Core regions are Dissemination Blocks that have at least 99% overlap with RS, RT or FSD zoning.</p>

<p>Fringe regions are Dissemination Blocks that have between 10% and 99% overlap with RS, RT or FSD zoning.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[More on Teardowns]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/02/21/more-on-teardowns/"/>
    <updated>2017-02-21T10:59:27-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/02/21/more-on-teardowns</id>
    <content type="html"><![CDATA[<p><a href="https://mountainmath.ca/teardowns"><img src="http://doodles.mountainmath.ca/images/teardowns_animated.gif" style="width:50%;float:right;margin-left:10px;"></a>
A little over a year ago we ran some analysis
<a href="http://doodles.mountainmath.ca/blog/2016/01/18/redevelopment/">on teardowns</a>
of single family homes in the City of Vancouver. We used the City of Vancouver
open data to understand why some single family homes got torn down and other&rsquo;s don&rsquo;t.</p>

<p>Relying entirely on open data, there were some important questions that could not
be answered. So together with Joe Dahmen at UBC&rsquo;s School Of Architecture And Landscape Architecture
we came back to the question
and folded in transaction data from BC Assessment to add some more details and rigor.</p>

<p>The result turned out quite similar to what our initial cruder methods came
up with, but it lead to some important refinements.</p>

<p>We won&rsquo;t go into the details of the findings here, you can
<a href="https://mountainmath.ca/teardowns" target="_blank" class='btn btn-default'>read the online data story</a>
if you are interested. Instead we will go into a little more details how
the analysis was done and what is still missing.</p>

<!-- more -->


<p>The most critical piece that we added was transaction data, that is
which properties got sold in what year. Almost all properties that got
torn down were associated with a property transaction in the 4 years
around it getting torn down rebuilt.</p>

<p>This allowed us to refine the question from &ldquo;why did building A get torn
own and building B did not&rdquo; to ask the same question only considering
transacted buildings.</p>

<p>Conditioning on the most important determinant of a building getting torn down,
the transaction, we could focus in much better on what building-specific
parameters are driving teardowns.</p>

<h3>Variables</h3>

<p>We had annual assessment data pegged at July 2005 through July 2016, although
we excluded the July 2016 data for some parts of the analysis as the value
gains that year where
<a href="http://doodles.mountainmath.ca/blog/2017/01/16/2017-assessment-data/">quite extraordinary</a>
and prices have come down
a bit since then. We felt that this most recent assessment may not be a good
launching point to project the future from.</p>

<p>Unfortunately, the number of variables for teardowns that we have is
quite limited. We only have good data on assessed land values, assessed
building values and lot area. For a very small subset of about 500 buildings
we also have the building age of the building that got torn down. We have
GFA estimates for buildings that got torn down after 2009 through the
<a href="http://doodles.mountainmath.ca/blog/2016/03/05/physical-sfh-form-over-time/">analysis of LIDAR data</a>
that we did, but those estimates are quite crude and again only cover a portion of our
time frame.</p>

<p>A crucial variable that we are still missing is the actual time of the building
demolition. We inferred this from the time a new building got completed on that
property, but this inevitably introduces noise to the data. It makes it
difficult to pick the right time to calculate the relative building value. Moreover,
there may be the occasional property that got built on vacant land, so nothing got torn down.
This was less an issue for the analysis part, where we had ways to filter out such properties,
but it did cause some problems with the visualization part of the project. We did filter out
some properties manually that we could identify as being built on vacant land within
the timeframe of the visualization, namely some properties on Deering Island.</p>

<p>On top of that, the decision to demolish the building was often made long
before the building got torn down. Waiting times on demolition permits can be quite long, depending
on the property. Having access to building permit data would help sharpen
this variable. The word from the friendly open data folks is that the
City of Vancouver is working on making these public, maybe an FOI request
can help them speed up the process.</p>

<h3>Noise</h3>

<p>The most important source of noise in our data is that fact that assessment
data is only accurate <em>on average</em>. For particular buildings it can be substantially
off. We suspect that this is one of the reasons why for
buildings that are assessed to be essentially worthless,
the teardown probability tops out at a little above 60%. So someone
paying $2.5 million for a house that is worth only $10,000 to move in and live
in that house makes absolutely no sense. If the building like this did not get torn down,
we hypothesize one of three scenarios:</p>

<ol>
<li>The building was purchased as a pure investment vehicle and rented out
until an opportune time to re-develop or sell the property.</li>
<li>The assessment grossly undervalued the building.</li>
<li>The building was extensively renovated.</li>
</ol>


<p>We have looked through the data and have found little evidence that scenario 3 is
playing out in significant numbers. Extensive renovations show up in assessment
data via building value gains and the &ldquo;year improved&rdquo;. We don&rsquo;t have
data to assess the other two hypotheses.</p>

<h3>Model</h3>

<p>Given that limited variables we trained a handful of models on our data to see
how to best predict future teardowns. In all models we used, the relative
building value was the single most predictive variable, accounting for well over
80% of explanatory power no matter what methods we used. Moreover, the
performance of more complex machine learning models was not markedly better
that using a simple logistic regression. Similarly, dropping all other variables
except the relative building value only slightly decreased the skill of our
model.</p>

<p>One way to improve on our model is to use a proper survival analysis that
can better account for data that is only available for certain time frames.
For example, teardown early in our time frame suffer from the shortcoming that
we don&rsquo;t have transaction data reaching back far enough to link the teardown
to a transaction. Or more to the point, be able to compare it to other
transacted properties that didn&rsquo;t get torn down. Similar problems occur
at the end of our time frame, and with variables that are only available
in certain sub time frames.</p>

<script>
function resetImages(){
    $('img').each(function(img){
        imgsrc = $(img).attr('src');
        if (imgsrc.slice(imgsrc.length-4)=='.gif') {
            $(img).attr('src', '');
            $(img).attr('src', imgsrc);

        }
    });
    setTimeout(function(){
        resetImages();
    },25000);
}
setTimeout(function(){
    resetImages();
},25000);
</script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bumper Year for Thumb Twiddlers]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/01/18/bumper-year-for-thumb-twiddlers/"/>
    <updated>2017-01-18T11:10:43-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/01/18/bumper-year-for-thumb-twiddlers</id>
    <content type="html"><![CDATA[<p><a href="https://mountainmath.ca/map/assessment?zoom=12&amp;lat=49.2494&amp;lng=-123.1241&amp;layer=12"><img src="http://doodles.mountainmath.ca/images/twiddling_thumbs_2006_2017.png" style="width:50%;float:right;margin-left:10px;"></a>
Almost a year has passed since we first noticed how
<a href="http://doodles.mountainmath.ca/blog/2016/01/24/work-vs-twiddling-thumbs/">sitting on single family homes and twiddling thumbs generates more income than working</a>.
And not just at the level of individual single family households. In the
City of Vancouver, the cumulative
land value gains of just the single family homes eclipsed the cumulative taxable earnings
reported to the CRA for the entire population.</p>

<p>With the new assessment data available now, it is time to run the numbers
and see how our thumb-twiddlers fared vs workers this year. If you thought
last year&rsquo;s twiddling thumbs returns were crazy high, you better hold onto
your hats!</p>

<!-- more -->


<h3>Work</h3>

<p>Not much changed in terms of the income people earned. CANSIM does not make the
taxfiler data freely available at the municipal level, we we will again estimate
the cumulative income for residents of the City of Vancouver by using 2010
Census data and extrapolating by applying the Metro Vancouver rate of income
growth.</p>

<p>This way we get a cumulative $22.3bn pre-tax or $18.6bn after-tax income in 2010,
<a href="http://www5.statcan.gc.ca/cansim/a26?lang=eng&amp;retrLang=eng&amp;id=1110009&amp;&amp;pattern=&amp;stByVal=1&amp;p1=1&amp;p2=37&amp;tabMode=dataTable&amp;csid=">which grew around 13% between 2010 and 2014</a>.
Extrapolating this for another two years to 2016 we estimate an income growth of around 20% since 2010,
which then pegs the cumulative income for the City of Vancouver at
$26.8bn pre-tax or $22.3bn after-tax (ignoring financial drag and other issues).</p>

<h3>Twiddling Thumbs</h3>

<p>Let&rsquo;s compare this to how much Vancouver home owner households &ldquo;earned&rdquo; last year by twiddling thumbs while sitting on their
property. To keep things simple and consistent with last year, we again focus on just the single family homes (SFH).
And again, we only consider land value changes, after all changing the
building value because of renovation or rebuilding certainly does not happen by twiddling thumbs.</p>

<p>The median SFH land value increased was $435,000 (the average was $594,005), for a cumulative land value increase
of $46.7bn, accounting for about half of the
<a href="http://doodles.mountainmath.ca/blog/2017/01/16/2017-assessment-data/">total land value increase of the City of Vancouver</a>
or two thirds of the land value increase for residential (and mixed) land uses.</p>

<p>So while last year the twiddling thumbs return were still comparable to the cumulative income in the City of Vancouver,
this year the thumb twiddlers blow the income earners out of the water.
<span style="font-weight:bolder;">Just by by twiddling their thumbs, the SFH property owners alone earned twice as much
as the entire population of the
City of Vancouver did by actually working</span>. And in most cases homeowners won&rsquo;t pay taxes on
their thumb-twiddle earnings, although the
<a href="http://doodles.mountainmath.ca/blog/2016/10/04/secondary-suites-and-taxes/">CRA recently made it harder with their new reporting rules</a>.</p>

<p>We are glossing over a couple of details here, for example the numbers are not adjusted for inflation, and costs like
property taxes and property transfer tax are not taken into account.</p>

<p>Of course, comparing income from work to income from twiddling thumbs is not entirely fair. The income from twiddling thumbs
is frozen in the property until the owner sells. But gains accumulate over the years, and eventually everyone sells and realizes
the gains (or passes them on to the next generation). And it&rsquo;s always good to remember that
&ldquo;<a href="https://twitter.com/GRIDSVancouver/status/813516103490015232">house-rich cash-poor homeowners are one transaction away from simply being rich renters</a>&rdquo;.</p>

<h3>The Long Term</h3>

<p><a href="https://mountainmath.ca/map/values?filter=sfh&zoom=13&lat=49.2482&lng=-123.1213&layer=25&mapBase=2&year=2016"><img src="http://doodles.mountainmath.ca/images/twiddling_thumbs_animated_2017.gif" style="width:50%;float:left;margin-right:10px;"></a>
Most people don&rsquo;t trade houses like stocks, so what really matters is the long term gains, not the year to year changes. The 11 year
timeframe for which we have data roughly matches the average holding time for a single family house. The year over year
changes in land value vary dramatically, as the image shows and can be explored further using the
<a href="https://mountainmath.ca/map/values?filter=sfh&amp;zoom=13&amp;lat=49.2482&amp;lng=-123.1213&amp;layer=25&amp;mapBase=2&amp;year=2016">interactive version</a>.</p>

<p>Over 11 years, the single family home land value quadrupled. The median (nominal) single family home land value increase over that timespan
was $1,233,000, or $112,000 per year. Broken down further, that&rsquo;s $2,339,000 ($213,000 per year) for the median west side home
and $1,031,000 ($94,000 per year) for the median east side home.</p>

<p><a href="https://mountainmath.ca/map/assessment?filter=sfh&amp;zoom=13&amp;lat=49.2494&amp;lng=-123.1241&amp;layer=12"><img  src="http://doodles.mountainmath.ca/images/twiddling_thumbs_2006_2017.png" style="width:50%;float:right;"></a>
We <a href="https://mountainmath.ca/map/assessment?filter=sfh&amp;zoom=13&amp;lat=49.2494&amp;lng=-123.1241&amp;layer=12">mapped the land value gain averaged over 11 years</a>.
We can observe that the average yearly increase depends on the square footage of the property as well as the location. The rates are mostly uniform
throughout the city (with some notable exceptions), but properties starting out with a higher value will see higher total value
increases. It&rsquo;s probably fair to say that even using the 11 year average, most homeowners &ldquo;earned&rdquo; more money twiddling thumbs
than pursuing a more traditional employment.</p>

<h3>Hourly Rate for Twiddling Thumbs</h3>

<p>Using the <a href="http://doodles.mountainmath.ca/blog/2016/01/24/work-vs-twiddling-thumbs/">same methods as last year</a>
we can compute the hourly earnings of thumb twiddlers. For the July 2016 to July 2017 timeframe, thumb twiddlers
in the City of Vancouver averaged a tidy $239 per hour.
Using the 11 year averaged numbers instead of focusing on just the last year we still get a healthy average
thumb twiddling rate of $62 per hour.</p>

<p>Another bumper year for thumb twiddlers!
Considering to change your line work to thumb twiddling? To bad thumb twiddling is so unaffordable!</p>

<h3>Data Dump</h3>

<p>Here is the raw output of the stats run on the single family properties for anyone interested.</p>

<h5>SFH Land Value Rise (2016 - 2017)</h5>

<ul>
<li>City Wide: Average $594,005 Median $435,000, Count: 78648, Total: $46,717,325,799, Hourly: $239</li>
<li>Eastside: Average $373,306 Median $358,000, Count: 47988, Total: $17,914,233,199, Hourly: $150</li>
<li>Westside: Average $939,435 Median $866,000, Count: 30660, Total: $28,803,092,600, Hourly: $378</li>
</ul>


<h5>SFH Land Value Rise (2006 - 2017)</h5>

<ul>
<li>City Wide: Average $153,777 Median $112,090, Count: 77809, Total: $11,965,271,272, Hourly: $62</li>
<li>Eastside: Average $96,892 Median $93,727, Count: 47545, Total: $4,606,748,985, Hourly: $39</li>
<li>Westside: Average $243,144 Median $212,636, Count: 30264, Total: $7,358,522,287, Hourly: $98</li>
</ul>


<p>The total number of units for the 2006 to 2017 analysis are a little lower since not all properties can be traced over that time
period without resorting to more tedious analysis.</p>

<script>
function resetImages(){
    $('img').each(function(img){
        imgsrc = $(img).attr('src');
        if (imgsrc.slice(imgsrc.length-4)=='.gif') {
            $(img).attr('src', '');
            $(img).attr('src', imgsrc);

        }
    });
    setTimeout(function(){
        resetImages();
    },25000);
}
setTimeout(function(){
    resetImages();
},25000);
</script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Coveted $1.2m - $1.6m Vote]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/01/17/the-coveted-2m-6m-vote/"/>
    <updated>2017-01-17T16:19:03-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/01/17/the-coveted-2m-6m-vote</id>
    <content type="html"><![CDATA[<p><a href="https://mountainmath.ca/map/special/81?layer=101&amp;mapBase=2"><img  src="http://doodles.mountainmath.ca/images/coveted_vote.png" style="width:50%;float:right;margin-left:10px;"></a>
Earlier this month the province increased the threshold for the homeowner grant from $1.2 million to $1.6 million dollars.
It&rsquo;s an election year, and with the BC Assessment data for the City of Vancouver now being available via their
<a href="http://vancouver.ca/your-government/open-data-catalogue.aspx">open data catalogue</a>
we can ask who exactly this move was targeting.</p>

<p>Restricted to the City of Vancouver, the answer is quite simple. There are about 24,000 single family homes, 1,200 duplex units and 4,000 condo units
in that bracket.</p>

<p>Let&rsquo;s take a closer look.</p>

<!-- more -->


<p><a href="https://mountainmath.ca/map/assessment?filter=[sfh,total_1200000_1600000]&amp;layer=101&amp;mapBase=2"><img  src="http://doodles.mountainmath.ca/images/coveted_sfh_vote.png" style="width:50%;float:left;margin-right:10px;"></a>
If we focus in on just the
<a href="https://mountainmath.ca/map/assessment?filter=[sfh,total_1200000_1600000]&amp;layer=101&amp;mapBase=2">single family homes</a>,
which make up the vast majority of the units in that bracket, we see that they
are (almost) entirely located in East Vancouver. In fact, we can see how Main Street delineates these properties quite neatly.
In fact, there are fewer than 500 single family homes west of Main in that bracket.</p>

<p>One could be lead to think that Main Street is the &ldquo;$1.6m line&rdquo;. But of the single family homes
east of Main, these only make up just over half of the properties there,
there are almost as many that are
<a href="https://mountainmath.ca/map/assessment?filter=[sfh,total_1600000]&amp;layer=101&amp;mapBase=2">assessed over $1.6m</a>
and <a href="https://mountainmath.ca/map/assessment?filter=[sfh,total__1200000]&amp;layer=101&amp;mapBase=2">almost 2,000 assessed under $1.2m</a>.</p>

<h4>Changing Homeowner Grant Status</h4>

<p>There are a number of single family homes where the homeowner grant status changed between 2016 and 2017.
There are about 3,100 single family homes who did not qualify for the homeowner
grant in 2016, but do now. And about 1000 that did qualify in 2016 but won&rsquo;t this year.</p>

<p>Yes, that&rsquo;s right, there are
1000 single family homes with 2016 assessment below $1.2m and 2017 assessment over $1.6m. I pity them,
having to pay an extra $50/month in property taxes just because the province did not care about them
enough to set the new threshold higher than $1.6m.</p>

<p>To round things up, there were a little under 500 duplex and condo units that did not qualify for the homeowner
grant in 2016 and do in 2017, and under 200 that did qualify in 2016 and don&rsquo;t now.</p>

<h3>How to get the grant if you are renting?</h3>

<p>You can&rsquo;t. And your landlord can&rsquo;t either. No matter how much your unit is worth, the province won&rsquo;t be cutting
any checks to lower your rent by $50/month.
The homeowner grant is just one of the many perks exclusively available home owners.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2017 Vancouver Assessment Data]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/01/16/2017-assessment-data/"/>
    <updated>2017-01-16T19:04:19-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/01/16/2017-assessment-data</id>
    <content type="html"><![CDATA[<p><a href="https://mountainmath.ca/map/values?filter=[sfh]&amp;zoom=13&amp;layer=9"><img  src="http://doodles.mountainmath.ca/images/value_animated.gif" style="width:50%;float:right"></a>
The friendly folks at
<a href="http://vancouver.ca/your-government/open-data-catalogue.aspx">Vancouver Open Data</a> just
<a href="https://twitter.com/VanOpenData/status/688060388190097408">updated their property assessment data</a> with the fresh 2017
property tax assessments. Time to run the script to update the <a href="https://mountainmath.ca/map/assessment">Vancouver Assessment Map</a>
with the new data, just <a href="http://doodles.mountainmath.ca/blog/2016/01/17/updated-vancouver-assessment-data/">like we did last year</a>.</p>

<p>For now we just updated our standard visuals and computed some overall statistics. We will take a closer look at the data over the coming days.</p>

<h4>Maps</h4>

<!-- more -->


<p>By now we have a variety of maps that highlight different aspects of Vancouver real estate, and after running the import scripts they
automatically serve the newest data. Our basic
<a href="https://mountainmath.ca/map/assessment">interactive assessment map</a> offers a variety of ways to slice and display the data. It&rsquo;s
mostly focused on functionality, some of which we described in
<a href="http://doodles.mountainmath.ca/blog/2016/01/17/updated-vancouver-assessment-data/">last year&rsquo;s post</a>, as well as other posts like
the one on <a href="http://doodles.mountainmath.ca/blog/2016/01/24/work-vs-twiddling-thumbs/">twiddling thumbs vs working</a>.</p>

<p>We also have interactive views focusing on how real estate prices varied over time, for example the <a href="http://doodles.mountainmath.ca/blog/2016/04/01/on-dirt-and-houses/">houses and dirt map</a>
that separates out (inflation adjusted) values of the structures and the land, and also allows to filter by type of housing, to animate changes over time.</p>

<p>For people that like simpler maps we also have a <a href="https://mountainmath.ca/map/values?filter=[sfh]&amp;zoom=13&amp;layer=9">plain total (nominal) value over time map</a>
that allows to interactively step through the years and see how single family house values in Vancouver changed over time. Here we also
added the ability to visualize year-over-year value changes, which also hints at how BC Assessment changed their valuation
algorithm over the years.</p>

<h4>The Data</h4>

<p>The data originates with BC Assessment, which estimates land and building values of each property based on recent sales
of comparable properties. The values are pegged at July 1 of each year, with the the most recent available now being July 1 2016.
The estimates for the values do not reflect changes in the market since then. Moreover, the estimates can be quite off on an individual
property level, but are unbiased. That means that any statistics derived from a large subsample should fairly accurately
reflect actual market conditions for July 1st. Lastly, the assessed values will still change a bit as some will be successfully appealed.</p>

<p>City of Vancouver, as well as the City of Surrey, make this data available for general use through their open data portal, which
allows us to create these maps. The format of the data the municipalities are giving out through their open data portal is
different, so lazy me is only importing data from City of Vancouver. Sadly, BC Assessment does not make this data
generally available province wide for us to make province wide maps.</p>

<p>While BC Assessment makes this data available on their <a href="https://evaluebc.bcassessment.ca">eValue website</a> for browsing individual
properties and also provides it in bulk to researchers, the attached license does not allow the thematic mapping of individual properties.</p>

<p>The motivation behind the map was to understand the building stock, so in the maps as well as the summary statistics below
we filter out parks and some other properties.</p>

<p>The new city dataset does not include the 2017 tax levy, so our maps still only show the 2016 tax levies until CoV updated their dataset.</p>

<h4>History</h4>

<p>In the spirit of <a href="http://doodles.mountainmath.ca/blog/2016/01/17/updated-vancouver-assessment-data/">last year&rsquo;s post</a> we ran some
quick summary statistics to break down the numbers by neighbourhood. Instead of listing the most recent land and building value
increases by neighbourhood we stuck everything into an interactive graph for the entire time span between 2006 and 2017 tax years.
Use the dropdown menus to drill down
into city neighbourhoods, view values for all properties or just residential properties and display as total value or year-over-year
percentage change.</p>

<p>The last year again
saw an huge increase in property values. For the City of Vancouver land values were up 35% and building values 10%, with the land
value increase setting a record for the timeframe for which we have data. The increases become even more pronounced when we zero in
on residential property only.</p>

<div style="margin:10px 50px;padding:5px;border: 1px solid black;border-radius:5px;">
<select id="nbhd-select"></select>
<select id="keys-select"></select>
<select id="type-select">
<option value='total'>Total Value</option>
<option value='percent'>Percentage Change</option>
</select>
<div id="graph" style="height:200px;max-width:640px;" data-lines="/data/detail_history.json"></div>
<div class="legend no-margin">
</div>
</div>




<script>
var ready_for_graph = function() {
    var d3lines=[];
    var padding = {top: 20, right: 20, bottom: 30, left: 90};
    var prevChartWidth = 0, prevChartHeight = 0;
    var updateTransistionMS = 750; // milliseconds
    var jsonData, xScale, yScale, line,neighbourhoods;

    var currentValue='City of Vancouver';
    var currentKeys=['land','building'];
    var currentModePercentage=false;

    var hash={
            land: {label:"Land Value", color:"green"},
              building: {label:"Building Value", color:"blue"},
              res_land: {label:"Residential Land Value", color:"darkgreen"},
              res_building: {label:"Residential Building Value", color:"darkblue"},
              land_p: {label:"Land Value Increase", color:"green"},
              building_p: {label:"Building Value Increase", color:"blue"},
              res_land_p: {label:"Residential Land Value Increase", color:"darkgreen"},
              res_building_p: {label:"Residential Building Value Increase", color:"darkblue"}
                };
    var keys=Object.keys(hash);

    var symbol;
    var prefix;
    var numberFormatter = function (y) {
        return '$' + Math.round(prefix.scale(y*10))/10.0 + symbol;
    };

    var graphs=d3.select("#graph");
    var div=graphs[0][0];
    if (div==null|| div.childElementCount!=0) {return;}
    var data_url=div.dataset.url;

    // create svg and g to contain the chart contents
    var baseSvg = graphs.append("svg");
    var chartSvg=baseSvg
        .append("g")
        .attr("class", "chartContainer")
        .attr("transform", "translate(" + padding.left + "," + padding.top + ")");

    // create the x axis container
    chartSvg.append("g")
        .attr("class", "x axis");

    // create the y axis container
    chartSvg.append("g")
        .attr("class", "y axis");
    var line;
    var largest=null;
    var lineData;
    if (div.dataset.lines) {
        d3.json(div.dataset.lines,function(error,json){
        jsonData=json;
        neighbourhoods=Object.keys(jsonData);
        var keyHash={all:{label: 'All Properties',data:['land','building']},res:{label: 'Residential Properties',data:['res_land','res_building']}};
        var keyOptions=Object.keys(keyHash);
        d3.select('#nbhd-select').selectAll('option').data(neighbourhoods).enter().append('option').attr('value',function(d){return d}).text(function(d){return d});
        $('#nbhd-select').on('change',function(d){
            currentValue=this.value;
            updateChart({init:true,keys:currentKeys,data:jsonData[currentValue],percentage:currentModePercentage})
        });
        d3.select('#keys-select').selectAll('option').data(keyOptions).enter().append('option').attr('value',function(d){return d}).text(function(d){return keyHash[d].label});
        $('#keys-select').on('change',function(d){
            currentKeys=keyHash[this.value].data;
            updateChart({init:true,keys:currentKeys,data:jsonData[currentValue],percentage:currentModePercentage})
        });
        $('#type-select').on('change',function(d){
            currentModePercentage=this.value=='percent';
            updateChart({init:true,keys:currentKeys,data:jsonData[currentValue],percentage:currentModePercentage})
        });
        lineData=json[currentValue];
        var domain=[null,null];
        var range=[null,null];
        lineData.forEach(function(d) {
             d.date = +d.date;
             if (domain[0]==null || domain[0]> d.date) domain[0]= d.date;
             if (domain[1]==null || domain[1]< d.date) domain[1]= d.date;
             keys.forEach(function(k){
                d[k]=+d[k];
                if (range[0]==null || range[0]> d[k]) range[0]= d[k];
                if (range[1]==null || range[1]< d[k]) range[1]= d[k];
            });
        });
        xScale=d3.scale.linear().domain(domain);
        var toAdd=(range[1]-range[0])/10;
        range[0]-=toAdd;
        range[1]+=toAdd;
        yScale=d3.scale.linear()
            .domain(range);

        line = d3.svg.line()
            .x(function(d) { return xScale(d.date); })
            .y(function(d) { return yScale(0); })
            .interpolate("linear");
        xAxis = d3.svg.axis()
            .scale(xScale)
            .orient("bottom")
            .tickFormat(d3.format("d"));
            //.ticks(5);
            //.tickValues(domain);

        yAxis = d3.svg.axis()
            .scale(yScale)
            .orient("left")
            .tickFormat(numberFormatter)
            .ticks(5);

        prefix = d3.formatPrefix(range[1]);
        if (prefix.symbol=='K') {
            symbol='k'
        } else if (prefix.symbol=='M') {
                symbol='m'
        } else if (prefix.symbol=='G') {
            symbol='bn'
        } else if (prefix.symbol=='T') {
            symbol='tn'
        }
        updateChart({init:true,keys:currentKeys,data:jsonData[currentValue],percentage:currentModePercentage});
        });

    }


    function updateChart(options)
    {
        var lineData=options.data;
        var init=options.init;
        var keys=options.keys;

        lineData.forEach(function(d,i) {
             keys.forEach(function(k){
                d[k]=+d[k];
                if (i>0) d[k+'_p']=d[k]/lineData[i-1][k]-1;
             });
        });

        if (options.percentage) {
            keys=keys.map(function(k){return k+'_p'});
            lineData=lineData.slice(1);
        }

        var domain=[null,null];
        var range=[null,null];
        lineData.forEach(function(d,i) {
             d.date = +d.date;
             if (domain[0]==null || domain[0]> d.date) domain[0]= d.date;
             if (domain[1]==null || domain[1]< d.date) domain[1]= d.date;
             keys.forEach(function(k){
                if (range[0]==null || range[0]> d[k]) range[0]= d[k];
                if (range[1]==null || range[1]< d[k]) range[1]= d[k];
            });
        });

        //if (options.percentage) domain[0]+=1;

        var toAdd=(range[1]-range[0])/10;
        range[0]-=toAdd;
        if (!options.percentage) range[0]=Math.max(0,range[0]);
        range[1]+=toAdd;
        yScale.domain(range);
        xScale.domain(domain);
        var formatter;
        if (options.percentage) {
            formatter=d3.format('.1%');
        } else {
            formatter=numberFormatter;
        }
        yAxis.tickFormat(formatter);

        var legend=d3.select('.legend');
        legend.empty();
        legend.selectAll('.item').data(keys)
            .enter().append('p').attr('class','item')
            .html(function(k){return '<i style="background:'+hash[k].color+'"></i> '+hash[k].label+' <span style="float:right;margin-right:10px;" id="'+k+'_value"></span>'});
        //legend.selectAll('.item').exit().remove();


        // get the height and width subtracting the padding
//    var innerHeight = window.innerHeight - 20;
        var innerWidth = window.innerWidth - 20;
        var divWidth=$(div).width();
        if (divWidth==0) divWidth=$(div.parentElement.parentElement).width();
        var maxWidth=parseInt($(div).css('max-width'));
        if (divWidth==0) divWidth=innerWidth*0.8;
        if (divWidth>maxWidth) divWidth=maxWidth;
        var chartWidth = divWidth-padding.left-padding.right;//960 - margin.left - margin.right,
        var chartHeight = $(div).height()-padding.top-padding.bottom;//500 - margin.top - margin.bottom;


        // only update if chart size has changed
        if (true || (prevChartWidth != chartWidth) || (prevChartHeight != chartHeight)) {
            prevChartWidth = chartWidth;
            prevChartHeight = chartHeight;

            //set the width and height of the SVG element
            chartSvg.attr("width", chartWidth + padding.left + padding.right)
                .attr("height", chartHeight + padding.top + padding.bottom);
            baseSvg.attr("width", chartWidth + padding.left + padding.right)
                .attr("height", chartHeight + padding.top + padding.bottom);

            // ranges are based on the width and height available so reset
            xScale.range([0, chartWidth]);
            yScale.range([chartHeight, 0]);




            if (init) {
                // if first run then just display axis with no transition
                chartSvg.select(".x")
                    .style({ 'stroke': 'grey', 'fill': 'none', 'stroke-width': '1px'})
                    .attr("transform", "translate(0," + chartHeight + ")")
                    .call(xAxis);

                chartSvg.select(".y")
                    .style({ 'stroke': 'grey', 'fill': 'none', 'stroke-width': '1px'})
                    .call(yAxis);

                chartSvg.select('.x.axis path').style('display','inherit');
            }
            else {
                // for subsequent updates use a transistion to animate the axis to the new position
                var t = chartSvg.transition().duration(updateTransistionMS);

                t.select(".x")
                    .attr("transform", "translate(0," + chartHeight + ")")
                    .call(xAxis);

                t.select(".y")
                    .call(yAxis);
            }

            var sourceData=lineData;

            function addSeries(key){
                var g=d3.select(this);
                var color=hash[key].color;
                var label=hash[key].label;
                var className=key;

                // bind up the data to the line
                var lines = g.selectAll("path.line")
                    .data([sourceData]); // needs to be an array (size of 1 for our data) of arrays

                var valueFunction=function(d){return d[key]};
                var yFunction=function(d){return yScale(valueFunction(d))};
                var ff=key[key.length-1]=='p' ? d3.format('.1%') : numberFormatter;
                var formatFunction=function(d){return ff(valueFunction(d))};

                function tooltipFunction(d,el){
                  var key=d3.select(el.parentElement).datum();
                  var ff=key[key.length-1]=='p' ? d3.format('.1%') : numberFormatter;
                  return d.date + ': ' + ff(d[key]);
                }

                 var line=d3.svg.line()
                      .x(function(d) { return xScale(d.date); })
                      .y(yFunction)
                      .interpolate("linear");

               // transistion to new position if already exists
                lines.transition()
                    .duration(updateTransistionMS)
                    .attr("d", line);


                // add line if not already existing
                lines.enter().append("path")
                    .attr("class", "line")
                    .attr("stroke", color)
                    .attr("stroke-width", 2)
                    .attr('fill','none')
                    .attr("d", line);

                lines.exit().remove();

                // bind up the data to an array of circles
                var circles = g.selectAll("circle")
                    .data(sourceData);

                // if already existing then transition each circle to its new position
                circles.transition()
                    .duration(updateTransistionMS)
                    .attr("cx", function (d) {
                        return xScale(d.date);
                    })
                    .attr("cy", yFunction);

                // if new circle then just display
                circles.enter().append("circle")
                    .attr("class", className)
                    .attr("cx", function (d) {
                        return xScale(d.date);
                    })
                    .attr("cy", yFunction)
                    .attr("r", 4)
                    .attr('fill', 'transparent')
                    .style("stroke", color)
                    .style("stroke-width", 8)
                    .on('mouseover',function(d){
                       d3.select('#'+this.classList[0]+'_value').text(tooltipFunction(d,this))
                    }).on('click',function(d){
                       d3.select('#'+this.classList[0]+'_value').text(tooltipFunction(d,this))
                    }).on('touch',function(d){
                       d3.select('#'+this.classList[0]+'_value').text(tooltipFunction(d,this))
                    }).on('mouseout',function(){d3.select('#'+this.classList[0]+'_value').text('')});
                circles.exit().remove();
                }
            }

            var selection=chartSvg.selectAll('g.series').data(keys);
            selection.exit().remove();
            selection.enter().append('g').attr('class','series');
            chartSvg.selectAll('g.series').each(addSeries);
    }

    // look for resize but use timer to only call the update script when a resize stops
    var resizeTimer;
    window.onresize = function(event) {
        clearTimeout(resizeTimer);
        resizeTimer = setTimeout(function()
        {
                updateChart({init:false,keys:currentKeys,data:jsonData[currentValue],percentage:currentModePercentage});
        }, 100);
    }


};
ready_for_graph();



function resetImages(){
    $('img').each(function(img){
        imgsrc = $(img).attr('src');
        if (imgsrc.slice(imgsrc.length-4)=='.gif') {
            $(img).attr('src', '');
            $(img).attr('src', imgsrc);

        }
    });
    setTimeout(function(){
        resetImages();
    },25000);
}
setTimeout(function(){
    resetImages();
},25000);

</script>

]]></content>
  </entry>
  
</feed>
