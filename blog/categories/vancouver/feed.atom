<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: vancouver | Mountain Doodles]]></title>
  <link href="http://doodles.mountainmath.ca/blog/categories/vancouver/feed.atom" rel="self"/>
  <link href="http://doodles.mountainmath.ca/"/>
  <updated>2017-08-23T22:57:58-07:00</updated>
  <id>http://doodles.mountainmath.ca/</id>
  <author>
    <name><![CDATA[MountainMath]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Density]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/08/23/density/"/>
    <updated>2017-08-23T10:15:29-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/08/23/density</id>
    <content type="html"><![CDATA[<p>Density in Vancouver has been one of the recurring themese on this blog, and there are many
different ways to come at it. We have <a href="http://doodles.mountainmath.ca/blog/2016/02/29/land-use/">looked at density in terms of land use</a>
to understand how much land is devoted to what purpose in Metro Vancouver and it&rsquo;s municipalities. We have looked
at density in terms of <a href="http://doodles.mountainmath.ca/blog/2016/03/02/property-taxes-and-land-use/">tax density</a> to
understand how property tax revenue depends on land use and zoning. We have looked at
<a href="http://doodles.mountainmath.ca/blog/2016/05/20/density/">density in terms of built floor space ratio</a>.</p>

<p>And of course we have looked at <a href="https://censusmapper.ca/maps/591">population density through CensusMapper</a>,
and this time we want to do a quick variation on that theme.</p>

<!-- more -->


<h2>Population Density</h2>

<p>Recently I have heard renewed chatter about how dense Vancouver is or is not. Before diving deepr into this it is
important to distinguish two types of density that often get mixed up.</p>

<h3>Gross Density</h3>

<p>Gross (population) density simply looks
at the total population divided by (land) area. Ignoring census undercounts, we can simply look at the 2016 census numbers
to compute these.</p>

<h3>Net Density</h3>

<p><em>Net density</em> takes residential land (instead of all land)
as it&rsquo;s base. One measure of net density is the <em>floor space ratio</em> (FSR), which we have
<a href="https://mountainmath.ca/map/assessment?zoom=13&amp;lat=49.25&amp;lng=-123.1182&amp;layer=16&amp;mapBase=2">approximated and mapped in the past</a>
and that also includes commercial space next to residential living space. More details on this are in
<a href="(http://doodles.mountainmath.ca/blog/2016/05/20/density/">this older blog post</a>).</p>

<p>Net density is typically what people refer to in the countext of building developments. Sadly it&rsquo;s hard to
get a hold of good data sources that would allow for meaningful comparisons across the country. The
provincial assessment authorities have that data, but in Canada this data only shared after significant financial
commitments.</p>

<h2>How Dense is Vancouver?</h2>

<p>How does Vancouver stack up against the rest of Canada? That, as always, depends on the details.
In particular, on whether we are talking about Metro Vancouver or the City of Vancouver, and on
what good comparables are. With the new <a href="https://github.com/mountainMath/cancensus">cancensus R package</a>
it&rsquo;s straight forward to start hacking away
at this question. Let&rsquo;s start simple by looking at the 10 census metropolitan
areas and 10 census subdivisions (cities) with the largest gross density. And to keep things
somewhat in check, let&rsquo;s only look at census subdivisions with at least 50,000 people. (If we
drop the population restriction we get the cities of Westmount, Côte-Saint-Luc, Hampstead,
and White Rock gate-crash our top 10 list.)</p>

<p><img  src="http://doodles.mountainmath.ca/images/densest_CMAs.png" style="width:49%;"><img  src="http://doodles.mountainmath.ca/images/densest_CSDs.png" style="width:49%;"></p>

<p>We see that the City of Vancouver takes the top spot among the cities, Metro Vancouver comes in
behind Toronto, Red Deer and Montréal. Great for a game of trivia, but it&rsquo;s hard to learn
much of significance from this.</p>

<p>The reason is that we don&rsquo;t know how these densities come about. Metro Vancouver contains the North Shore mountains,
a very large swath of land where nobody lives. Yet this counts to our area (or at least the horizontal projection of it).
Toronto has the green belt. How does one compare these things?</p>

<h2>Distribution of Density</h2>

<p>A good first step is to look at the distribution of density within the cities. Again <em>cancensus</em> makes it easy
to map dissemination block level density. We change gears a tiny pit and simply focus Canada&rsquo;s 9 largest (by population) cities.</p>

<p><img  src="http://doodles.mountainmath.ca/images/density_map.png" style="width:99%;margin:5px auto;"></p>

<p>The large grey areas, with fewer than 1 person per hectare, jump out immediately. As the colour gradient suggest, there
are some denser areas around the centres, but the exact extent of these are hard to grasp. A better way to get a grip on
the proportion is to abandon the geographic coordinates and show the data as a tree map.</p>

<p><img  src="http://doodles.mountainmath.ca/images/density_area.png" style="width:99%;margin:5px auto;"></p>

<p>Now we much more clearly how the density in the different cities is made up, the proportion of low and high density areas.
The grey areas, with less than 1 person per hectare, are the parks, industrial and commercial land base of the city. Areas with
fewer than 25 people per hectare are densities usually found in broad suburban sprawl. In Vancouver, Shaughnessey, Southlands, or the Drummond Drive
area of West Point Grey are examples.</p>

<p>We can see that only Toronto, Montreal and Vancouver have significant portions of land beyond the 100 people per hectare density, with
Montréal devoting a larger portion of it&rsquo;s land to that density than any other of the cities.
In Vancouver the 50 to 100 people per hectare density dominates, althoguh the cutoffs are quite arbitrary to this should not be
over-interpreted, whereas in Toronto the  1-50 and 50-100 areas are larger.</p>

<p>Instead of asking how much area is devoted to what density, we can also ask what share of the population lives in what density.</p>

<p><img  src="http://doodles.mountainmath.ca/images/density_population.png" style="width:99%;margin:5px auto;"></p>

<p>This visualizes the density as felt by the population that lives in it. Comparing Montréal and Vancouver we see that about half of Montréal&rsquo;s citizens
live in 50 ro 150 people per hectare density, whereas in Vancouver half live in 25 to 100 people per hectare density. To make up for that, Vancouver has
a much higher portion of the population living in over 300 people per hectare density than Montréal.</p>

<h2>Next Steps</h2>

<p>There are several obvious ways to expand on this. One would be to take better comparables, so instead of comparing cities one could compare
areas with similar population centred around census metropolitan area centres. Comparing Vancouver to Toronto as cities is tricky, Toronto has
a comparable population to the whole of Metro Vancouver. So a better comparison could be to take the old City of Toronto boundaries and compare
these against Toronto. Or throw Burnaby, Richmond, New Westminster and North Vancouver into the mix with the City of Vancouver.</p>

<p>With the <a href="https://github.com/mountainMath/cancensus">cancensus R package</a> this is quite easy to do. And totally reproducible,
as I have <a href="https://github.com/mountainMath/density-explorations">uploaded the R notebook I used to create all the included images to github</a>.</p>

<p>Feel free to clone or fork it and adapt it for your own purposes.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RS Population Change]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/03/06/rs-population-change/"/>
    <updated>2017-03-06T11:06:57-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/03/06/rs-population-change</id>
    <content type="html"><![CDATA[<p><a href="https://censusmapper.ca/maps/583"><img src="http://doodles.mountainmath.ca/images/pop_change_ct.png" style="width:50%;float:right;margin-left:10px;"></a>
With reporting on the new census numbers gaining traction, and now
Mayor Robertson
<a href="http://www.cbc.ca/news/canada/british-columbia/gregor-robertson-statement-vancouver-character-homes-review-1.4011100">picking up on single family neighbourhoods losing population</a>
we thought it is time to crunch some numbers.</p>

<p>Why does it need number crunching? All the reporting so far is based on looking at CT (Census Tract) aggregates, like e.g. in the
map shown and linked to the right. But there is actually no
single CT in the City of Vancouver that only contains RS zoning. Deducing results by just looking on CT aggregates can lead
to misleading reporting, like we have seen with unoccupied dwellings in the &ldquo;Marine Gateway Neighbourhood&rdquo;. Given how prominent
this topic has become it is high time to dig into the details.</p>

<h3>TL;DR</h3>

<p>In summary, we can confirm that RS (single family), RT (duplex) and FSD neighbourhoods have been dropping population.
Slightly. Looking separately at the
east and the west side, we notice that population in these neighbourhoods dropped by about 1% on the west side and increased
slightly on the east side.</p>

<p>In all groupings that we looked at the household size dropped and the rate of unoccupied dwellings increased. This was counter-acted
by a growth in dwelling units, mostly confined to RS zones where laneway houses and suites were added (or newly discovered
in the 2016 census).</p>

<p>We split the analysis into <em>core</em> regions, blocks that lie completely within RS, RT and FSD zoning, and <em>fringe</em> regions,
blocks that have RS, RT or FSD zoning as well as other zoning. Fringe regions grew in population and had overall lower rates
of unoccupied units when compared to core regions.</p>

<!-- more -->


<h3>Comparing Censuses</h3>

<p>Comparing data across censuses is hard. For one, definitions change from one census to the next
and thus variables aren&rsquo;t always comparable. Four our immediate goal of comparing
population, private dwellings, and private households between the 2011 and 2016 censuses
that is not a concern.</p>

<p>Comparing data is relatively easy when census geographies are large (i.e. CT, CSD level or higher)
and the census geography matches exactly the area that we are interested in. For CSDs (Municipalities)
this is often the case, but at the sub-municipal level, the CTs (Census Tracts) or other sub-municipal
aggregation levels rarely line up with the regions one is interested in.</p>

<p>For example, if one is interested in changes in population in RS (single family zoned) neighbourhoods in
Vancouver, looking at selected CTs will only give some initial indication. The reason is that
there is actually no CT in the City of Vancouver that is entirely RS zoned. There are several that
come close (the closest one is CT 9330015.01 around 41st and Thyne, which actually
increased population from 5,364 in 2011 to 5,485 in 2016) but it shows how tricky
it is to answer the really simple question how the population changed in RS neighbourhoods.</p>

<p>So how to deal with this issue? The cleanest way is a custom tabulation from StatCan, but that takes
time, costs money, and may still
<a href="https://twitter.com/vb_jens/status/838561779970011136">result in problems when data was not geocoded correctly</a>,
which is next to impossible to detect in custom tabulations.</p>

<p>An alternative way is to compare censuses at finer aggregation levels, that is at DAs (Dissemination Areas) or
DBs (Dissemination Blocks).</p>

<h3>Comparing Censuses at DA or DB levels</h3>

<p>For our concrete example, that means we look for DBs within RS zoning and work with these.</p>

<p>There are several difficulties with this approach. The most important is that the finer data we look at,
the more likely we pick up problems with Census data (yes, there are problems) and mistake them for real world data.
For our case through, we can avoid some of that by aggregating over all DBs within RS zoning to even out some
of these issues. Morever, we can visually inspect the data to look for any particular DB that seems to be problematic
and do some ground-truthing to see if the issues are only in the data or actually on the ground.</p>

<p>The next difficulty is technical in nature. Census geographies, including DBs and DAs, can change from one census to
another and thus may not be comparable. In order to get reliable results we need to make sure that we work with
a common set of geographies for both the 2011 and 2016 censuses. Luckily this is only a technical problem that can be
overcome as census geographies don&rsquo;t just change randomly but still retain some basic comparability.</p>

<p>And it&rsquo;s perfect timing, since we just created a &ldquo;least common denominator&rdquo; tiling derived from 2011 and 2016 DBs and DAs. At
CensusMapper we work with &ldquo;cartographic&rdquo; DBs (so we clip our major bodies of water), which leads to a minor issue where
between 2011 and 2016 things were clipped slightly differently which yielded two DBs in 2011 (with 16 and 17 people in it)
being clipped out (and having no people in it) in 2017, likely a combination of adjusting some tolerances in the StatCan
algorithms as well as some minor changes in geocoding that moved the population into an adjacent DB
(like e.g. happened with 59150971009 and 59150971008 south of King Edward split along Carnarvon). Apart from that, the
result is a tiling of Canada by DB and DA-based geographies that allow for consistent comparisons across the two censuses.</p>

<p>In numbers there were 493,192 cartographic DBs in 2016, 489,676 in 2016, and these resulted in a least common denominator tiling
by 445,953 DB-based geographies.</p>

<h3>RS, RT and FSD Zones and Population Change</h3>

<p><img src="http://doodles.mountainmath.ca/images/filter_all.png" style="width:50%;float:right;margin-left:10px;">
Back to our original question, how did population change in RS zoning. Before we go there, we think it makes more sense to expand
the question to ask for RS, RT (duplex) and FSD (First Shaughnessy) combined as these are about equally restrictive in what
we allow there.</p>

<p>Grabbing the <a href="http://data.vancouver.ca/datacatalogue/zoning.htm">latest available zoning data</a> and uploading it to
CensusMapper makes it easy to download the 2011 and 2016 dissemination blocks that intersect RS, RT and FSD zoning. We removed the RS part
that snakes along the downtown beaches and covers Stanley Park, as well as the sliver creeping up False Creek and covering the marinas there.</p>

<p>When we intersect the census data with the zones, we also compute the overlap each DB has with the zoning and disregard any region
with less than 10% overlap. Moreover we divide the dissemination blocks into <em>core</em> blocks where
the overlap is greater than 99% and <em>fringe</em> blocks, where the overlap is less than 99%.</p>

<p>One should remember that a significant
portion (a majority actually) of RS, RT and FSD dwellings are contained in &ldquo;fringe&rdquo; areas.
So it is best to focus on the rates of change, we would expect the total number of population decline
of all RS, RT and FSD zoned properties to be higher.</p>

<p>Here are the results:</p>

<pre><code>RS, RT, FSD
core: 236 DB, fringe: 475 DB
Population 2011 - 2016
core pop change: -69, fringe pop change: 6673, core total pop: 124916, fringe total pop: 284231
Dwellings 2011 - 2016
core dw change: 2812, fringe dw change: 7142, core total dw: 47008, fringe total dw: 121488
Households 2011 - 2016
core hh change: 1194, fringe hh change: 5127, core total hh: 42298, fringe total hh: 111801
</code></pre>

<p><img src="http://doodles.mountainmath.ca/images/filter_core.png" style="width:50%;float:right;margin-left:10px;">
What we see is that the population in the &ldquo;core&rdquo; DBs did drop. Slightly. At the same time the number of dwellings
increased quite noticeably by 6.3% in the core, with essentially all of the dwelling growth located within RS zones
(as opposed to RT and FSD). So most of that dwelling
growth is due to suites and laneway houses. Note that we only capture 47008 dwellings in the &ldquo;core&rdquo; RS, RT, FSD areas,
which is less
than half of the dwelling units in RS, RT and FSD with the remaining dwellings are located within the &ldquo;fringe&rdquo; regions.</p>

<p><a href="https://censusmapper.ca/maps/596"><img src="http://doodles.mountainmath.ca/images/van_pop_comp.png" style="width:50%;float:left;margin-right:10px;"></a>
Interestingly, the number of households grew much slower than the number of dwellings in the &ldquo;core&rdquo; regions, increasing the rate
of unoccupied units from 7% to 10%. Following our decomposition of population growth <a href="https://censusmapper.ca/maps/596">mapped here</a>
and <a href="http://doodles.mountainmath.ca/blog/2017/02/10/2016-census-data/">explained in more detail in a previous post</a>, we see
that the population growth of -69 in the &ldquo;core&rdquo; regions can be decomposed into:</p>

<ul>
<li>-3,699 due to declining household size,</li>
<li>-4,321 due to increase in unoccupied dwellings, and</li>
<li>7,952 due to increase in dwelling units.</li>
</ul>


<p><img src="http://doodles.mountainmath.ca/images/filter_fringe.png" style="width:50%;float:right;margin-left:10px;">
We can do the same analysis for the &ldquo;fringe&rdquo; areas, where RS, RT and FSD zoning mixes with other zones. Here we get a population
increase by 2.4%, driven by an increase
in dwelling units by 6.2%, and dampened by shrinking household size and a
more modest increase in the rate of unoccupied units from 6.7% in 2011 to 8% in 2016. We note that
the rate of unoccupied units increased significantly less on the fringe when compared to the core.</p>

<p>Breaking up the population growth of 6,673 people as before we have:</p>

<ul>
<li>-6,667 due to declining household size,</li>
<li>-3,996 due to increase in unoccupied dwellings, and</li>
<li>17,336 due to increase in dwelling units.</li>
</ul>


<h4>The West Side</h4>

<p>Lastly, we probably can&rsquo;t talk about this without running a separate analysis for the west side. So here we go.</p>

<pre><code>RS, RT, FSD
core: 88 DB, fringe: 184 DB
Population 2011 - 2016
core pop change: -510, fringe pop change: 1631, core total pop: 42878, fringe total pop: 105309
Dwellings 2011 - 2016
core dw change: 572, fringe dw change: 2426, core total dw: 16735, fringe total dw: 49210
Households 2011 - 2016
core hh change: -18, fringe hh change: 1226, core total hh: 15066, fringe total hh: 44907
</code></pre>

<p>We see that this confirms conventional wisdom that the population decline in the core areas of RS, RT, FSD is stronger
on the west side (and in fact population did increase overall in the core areas on the east side). The rate of unoccupied (by usual residents)
units was quite similar to the overall RS, RT, FSD, climbing from 6.7% in 2011 to 10% in 2016.</p>

<p>Again splitting up the population change of -510 people in the &ldquo;core&rdquo; area into components we get:</p>

<ul>
<li>-458 due to declining household size,</li>
<li>-1,587 due to increase in unoccupied dwellings, and</li>
<li>1,535 due to increase in dwelling units.</li>
</ul>


<p>For the &ldquo;fringe&rdquo; west side areas we again observe that population increased at 1.5%, dwellings by 5.1% and
the rate of unoccupied units grew slower from 6.6% to 8.7%. Splitting up the population change of 1,631 people:</p>

<ul>
<li>-1,278 due to declining household size,</li>
<li>-2,466 due to increase in unoccupied dwellings, and</li>
<li>5,376 due to increase in dwelling units.</li>
</ul>


<h3>Glossary</h3>

<p>We are a little loose with our use of language. In this post &ldquo;unoccupied&rdquo; is always short for &ldquo;not occupied by usual residents&rdquo;,
so in simpler terms &ldquo;not used as primary residence&rdquo;. &ldquo;Occupied&rdquo; refers to &ldquo;used as primary residence&rdquo;.</p>

<p>West side and east side were divided along the longitude for Ontario road.</p>

<p>Core regions are Dissemination Blocks that have at least 99% overlap with RS, RT or FSD zoning.</p>

<p>Fringe regions are Dissemination Blocks that have between 10% and 99% overlap with RS, RT or FSD zoning.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Transit Explorer]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/03/01/transit-explorer/"/>
    <updated>2017-03-01T12:10:29-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/03/01/transit-explorer</id>
    <content type="html"><![CDATA[<p><a href="https://mountainmath.ca/transit/map"><img src="http://doodles.mountainmath.ca/images/transit_vancouver.png" style="width:50%;float:right;margin-left:10px;"></a>
I have played with <a href="https://mapzen.com/documentation/mobility/isochrone/api-reference/#isochrone-service-api-reference">Mapzen&rsquo;s Isochrone serivce</a>
in the past with a simple <a href="http://doodles.mountainmath.ca/blog/2016/11/18/interactive-isochrones/">visualization of walksheds</a>.</p>

<p>Recently Mazen <a href="https://mapzen.com/blog/exclusion/">updated the isochrone API</a> to allow for a more
fine-grained selection of exactly what transit services to include
or exclude in transit routing, and they created an <a href="https://mapzen.com/mobility/explorer/">amazing mobility explorer</a>
based on that.</p>

<p>Partially motivated by chatting with two TransLink planners I decided to riff off of that and
<a href="https://mountainmath.ca/transit/map">take a look at how well TransLink serves different parts of Vancouver</a>.
At different times of day.
And how susceptible TransLink&rsquo;s network is
to Skytrain service disruptions.</p>

<!-- more -->


<p>To do this I decided to allow users to drag a location pin around that sets the start location, allow to change the time of day,
and call Mapzen&rsquo;s API to compute transit isochrones to visualize what areas can be reached
from the start location in 15, 30, 45 and 60 minutes.</p>

<p>To add some fun I made the Skytrain stations clickable, allowing the user to toggle the station status from open to closed,
so users can explore how mobility options change if a station is closed for boarding and no Skytrains pass through
any more. Essentially this cuts the transit network.</p>

<p>This does neglect bottlenecks that will emerge when alternative routes become overcrowded in the event of a skytrain failure,
and it does not take into account countermeasures by TransLink to deploy parallel buses, but it nonetheless gives
interesting conclusions about how crucial certain nodes are to the overall network.</p>

<p>Do you feel that your area is not served well enough by transit? Or under served in the evenings? Or are you worried about
what happens if the Skytrain breaks down somewhere? Just
<a href="https://mountainmath.ca/transit/map" target="_blank" class='btn btn-default'>launch the Vancouver Transit Explorer</a>
and play around to see how transit serves your needs.</p>

<p>Don&rsquo;t live in Vancouver and want to explore transit in your region? Not a problem. Use the search bar to jump to whatever city you
are interested in and click on the map to move the start location there. Then drag it around to explore that region.</p>

<p>If transit services in your city are already part of the <a href="https://transit.land/feed-registry/">TransitLand feed registry</a> that is.
If not, this visualization won&rsquo;t do you much good right now. If you are keen to use it to explore transit in your city,
just help TransitLand <a href="https://transit.land/news/2016/02/19/get-started-add-feeds.html">add your local transit agency to their feed registry</a>.</p>

<h3>Details</h3>

<p>I used settings that assume we have some happy walkers that are willing to walk quite a bit to get to and from transit, as
well as walking between stations. It seemed to me that the visualization is already overloaded with options that I did not want
to throw in another leaver.</p>

<p>The Mapzen Isochrone API also allows for routes or operators to be excluded from the calculations, so one can build more
complex &ldquo;what if&rdquo; type simulations.</p>

<p>And the service does not include bike share, which really is another piece in the whole mobility puzzle that can
significantly shorten travel time (or increase travel distance).</p>

<h3>Issues and Caveats</h3>

<p>Times after midnight may run into some issues, in some places, like e.g. Vancouver or Toronto, the early morning hour
isochrones won&rsquo;t work properly using this visualization. The technical reason seems to be that some GTFS used times past
24 hours, so 25:01 for one minute past 1AM the next day. And that breaks things somewhere. The good news is it&rsquo;s just a matter
of time for this to get fixed one way or another. But for now it&rsquo;s broken. :-(</p>

<p>Also, the tools this is built on are quite fresh. So there might be some glitches and opportunities to improve. Exciting times
when services like the isochrone API by Mapzen become publicly, and freely, available.</p>

<h3>5pm transit sheds around the world</h3>

<p><img src="http://doodles.mountainmath.ca/images/transit_vancouver.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_toronto.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_calgary.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_seattle.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_san_francisco.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_new_york.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_london.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_paris.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_melbourne.png" style="display:inline-block; width:30%; padding:1%"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[More on Teardowns]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/02/21/more-on-teardowns/"/>
    <updated>2017-02-21T10:59:27-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/02/21/more-on-teardowns</id>
    <content type="html"><![CDATA[<p><a href="https://mountainmath.ca/teardowns"><img src="http://doodles.mountainmath.ca/images/teardowns_animated.gif" style="width:50%;float:right;margin-left:10px;"></a>
A little over a year ago we ran some analysis
<a href="http://doodles.mountainmath.ca/blog/2016/01/18/redevelopment/">on teardowns</a>
of single family homes in the City of Vancouver. We used the City of Vancouver
open data to understand why some single family homes got torn down and other&rsquo;s don&rsquo;t.</p>

<p>Relying entirely on open data, there were some important questions that could not
be answered. So together with Joe Dahmen at UBC&rsquo;s School Of Architecture And Landscape Architecture
we came back to the question
and folded in transaction data from BC Assessment to add some more details and rigor.</p>

<p>The result turned out quite similar to what our initial cruder methods came
up with, but it lead to some important refinements.</p>

<p>We won&rsquo;t go into the details of the findings here, you can
<a href="https://mountainmath.ca/teardowns" target="_blank" class='btn btn-default'>read the online data story</a>
if you are interested. Instead we will go into a little more details how
the analysis was done and what is still missing.</p>

<!-- more -->


<p>The most critical piece that we added was transaction data, that is
which properties got sold in what year. Almost all properties that got
torn down were associated with a property transaction in the 4 years
around it getting torn down rebuilt.</p>

<p>This allowed us to refine the question from &ldquo;why did building A get torn
own and building B did not&rdquo; to ask the same question only considering
transacted buildings.</p>

<p>Conditioning on the most important determinant of a building getting torn down,
the transaction, we could focus in much better on what building-specific
parameters are driving teardowns.</p>

<h3>Variables</h3>

<p>We had annual assessment data pegged at July 2005 through July 2016, although
we excluded the July 2016 data for some parts of the analysis as the value
gains that year where
<a href="http://doodles.mountainmath.ca/blog/2017/01/16/2017-assessment-data/">quite extraordinary</a>
and prices have come down
a bit since then. We felt that this most recent assessment may not be a good
launching point to project the future from.</p>

<p>Unfortunately, the number of variables for teardowns that we have is
quite limited. We only have good data on assessed land values, assessed
building values and lot area. For a very small subset of about 500 buildings
we also have the building age of the building that got torn down. We have
GFA estimates for buildings that got torn down after 2009 through the
<a href="http://doodles.mountainmath.ca/blog/2016/03/05/physical-sfh-form-over-time/">analysis of LIDAR data</a>
that we did, but those estimates are quite crude and again only cover a portion of our
time frame.</p>

<p>A crucial variable that we are still missing is the actual time of the building
demolition. We inferred this from the time a new building got completed on that
property, but this inevitably introduces noise to the data. It makes it
difficult to pick the right time to calculate the relative building value. Moreover,
there may be the occasional property that got built on vacant land, so nothing got torn down.
This was less an issue for the analysis part, where we had ways to filter out such properties,
but it did cause some problems with the visualization part of the project. We did filter out
some properties manually that we could identify as being built on vacant land within
the timeframe of the visualization, namely some properties on Deering Island.</p>

<p>On top of that, the decision to demolish the building was often made long
before the building got torn down. Waiting times on demolition permits can be quite long, depending
on the property. Having access to building permit data would help sharpen
this variable. The word from the friendly open data folks is that the
City of Vancouver is working on making these public, maybe an FOI request
can help them speed up the process.</p>

<h3>Noise</h3>

<p>The most important source of noise in our data is that fact that assessment
data is only accurate <em>on average</em>. For particular buildings it can be substantially
off. We suspect that this is one of the reasons why for
buildings that are assessed to be essentially worthless,
the teardown probability tops out at a little above 60%. So someone
paying $2.5 million for a house that is worth only $10,000 to move in and live
in that house makes absolutely no sense. If the building like this did not get torn down,
we hypothesize one of three scenarios:</p>

<ol>
<li>The building was purchased as a pure investment vehicle and rented out
until an opportune time to re-develop or sell the property.</li>
<li>The assessment grossly undervalued the building.</li>
<li>The building was extensively renovated.</li>
</ol>


<p>We have looked through the data and have found little evidence that scenario 3 is
playing out in significant numbers. Extensive renovations show up in assessment
data via building value gains and the &ldquo;year improved&rdquo;. We don&rsquo;t have
data to assess the other two hypotheses.</p>

<h3>Model</h3>

<p>Given that limited variables we trained a handful of models on our data to see
how to best predict future teardowns. In all models we used, the relative
building value was the single most predictive variable, accounting for well over
80% of explanatory power no matter what methods we used. Moreover, the
performance of more complex machine learning models was not markedly better
that using a simple logistic regression. Similarly, dropping all other variables
except the relative building value only slightly decreased the skill of our
model.</p>

<p>One way to improve on our model is to use a proper survival analysis that
can better account for data that is only available for certain time frames.
For example, teardown early in our time frame suffer from the shortcoming that
we don&rsquo;t have transaction data reaching back far enough to link the teardown
to a transaction. Or more to the point, be able to compare it to other
transacted properties that didn&rsquo;t get torn down. Similar problems occur
at the end of our time frame, and with variables that are only available
in certain sub time frames.</p>

<script>
function resetImages(){
    $('img').each(function(img){
        imgsrc = $(img).attr('src');
        if (imgsrc.slice(imgsrc.length-4)=='.gif') {
            $(img).attr('src', '');
            $(img).attr('src', imgsrc);

        }
    });
    setTimeout(function(){
        resetImages();
    },25000);
}
setTimeout(function(){
    resetImages();
},25000);
</script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Jane Jacobs' Vancouver]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/01/25/jane-jacobs-vancouver/"/>
    <updated>2017-01-25T21:57:05-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/01/25/jane-jacobs-vancouver</id>
    <content type="html"><![CDATA[<p>Some time ago I saw <a href="https://twitter.com/gboeing/status/816331801266262017">Geoff Boeing&rsquo;s excellent package</a>
to generate Jane Jacobs style street grid images. It&rsquo;s lots of fun to compare different cities that way.</p>

<p>It can be hard to represent one city by one square mile, so I thought it would be neat to use this
to compare different parts of Vancouver. Some common themes emerge for the central parts,
the more outlying areas display very differnet patterns.</p>

<!-- more -->


<p>So I <a href="http://bl.ocks.org/d/88803d79ab2a3e637e2cce7fc151423d">dropped a couple of points on a map</a>, downloaded
the geojson and ran the script below. These are the results:</p>

<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Downtown.png" ><p>Downtown</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/West%20End.png" ><p>West End</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Grandview%20Woodlands.png" ><p>Grandview Woodlands</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Kitsilano.png" ><p>Kitsilano</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/North%20Vancouver.png" ><p>North Vancouver</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/New%20West.png" ><p>New West</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Surrey.png" ><p>Surrey</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Metrotown.png" ><p>Metrotown</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Richmond.png" ><p>Richmond</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/West%20Vancouver.png" ><p>West Vancouver</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Langley.png" ><p>Langley</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Port%20Moody.png" ><p>Port Moody</p></div>


<p>If you want to make your own, just grab the <a href="https://github.com/gboeing/osmnx/blob/master/examples/09-example-figure-ground.ipynb">lightly adapted</a> code below.
Yes, it is that easy.</p>

<h4>Code to generate the images</h4>

<pre><code># jane_jacobs.py
import geojson
import osmnx as ox
from IPython.display import Image
ox.config(log_file=True, log_console=True, use_cache=True)

file="data/van_cities.geojson"
img_folder = 'images'
extension = 'png'
size = 350
dpi = 90

cities=geojson.loads(open(file,"r").read())
for city in cities.features:
    place = city.properties['name']
    point = (city.geometry.coordinates[1],city.geometry.coordinates[0])
    fig, ax = ox.plot_figure_ground(point=point, filename=place)
    Image('{}/{}.{}'.format(img_folder, place, extension), height=size, width=size)
</code></pre>
]]></content>
  </entry>
  
</feed>
