<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: censusmapper | Mountain Doodles]]></title>
  <link href="http://doodles.mountainmath.ca/blog/categories/censusmapper/feed.atom" rel="self"/>
  <link href="http://doodles.mountainmath.ca/"/>
  <updated>2017-08-25T22:11:03-07:00</updated>
  <id>http://doodles.mountainmath.ca/</id>
  <author>
    <name><![CDATA[MountainMath]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[dot-density]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/08/24/dot-density/"/>
    <updated>2017-08-24T22:28:40-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/08/24/dot-density</id>
    <content type="html"><![CDATA[<p>I started writing this blog post in December 2015, when CensusMapper quite a bit younger and
I hacked together some basic dot-density maps. I never much liked the results and have been
slowly improving and thinking about them. I am still not entirely happy with the current
implementation, but it is slowly getting there. The final impulse to finsish this post was
the work on <code>cancensus</code>, and R wrapper for the CensusMapper API my explorations in multi-category
dot density maps in R, now tied up into the new <code>dotdensity</code> package.</p>

<h4>One person at a time</h4>

<p><img  src="http://doodles.mountainmath.ca/images/recent_immigrants_cropped.png" style="width:50%;float:right;margin-left:10px;">
Dot-density maps look pretty cool.
They have been <a href="https://www.google.com/search?q=dot-density+map+images&amp;client=safari&amp;rls=en&amp;tbm=isch&amp;tbo=u&amp;source=univ&amp;sa=X&amp;ved=0ahUKEwjuy9Ch6PjJAhUivXIKHWcvDb4QsAQIHA&amp;biw=1253&amp;bih=812">flying around the itnernet</a>
lately, so we have been thinking about how to offer them in CensusMapper.</p>

<p>So what&rsquo;s so great about dot-density maps? Essentially two things:</p>

<ol>
<li>They are very simple to interpret. One dot = one person is something everyone understands immediately.</li>
<li>They can show several variables at once, for example mapping both male and female cyclist like above or
<a href="http://www.nytimes.com/interactive/2015/07/08/us/census-race-map.html">mapping ethnic segregation</a>.</li>
</ol>


<p>But once one looks closer there are lots of issues that need to be dealt with.</p>

<!-- more -->


<h4>The devil is in the details</h4>

<p>As simple as the the basic dot-density promise of <em>one dot = one person</em> is, it must fundamentally remain a lie for
census maps. We simply don&rsquo;t have the level of detail that the maps suggest. We don&rsquo;t know the location of people with
the accuracy depicted in the maps, and we certainly don&rsquo;t know the categories that give the color with the accuracy
suggested in the maps.</p>

<p>That&rsquo;s the most serious drawback of dot-density maps, they often suggest a level of detail that simply isn&rsquo;t there. Does
that outweigh the advantages? For that it is useful to take a quick look at the alternative that we have been using
at CensusMapper</p>

<h4>Choropleth Maps</h4>

<p>Choropleth maps are the staple of census maps. Every census region gets colored depending on a value of a census
variable (or function derived from census variables). While this is also quite simple, in practive there are a number of
problems with that:</p>

<ol>
<li><p>Low population bias. Let&rsquo;s look at an example to see how this works. Take a
<a href="http://censusmapper.ca/maps/132?zoom=12&amp;lat=49.2462&amp;lng=-123.0761">map of the percentage of children living in poverty</a>.
We immediately see where the percentage of child poverty is high. And child poverty is a problem. But what we don&rsquo;t see
is how many poor children live in each area. So while we see the relative magnitude, we don&rsquo;t see the absolute magnitude
of the problem. So for example the <a href="http://censusmapper.ca/maps/132?zoom=17&amp;lat=49.2647&amp;lng=-123.1429">DA north-west of Broadway and Fir</a>
sports 66.7% of children living in poverty, but there are only 30 children in the area. The
<a href="http://censusmapper.ca/maps/132?zoom=17&amp;lat=49.2435&amp;lng=-123.1516">DA north-east of Arbutus and 33rd</a> has a similar rate
of 69.1%, but there are 345 children in that area. So when trying to understand child poverty in the west side of Vancouver
one should focus on the latter not the former, but on the map they appear identical. Dot-density maps do a much better
job at representing this properly as they would simply draw a dot for each child in poverty, contrasted by a dot for
each child not in poverty as <a href="http://censusmapper.ca/maps/216?zoom=13&amp;lat=49.2465&amp;lng=-123.1425">you can see here</a>. Another
way to deal with this issue is via <a href="http://doodles.mountainmath.ca/blog/2017/04/10/surprise/">a surprise map</a> which
we have explained <a href="">in a previous post</a></p></li>
<li><p>Choropleth maps are difficult to understand. If you read this far you probably have dealt with a fair share of maps
and won&rsquo;t appreciate how some people struggle understanding these. But the amount of time I have spent explaining to
journalists what they see in the <a href="http://censusmapper.ca/maps/137">halloween map of trick or treat density</a> is (torturous)
testament of the difficulties people have with these kind of maps. I don&rsquo;t think I would have gotten any questions if I
had simply use [the dot-density version] instead.</p></li>
<li><p>One can only show one variable at a time. There are ways to stretch this a little, for example
<a href="http://andywoodruff.com/blog/value-by-alpha-maps/">value by alpha maps</a> are one way around this that tackle the population
bias. Another way is the <a href="http://censusmapper.ca/maps/162">RGB maps CensusMapper has</a>. But this does not exactly make it
easier to interpret. Dot-density versions of this is certainly <a href="http://censusmapper.ca/maps/202">easier to interpret</a>
plus one is not limited by the three categories of the RGB maps.</p></li>
</ol>


<h4>Dot-Density Maps</h4>

<p>One other big challenge with dot-density maps is that they are surprisingly hard to make. Right now we at CensusMapper
just have the bare minimum in place to produce these kind of maps: A way to randomly place the required number of dots
into each geographic region colored by the given categories. Just when I was about to try myself at dot-density maps I
saw a <a href="https://twitter.com/pwramsey/status/677502052210085888">helpful tweet</a> telling me exactly what to pay attention
to, so the implementation was quick and painless. &ndash; Well, not quite, I still had to deal with issues due to polygons
clipped server side and the fact that census areas are often multi-polygons.</p>

<p> Of course I had to try this out on CensusMapper. The current implementation suffers from a number of (minor) issues though.</p>

<h4>CensusMapper Dot-Density Issues</h4>

<p><a href="https://censusmapper.ca/maps/797#12/49.2430/-123.0103"><img  src="http://doodles.mountainmath.ca/images/recent_immigrants_da.png" style="width:50%;float:right;margin-left:10px;"></a>
1. Clipping. There are still some minor issues due to clipping that can lead to the number of dots being off by a small
proportion. I won&rsquo;t bore you with the technical details, but the good news is that it can be worked out at the expense
of adding some more custom code on the client.
2. Dynamic dot-value scaling. CensusMapper maps allow for zooming from country-level down to street level. The one dot
= one person paradigm does not work very well on all scales. Visually as well as computationally. The smallest unit to
draw is one pixel (or 1 quarter of a pixel on 2x retina displays), and at some point (at the
latest when having to draw 33 million dots randomly within different regions in Canada) your browser performance will
tank. To fix this we need to dynamically adjust the value of each dot. Instead of 1 dot = 1 person it will be 1 dot =
10 people at lower zoom levels. And at higher zoom levels at some point one dot will have to start to get larger to be
more visible. Dynamically changing scales can be confusing though. As we zoom we keep the size of each dot relative to
the map constant, but if we re-scale we change the size of each dot relative to the map scale to make it clearer to the user that
wer are rescaling.
<a href="https://censusmapper.ca/maps/797#10/49.2430/-123.0103"><img  src="http://doodles.mountainmath.ca/images/recent_immigrants_ct.png" style="width:50%;float:left;margin-right:10px;"></a>
3. Non-uniform distribution of population. The current code has the problem of placing the dots randomly in each census
geography regardles of where people actually live. This goes back to the fundamental issues that dot-density maps suggest
a level of precision that simply is not there. But it definitely is odd to see dots in the Pacific Spirit Park or
<a href="https://twitter.com/mikeklassen/status/684981658013990913">camping out on Burnaby Mountain</a>.
The good news is that there is a partial fix to this. We have population counts at a finer census geometry:
Census Blocks. And at the Census
Block level we see that nobody lives in the Pacific Spirit Park, or on most of Burnaby Mountain. So to fix this we
simply need to shift the way we decide what census geography to display. This is quite difficult to fix within the
CensusMapper paradigm of highly dynamic maps where nothing is pre-computed.
4. Visual feedback on hover / select. For Choropleth maps we highlight regions on hover so that the user knows what geographic
area the variables in the legend and in the popup are for. This is something that is not too difficult to add, but we
will have to wait for the next bigger CensusMapper map refresh.</p>

<h4>Static dot-density maps</h4>

<p>Statis maps is one way where the above issues don&rsquo;t appear. And most importantly, we can fix issue 3. completely by
taking the time to weight the placement of dots by census block level data. The new
<a href="https://github.com/mountainMath/cancensus"><code>cancensus</code> R package</a> now makes it
super easy to import cenusus data into R, and we wrote a <a href="https://github.com/mountainMath/dotdensity"><code>dotdensity</code> R package</a>
to implement common functions that deal
with the usual pitfalls of multi-category dot-density maps. By moving from CensusMapper to R we trade the dynamic nature
of CensusMapper for crisper images and improved processing and dot-placement. Often we aren&rsquo;t interested in Canada-wide
maps that are the staple of CensusMapper, but only want to focus on one particular region. Or maybe a couple of regions,
and the <code>cancensus</code> and <code>dotdensity</code> packages still make it very easy to change the region and make the same map for a
different geographic region. Or make changes to the variables we want to map. In particular in conjunction with the
<a href="">CensusMapper API helper</a> that reduces the selection of geographies and variables to a couple of mouse clicks and
let&rsquo;s you copy and paste the R code to import the data through <code>cancensus</code>.</p>

<p>The dot-density package has two main functions that we use</p>

<p><code>dot_density.compute_dots</code> takes care of converting geographic shapes with counts for each category into dots. This
is fairly straight-forward, but we need to pay attention to two potential pitfalls.</p>

<ul>
<li>The order of the dots need to be
randomized so we don&rsquo;t draw all items of one particular category (colour) last, so that these end up on top and appear
more prominent than others.</li>
<li>When we scale so that 1 dot represents more than 1 unit in our category count, we need to employ statistical rounding,
not just regular rounding, otherwise the overall count of the dots may not represent the overall averages. To see this,
suppose we want to map German speakers, and we scale so that 1 dot corresponds to 50 German speakers. If German speakers
are uniformly distributed in each area so that there are 20 German speakers in each area, regular rounding will produce a
map without any German speakers at all. Statistical rounding will properly reflect the total number of German speakers,
but they will be randomly placed in each area. Not ideal, we probably should adjust our scale. But better than random
rounding. And adjusting the scale is not always an option, for example there might be one cluster of German speakers and a uniform
distribution everywhere else.</li>
</ul>


<p>The <code>dot_density.compute_dots</code> takes care of these issues under the hood. (And so does CensusMapper.)</p>

<p><code>dot_density.proportional_re_aggregate</code> takes two nested geographies, for example census subdivisions and census tracts. It will
compare counts across the geographic levels and adjust the lower-level geography counts with the more accurate higher-level data.
If lower level geographic data has been suppressed due to quality or privacy concerns the overall counts at that aggregation level
won&rsquo;t accurately reflect the overall data. The <code>dot_density.proportional_re_aggregate</code> will re-distribute the missing counts
proportionately among the lower level geographies, weighted appropriately.</p>

<p>The same function can also be used to weight the dots we want to draw by block level data, so this will produce maps that avoid
placing dots in parks or other unpopulated areas, spacing them according to population density at the block level.</p>

<h4>Examples</h4>

<p>When the data is easily accessible and well-organized, it is incredibly easy to run analysis or visualize it. In CensusMapper,
we can make dot-density maps within a matter of minutes, and with the <code>cancensus</code> and <code>dotdensity</code> packages it&rsquo;s no different in R.</p>

<p>Hear are a couple of examples, first from CensusMapper with links to the live maps, and then from the vignettes embedded into the R package.</p>

<h5>CensusMapper</h5>

<p>Occupied dwelling units by type
<a href="https://censusmapper.ca/maps/727#12/49.2719/-123.0967"><img  src="http://doodles.mountainmath.ca/images/dwellings-dot-density.png"></a></p>

<h5>R</h5>

<p>Language Spoken at Home
<img src="https://github.com/mountainMath/dotdensity/raw/master/images/vancouver-languages.png" alt="Languages" /></p>

<p>Household Size
<img src="https://github.com/mountainMath/dotdensity/raw/master/images/toronto-hh-size.png" alt="Household Size" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Density]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/08/23/density/"/>
    <updated>2017-08-23T10:15:29-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/08/23/density</id>
    <content type="html"><![CDATA[<p>Density in Vancouver has been one of the recurring themese on this blog, and there are many
different ways to come at it. We have <a href="http://doodles.mountainmath.ca/blog/2016/02/29/land-use/">looked at density in terms of land use</a>
to understand how much land is devoted to what purpose in Metro Vancouver and it&rsquo;s municipalities. We have looked
at density in terms of <a href="http://doodles.mountainmath.ca/blog/2016/03/02/property-taxes-and-land-use/">tax density</a> to
understand how property tax revenue depends on land use and zoning. We have looked at
<a href="http://doodles.mountainmath.ca/blog/2016/05/20/density/">density in terms of built floor space ratio</a>.</p>

<p>And of course we have looked at <a href="https://censusmapper.ca/maps/591">population density through CensusMapper</a>,
and this time we want to do a quick variation on that theme.</p>

<!-- more -->


<h2>Population Density</h2>

<p>Recently I have heard renewed chatter about how dense Vancouver is or is not. Before diving deepr into this it is
important to distinguish two types of density that often get mixed up.</p>

<h3>Gross Density</h3>

<p>Gross (population) density simply looks
at the total population divided by (land) area. Ignoring census undercounts, we can simply look at the 2016 census numbers
to compute these.</p>

<h3>Net Density</h3>

<p><em>Net density</em> takes residential land (instead of all land)
as it&rsquo;s base. One measure of net density is the <em>floor space ratio</em> (FSR), which we have
<a href="https://mountainmath.ca/map/assessment?zoom=13&amp;lat=49.25&amp;lng=-123.1182&amp;layer=16&amp;mapBase=2">approximated and mapped in the past</a>
and that also includes commercial space next to residential living space. More details on this are in
<a href="(http://doodles.mountainmath.ca/blog/2016/05/20/density/">this older blog post</a>).</p>

<p>Net density is typically what people refer to in the countext of building developments. Sadly it&rsquo;s hard to
get a hold of good data sources that would allow for meaningful comparisons across the country. The
provincial assessment authorities have that data, but in Canada this data only shared after significant financial
commitments.</p>

<h2>How Dense is Vancouver?</h2>

<p>How does Vancouver stack up against the rest of Canada? That, as always, depends on the details.
In particular, on whether we are talking about Metro Vancouver or the City of Vancouver, and on
what good comparables are. With the new <a href="https://github.com/mountainMath/cancensus">cancensus R package</a>
it&rsquo;s straight forward to start hacking away
at this question. Let&rsquo;s start simple by looking at the 10 census metropolitan
areas and 10 census subdivisions (cities) with the largest gross density. And to keep things
somewhat in check, let&rsquo;s only look at census subdivisions with at least 50,000 people. (If we
drop the population restriction we get the cities of Westmount, Côte-Saint-Luc, Hampstead,
and White Rock gate-crash our top 10 list.)</p>

<p><img  src="http://doodles.mountainmath.ca/images/densest_CMAs.png" style="width:49%;"><img  src="http://doodles.mountainmath.ca/images/densest_CSDs.png" style="width:49%;"></p>

<p>We see that the City of Vancouver takes the top spot among the cities, Metro Vancouver comes in
behind Toronto, Red Deer and Montréal. Great for a game of trivia, but it&rsquo;s hard to learn
much of significance from this.</p>

<p>The reason is that we don&rsquo;t know how these densities come about. Metro Vancouver contains the North Shore mountains,
a very large swath of land where nobody lives. Yet this counts to our area (or at least the horizontal projection of it).
Toronto has the green belt. How does one compare these things?</p>

<h2>Distribution of Density</h2>

<p>A good first step is to look at the distribution of density within the cities. Again <em>cancensus</em> makes it easy
to map dissemination block level density. We change gears a tiny pit and simply focus Canada&rsquo;s 9 largest (by population) cities.</p>

<p><img  src="http://doodles.mountainmath.ca/images/density_map.png" style="width:99%;margin:5px auto;"></p>

<p>The large grey areas, with fewer than 1 person per hectare, jump out immediately. As the colour gradient suggest, there
are some denser areas around the centres, but the exact extent of these are hard to grasp. A better way to get a grip on
the proportion is to abandon the geographic coordinates and show the data as a tree map.</p>

<p><img  src="http://doodles.mountainmath.ca/images/density_area.png" style="width:99%;margin:5px auto;"></p>

<p>Now we much more clearly how the density in the different cities is made up, the proportion of low and high density areas.
The grey areas, with less than 1 person per hectare, are the parks, industrial and commercial land base of the city. Areas with
fewer than 25 people per hectare are densities usually found in broad suburban sprawl. In Vancouver, Shaughnessey, Southlands, or the Drummond Drive
area of West Point Grey are examples.</p>

<p>We can see that only Toronto, Montreal and Vancouver have significant portions of land beyond the 100 people per hectare density, with
Montréal devoting a larger portion of it&rsquo;s land to that density than any other of the cities.
In Vancouver the 50 to 100 people per hectare density dominates, althoguh the cutoffs are quite arbitrary to this should not be
over-interpreted, whereas in Toronto the  1-50 and 50-100 areas are larger.</p>

<p>Instead of asking how much area is devoted to what density, we can also ask what share of the population lives in what density.</p>

<p><img  src="http://doodles.mountainmath.ca/images/density_population.png" style="width:99%;margin:5px auto;"></p>

<p>This visualizes the density as felt by the population that lives in it. Comparing Montréal and Vancouver we see that about half of Montréal&rsquo;s citizens
live in 50 ro 150 people per hectare density, whereas in Vancouver half live in 25 to 100 people per hectare density. To make up for that, Vancouver has
a much higher portion of the population living in over 300 people per hectare density than Montréal.</p>

<h2>Next Steps</h2>

<p>There are several obvious ways to expand on this. One would be to take better comparables, so instead of comparing cities one could compare
areas with similar population centred around census metropolitan area centres. Comparing Vancouver to Toronto as cities is tricky, Toronto has
a comparable population to the whole of Metro Vancouver. So a better comparison could be to take the old City of Toronto boundaries and compare
these against Toronto. Or throw Burnaby, Richmond, New Westminster and North Vancouver into the mix with the City of Vancouver.</p>

<p>With the <a href="https://github.com/mountainMath/cancensus">cancensus R package</a> this is quite easy to do. And totally reproducible,
as I have <a href="https://github.com/mountainMath/density-explorations">uploaded the R notebook I used to create all the included images to github</a>.</p>

<p>Feel free to clone or fork it and adapt it for your own purposes.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Millennials Redux]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/08/06/millennials-redux/"/>
    <updated>2017-08-06T20:54:48-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/08/06/millennials-redux</id>
    <content type="html"><![CDATA[<p>Catching up with my local news reading last night I stumbled about another
<a href="https://beta.theglobeandmail.com/real-estate/vancouver/priced-out-of-downtown-vancouver-millennials-are-building-hipsturbia/article35884038/">new report on millennials</a>.</p>

<p>The notion that millennials are fleeing Vancouver is a recurring theme in the Vancouver press, and we have addressed
some of the <a href="http://doodles.mountainmath.ca/blog/2017/05/16/lifeblood/">problems in the data used to support that claim before</a>.</p>

<p>Sadly, this new article&rsquo;s use of data is no less problematic, and the topic, as well as the data misrepresentations, are serious enough that
I felt they need addressing so as not do distract from the actual real problems that millennials are facing. Problems that are quite
different from those the 25 to 39 year old age cohort was facing 20 years ago. Groups like Generation Squeeze
have done a good job nailing some of that down in the data.</p>

<h3>The Data Rabbit Hole Trap</h3>

<!-- more -->


<p>To the data-minded person reading the article there are a number of red flags that go off throughout. Many of these can
be attributed to today&rsquo;s typical data-adverse journalism, but typically the actual hard numbers in the article hold up and are just
misrepresented to varying degrees. What got me stumbling in this article was the data chart at the bottom claiming that the 25 to 39 year old age cohort
in the &ldquo;UEL&rdquo; grew by 5% between 1996 and 2016. The UEL of course is a quasi-municipality that sits wedged between the City of Vancouver and UBC,
but many people less attuned to data and administrative details use the term to refer to various portions of the region west of the Pacific Spirit Park,
sometimes including &ldquo;Little Australia&rdquo; which is west of the Park but an actual part of the UEL and sometimes excluding it.</p>

<p>I took it to mean some version of UEL and UBC/UNA combined, and the 5% number looked suspicious to me. The population in that area more than tripled
during that period, one would expect the change in that age cohort to be much larger. So I started to dig into the numbers.</p>

<p>The first step was to look up the numbers for the City of Vancouver since there are no issues with administrative boundaries between 1996 and 2016,
just to make sure that the data was labelled correctly and it was really representing the percentage change in the number of millennials between 1996 and 2016.
But the number I got was different from the one in the article. The article lists a 10% increase, I calculated an 11% increase. 11.2% to be precise, so
there was no chance that this was a rounding issue.</p>

<p>And the data rabbit hole opens up, sucks me in and the trap closes.</p>

<h3>The Data</h3>

<p>The data is, for the most part, reasonably straight forward. I just grabbed the 1996 count of 25 to 39 year olds, then the 2016 counts and compared them.
One problem is boundary changes. Administrative boundaries don&rsquo;t stay fixed. And boundary changes don&rsquo;t always show up when just looking at non-geographic
data, names or even the uniqe geographic identifiers don&rsquo;t necessarily change when census boundaries change. Looking that the geographic data for both
censuses one immediately notices that the UEL/UBC/UNA area changed a lot (and also got new geographic identifiers), and Coquitlam changed too.
That complicates things a little, the UEL/UBC/UNA part is easy enough to deal with. In 1996 that area was called the &ldquo;University Endowment Area&rdquo;, in 2016
that same area can be obtained by adding to census tracts. Coquitlam is a little trickier and I wasn&rsquo;t interested enough in figuring out the details so
I decided to ignore it.</p>

<p>Step one, trying to reproduce the graph in the newspaper, is below with blue bars, with the graph from the newspaper in red bars for reference.</p>

<div class="half-image"><a href="http://doodles.mountainmath.ca/images/millennial_grap_1.png"><img src="http://doodles.mountainmath.ca/images/millennial_grap_1.png" ><p>News Story</p></a></div>


<div class="half-image"><a href="http://doodles.mountainmath.ca/images/millennial_grap_2.png"><img src="http://doodles.mountainmath.ca/images/millennial_grap_2.png" ><p>Actual Data</p></a></div>


<p>There is definitely a correspondence between the graphs, but the numbers don&rsquo;t quite match up. I have no idea how the &ldquo;UEL&rdquo; numbers were derived for
the article. But I have an explanation for the difference in the other municipality&rsquo;s numbers. Looking at the graphs
suggests that a larger denominator was used in the article, and indeed the numbers match up perfectly if I were to divide the
difference of population in the 25-39 year
old cohort by the 2016 number instead of the 1996 number. An embarrassing data mistake to be sure, but nothing out of the ordinary for today&rsquo;s
news stories.</p>

<p>I can&rsquo;t explain why Surrey, the city with the largest gain in millennials, was dropped from the data used for the story.</p>

<h3>Data Representation</h3>

<p>But these data problems are really only a side show to the real issue.
The most important question is what data to use for what purpose. The article chose to use the change in the total number of millennials
to support the notion that the 25 to 39 year old cohort are shunning the City of Vancouver for some of the more outlying regions.
The obvious issue with that
is that that measure is confounded by population growth. If the population is growing, so will the number of millennials,
even if the share of millennials
in the population did not change. For this story, this is clearly a very poor choice of data representation.</p>

<p><a href="http://doodles.mountainmath.ca/images/millennial_grap_3.png"><img  src="http://doodles.mountainmath.ca/images/millennial_grap_3.png" style="width:50%;float:right;margin-left:10px;"></a>
As a first approximation to understanding where that age cohort settles in 2016 compared to 1996 one can look at the respective shares of the
population in those age cohorts. The only problem, the pretext of the story goes away when one represents the data in this way.</p>

<p>What stands out is that the share of 25-39 year olds dropped in all areas. Some of that is just part of the
changing makeup of the population in general. And
one sees that the City of Vancouver not only has the highest share of 25-39 year olds, it also experienced the lowest drop.</p>

<p>One should probably also look at other age cohorts to better understand how the population is changing. And compare this to other regions
to try and distinguis Vancouver-specific trends from more general Canada-wide ones.</p>

<h3>Framing of the Data</h3>

<p>The other part of the story that irks me is the deep confusion and free mixing of two different concepts. One is that of migration, that is
(the same) people moving from one area to another over some time period. The other is that of the number or share of (different)
people in a secific age cohort at two distinct points in time. Nathan Lauster has added some very
<a href="https://homefreesociology.wordpress.com/2016/02/12/is-the-lifeblood-of-vancouver-leaving/">good analysis</a> to this topic, and has
followed up with a series of blog posts. And this was picked up in various news articles too.</p>

<p>This article not only lacks appreciation for this important distinction by talking about &ldquo;migration&rdquo; when really comparing age cohorts, but
it takes it to the next level by talking about &ldquo;millennials&rdquo; as being 25-39 year old in 1996 (as well as in 2016), which is
comically absurd.</p>

<p>Not sure what to make of the authors assertion that BC Assessment is in the business of enumerating 25 to 39 year olds between 1996 and 2016,
I wonder how people get stuff like this past their editors.</p>

<p>The larger storyline is still important here, as Vancouver grows up from a city with surrounding suburbs into an integrated metropolitan area.
And a new generation,
spurred on by new challenges, including housing affordability, accelerating that transformation and re-defining what some of these former suburbs into
hip local centres that are tied together by a growing transit system.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lifeblood]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/05/16/lifeblood/"/>
    <updated>2017-05-16T13:52:05-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/05/16/lifeblood</id>
    <content type="html"><![CDATA[<p><a href="https://censusmapper.ca/maps/731"><img src="http://doodles.mountainmath.ca/images/net_animated.gif" style="width:50%;float:right;margin-left:10px;"></a>
Ever since that <a href="https://www.bloomberg.com/news/articles/2016-03-14/millennials-flee-vancouver-for-cities-with-more-affordable-homes">Bloomberg article whose claims nobody could reproduce</a>,
where the author refused to disclose what data was used, but that
got recycled all across the local press there has been a hightened interest
in migration patterns in Vancouver. Nathan Lauster took it upon himself to
dig deeper and look if <a href="https://homefreesociology.wordpress.com/2016/02/12/is-the-lifeblood-of-vancouver-leaving/">Vancouver&rsquo;s lifeblood was really leaving</a>,
which he kept elaborating on as better data became available until the
<a href="https://homefreesociology.wordpress.com/2017/05/05/good-age-specific-net-migration-estimates-come-in-threes/">most recent iteration</a>
that compares Metro Vancouver to other Candian metropolitan areas as well
as the City of Vancouver to other cities within Metro Vancouver using 2016 census data.</p>

<p>This is seriously good work and we thought it would be helpful to reproduce Lauster&rsquo;s methods
in CensusMapper. The result is a series of maps, one for each five-year age cohort, that
visualized net migration of the cohort geographically, while hovering over a
region reproduces Lauster&rsquo;s net migration bar graph for that region.</p>

<!-- more -->


<p>With CensusMapper, we instantly get the ability to dig into areas to observe
finer net migration patterns, and to pan across the country to compare different
regions.</p>

<p>For Metro Vancouver, we can see how we have strong net in-migration in all younger
cohorts, including children. And as Lauster observed, we see a net out-migration
of 50 to 60 year olds.</p>

<p>For the City of Vancouver we see a net in-migration for 5 to 30 year olds, with
basically all other age groups exhibiting net out-migration. This is echoed by
Burnaby and New Westminster, and to a lesser extend Richmond. We can zoom in
further to the Census Tract level to observe spacial patterns of net migration
at the sub-municipal level. There we see that net migration of the under 5 cohort
and the 20 to 24 cohort are almost exact mirror images. The strongest signal
comes from the town centres of the region, that get flooded as the 20 to 24 year
old cohort ages into the 25 to 29 year old cohort. As they form families and have kids,
the flood reverses and as many children that under 5 that lived in these areas don&rsquo;t
live there any more when they advance to the 5 to 9 cohort.</p>

<p>Sadly we don&rsquo;t have common tiles for other censuses that would allow for hassle-free
comparisons to detect changes over time. (It&rsquo;s a surprising amount of work
to get those common tilings right.) But we can compare this pattern to other
population centres in Canada, and this trend seems to hold true universally.</p>

<div class="half-image"><img src="http://doodles.mountainmath.ca/images/net_van.png" ><p>Vancouver</p></div>


<div class="half-image"><img src="http://doodles.mountainmath.ca/images/net_tor.png" ><p>Toronto</p></div>


<div class="half-image"><img src="http://doodles.mountainmath.ca/images/net_mon.png" ><p>Montreal</p></div>


<div class="half-image"><img src="http://doodles.mountainmath.ca/images/net_cal.png" ><p>Calgary</p></div>


<p>Metro Vancouver as a region certainly looks quite healthy in terms of the net migration of it&rsquo;s age groups.
The migration patterns within the region also seem to be consistent with other population centres in Canada.
These alone, at least at the qualitative level that we are mapping, does not seem to explain the
prevalent feeling of millennials &ldquo;fleeing&rdquo; Vancouver. Maybe a more quantitative approach could
dig up more. Or it could be that families moving away from the central regions is generally
perceived as a &ldquo;move up&rdquo; in most cities, but in Vancouver it is viewed as &ldquo;moving down&rdquo;.</p>

<h3>Technical Details</h3>

<h4>Common Geographies</h4>

<p>The first (and biggest) problem is that the 2011 and 2016 census geographies
don&rsquo;t necessarily match up. But we <a href="http://doodles.mountainmath.ca/blog/2017/03/22/comparing-censuses/">solved that problem</a>
for the 2011 and 2016 censuses.</p>

<h4>Easier said than done</h4>

<p>The devil is of course always in the details, and as usual it is not until
one has reproduced something until one can fully appreciate the work that
went into the original piece. There were two main challenges for us to
reproduce this within CensusMapper.</p>

<h4>The basics</h4>

<p>What is net migration? To compute the net migration for an age group,
say the &ldquo;under 5&rdquo; (in 2011) age group, we want to compare them to an age
group in 2016. To do that we need to &ldquo;age them forward&rdquo;. Children that were
under 5 in 2011 were 5 to 9 years old in 2016. But some, in the case of
the under 5 age group only a very small fraction, won&rsquo;t have lived to 2016.
So we need to subtract those out. More formally, we need to apply the
apporpriate mortality rates as we age them forward. Then we compare
the aged-forward group to the 5 to 9 year old cohort that the 2016 census
counted, and we divide by the size of the original under 5 year old cohort
(from 2011) to get the percentage net migration.</p>

<h4>Mortality</h4>

<p>This basic fact of life makes net migration really tricky to get right.
Once we get into the older age groups, and thus higher mortality rates,
the process is extremely sensitive to changes in the mortality rates. In
CensusMapper we are using effective mortality rates of 5 year cohorts from
<a href="http://www5.statcan.gc.ca/cansim/a26?lang=eng&amp;id=1020504">CANSIM</a> for
Canada as a whole and the provinces and territories. A fair amount of
massaging is needed to make sure this works properly, in particular it
is important to interpolate the effective mortality rates as we age a
cohort forward. And one should recognise that the mortality rates are
based on the age at death, but that an age cohort in the census is, on average,
already half way through a given year in their life.</p>

<p>Additionally, there is little reason to believe that there is no geographic
variation in mortality rates within the provinces. To deal with that we
decided to add an uncertainty band to the graph that allows for a 5%
variation in mortality rates.</p>

<h4>Uncertainty</h4>

<p>The next issue is that census data underwent random rounding to an adjacent
number that&rsquo;s divisible by 5, which leads to an expected error of 1.6.
(Actual rounding gives an expected error of 1.2.)
When taking differences between censuses, that yields an expected error of 2.2.
Additionally, we don&rsquo;t know the actual number of people in each age group,
just the one the census found. The &ldquo;census undercount&rdquo; can be quite
sizable. Overall it is around 3%, but it varies by age group and geography.</p>

<p>To deal with this we add an error term of a mis-count of 5 people that
also shows up in our error bars in the graph.</p>

<h4>Fine geographies</h4>

<p>CensusMapper is great for exploring all geographic levels. But that can
lead to problems when our age cohorts become small in size. We divide
by the size of the original 2011 age group cohort, and to avoid running
into small denominator issues we cut our estimates off when there are
fewer than 50 people in a cohort. Our error bars partially take care of
this issue, but at 50 people our error bar already spans 10% points of
net migration on either side of the computed value, showing values with
even larger error bars is likely to do more harm than good.</p>

<script>
function resetImages(){
    $('img').each(function(img){
        imgsrc = $(img).attr('src');
        if (imgsrc.slice(imgsrc.length-4)=='.gif') {
            $(img).attr('src', '');
            $(img).attr('src', imgsrc);

        }
    });
    setTimeout(function(){
        resetImages();
    },35000);
}
setTimeout(function(){
    resetImages();
},35000);
</script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Surprise Maps]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/04/10/surprise/"/>
    <updated>2017-04-10T08:43:58-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/04/10/surprise</id>
    <content type="html"><![CDATA[<p><a href="https://censusmapper.ca/maps/668"><img src="http://doodles.mountainmath.ca/images/surprise.png" style="width:50%;float:right;margin-left:10px;"></a>
At CensusMapper we like building models based on census data. We now
have a <a href="http://doodles.mountainmath.ca/blog/2017/03/22/comparing-censuses/">common tiling for 2011 and 2016 geographies</a>
that allows us to easily model changes over time. After building a model
we often want to see how well the model performs. An easy way to do this is to
simply map the difference of observations and model predictions.</p>

<p>Those maps are great and it is easy to understand what is mapped. But they are difficult to interpret properly. In many cases
a better metric to map is how consistent the observations in each region are with the model. Which brings us to Bayesian surprise maps.</p>

<!-- more -->


<p>There is a <a href="https://medium.com/@uwdata/surprise-maps-showing-the-unexpected-e92b67398865">great post</a> making the rounds on the
web, and when it recently <a href="https://twitter.com/LGeospatial/status/850806648201388032">showed up again in my Twitter feed</a>
I finally decided to get in on the fun.</p>

<h3>The Problem</h3>

<p><a href="https://censusmapper.ca/maps/584#15/49.2089/-123.1141"><img src="http://doodles.mountainmath.ca/images/marine_gateway_nbhd.png" style="width:50%;float:left;margin-right:10px;"></a>
To understand why surprise maps can be so useful, let&rsquo;s look a a concrete example. Suppose we want to understand dwelling units
that are not used as primary residences. (And incidentally it seems that everyone currently living in Vancouver or Toronto wants to do this.) To
that end we can simply consult <a href="https://censusmapper.ca/maps/584">the map of these</a> based on the 2016 census. As we try and
understand better what is happening in each region and we zoom in more and more we start to run into issues. Consider
<a href="https://censusmapper.ca/maps/584#15/49.2089/-123.1141">this example looking at the Marine Gateway neighbourhood in Vancouver</a>. We
see two areas coloured in dark blue, indicating a high rate. The left is the site of the MC2 development that got completed
just before the census and we discussed <a href="http://doodles.mountainmath.ca/blog/2017/04/03/joyce-collingwood/">earlier in detail</a>.
The right one is a large area with exactly one private dwelling unit, which happens not to be a primary residence for anyone. If
someone did use it as primary residence it would show up on the other extreme end of our colour spectrum. Either way, it does not
really give much useful information, it is mostly a distraction that takes attention away from MC2 that has a more important story
to tell.</p>

<p>More generally, areas with very low dwelling counts are much more likely to see high variations of rates of non-permanent residence buildings
purely for statistical reasons. This results in a <a href="https://censusmapper.ca/maps/584#16/49.2425/-123.1777">&ldquo;checkerboard&rdquo; pattern</a>
that is mostly due to statistical noise and hides meaningful variations in the data.</p>

<h3>Surprise maps</h3>

<p><a href="https://censusmapper.ca/maps/669#15/49.2089/-123.1141"><img src="http://doodles.mountainmath.ca/images/marine_gateway_nbhd2.png" style="width:50%;float:right;margin-left:10px;"></a>
That&rsquo;s were surprise maps come in. As a first step, instead of colouring by the rate of non-primary residence dwellings,
let&rsquo;s colour by how this rate differs from our expectations. So we re-interpret our original map as mapping the difference from expectations
where the expectation is that all dwellings are used as primary residences. Alternatively we can also take the regional average
rate of non-primary residence dwellings and map the deviation from the average. Or we could build a
<a href="https://censusmapper.ca/maps/669">more elaborate model</a> using the 2011 rates and the Canada-wide average rates per net new dwelling unit.</p>

<p>Either way, what we are doing here is we make a guess what we think the rate of non-primary residence units should be in each area
and we compare it with observations. The better our guess is, the stronger the &ldquo;checkerboard&rdquo; pattern will become as the residuals
will be reduced to statistical noise. This as can easily be seen when
<a href="https://censusmapper.ca/maps/669#16/49.2425/-123.1777">comparing the more advanced model</a>
to the <a href="https://censusmapper.ca/maps/584#16/49.2425/-123.1777">checkerboard observed using the &ldquo;zero&rdquo; model</a>. In practice that
means that we have to click into each region to see the number of dwelling units, as well as the rate, to understand how we want
to interpret the result. Through this labour intensive process we will then weed out the area with just 1 dwelling unit and ignore
it.</p>

<p>Surprise maps don&rsquo;t map the actual difference of model and observation, they map how consistent the model is with the observation
in each area. In our initial example of an area with only one dwelling unit in it, no matter if that unit is used as
primary residence or not, this cannot be taken as strong evidence that our model is wrong. We should assign this a neutral colour.
The MC2 development on the other hand contained 570 dwelling units in 2016, a large deviation from the model indicates that
our model prediction might have some problems for that region.</p>

<p>In surprise maps, we colour each area by the amount of evidence observations in a that area gives against our model. To have good evidence
against our model, observations should deviate from model prediction, and we should be able to exclude regular statistical noise as
a cause for this.</p>

<p>For this example, we chose a mixture of the &ldquo;base rate&rdquo; and &ldquo;de Moivre funnel&rdquo; models
<a href="http://idl.cs.washington.edu/files/2017-SurpriseMaps-InfoVis.pdf">described in this excellent paper</a> where we essentially modify
the de Moivre funnel model by allowing an arbitrary model to take the place of the average of our variable. We also keep track
of the sign of the evidence we collect against our model, so whether our model underpredicted or overpredicted the rate of
non-primary residence dwelling units.</p>

<p><a href="https://censusmapper.ca/maps/668#15/49.2089/-123.1141"><img src="http://doodles.mountainmath.ca/images/marine_gateway_nbhd3.png" style="width:50%;float:left;margin-right:10px;"></a>
The <a href="https://censusmapper.ca/maps/668">result is a map that makes it much easier to sport &ldquo;surprising&rdquo; areas</a>,
that is areas where observations provide good evidence
that our model does not hold well there.</p>

<p>We can now go back to check the <a href="https://censusmapper.ca/maps/668#16/49.2425/-123.1777">Marine Gateway area</a> we looked at before,
and we see that the only areas that contribute solid evidence against our model are the unexpectedly high rates at the MC2 development,
as well as the unexpectedly low rates at the area to the east between Main and Frasier streets.</p>

<h3>Surprise Maps in CensusMapper</h3>

<p><a href="https://censusmapper.ca/maps/671"><img src="http://doodles.mountainmath.ca/images/child_poverty_surprise.png" style="width:50%;float:right;margin-left:10px;"></a>
We baked these kind of surprise maps into CensusMapper, so now we can easily apply this to any other kind of observable.</p>

<p>The CensusMapper surprise maps that are implemented right now require as input a &ldquo;model&rdquo; , an &ldquo;observation&rdquo; a &ldquo;base&rdquo; variable
(the number of dwelling units, averaged over the 2011 and 2016 censuses in our case) and a standard deviation of the difference
between model and predictions. For now, that standard deviation will have to be entered manually for technical reasons.
Moreover, other parameters like estimates of accuracy of census counts as well ask statistical rounding and other
operations that may have been performed on the data, can be added in to account for the fact that the rate observed in the census
is different from the actual rate. We added the ability to make the standard deviation region dependent, which allows us to
account for estimates of the accuracy of the census data based on region dependent variables.</p>

<p>For a simple example what this might look like consider child poverty. We have
<a href="https://censusmapper.ca/maps/132">mapped this variable in CensusMapper</a>, but at times
it can be hard to distill out the really important areas that have high child poverty rates as well as a high number of
children overall.
We have added a scatter plot of the rate vs the total number of children in poverty to the
map story, so that the user can more easily determine how significant a high child poverty rate in each particular region is.</p>

<p>Reliability of the data can also be tainted by low NHS return rates,
so CensusMapper maps automatically shade to regions that have particularly low NHS return rates
(and similarly for the full census return rates) to give some indication of reliability,
and we display the return rate on hover. But it is cumbersome to keep track of all this information.</p>

<p>Another way to deal with these issues is to make a <a href="https://censusmapper.ca/maps/671">child poverty surprise map</a>.
As model we can simply use the assumption that there
are zero children in poverty in each area. We scale the standard deviation of the child poverty rate linearly by the return rate
to weight down areas with low return rate. The result is a map that colours each region by the amount of evidence they provide
against the model assumption of zero children in poverty.</p>

<p>This makes it easier to filter out regions that have a low number
of children overall, where high rates of child poverty might just be a statistical fluke.</p>

<h3>Where to go from here</h3>

<p>Should all maps be surprise maps? No, there is value in just mapping straight up census variables, or mapping plain differences
of observations from the model. But there are many good reasons why such maps should be complemented,
or in some cases even replaced by, surprise maps.</p>

<p>Some kind of automation to aid the selection of appropriate standard deviation for the surprise model is needed before we can
open this up to a wider user base. Or CensusMapper server has an R server running that ties directly into the database and
communicates with the web server, so we need to build the appropriate scripts that can automate this task.</p>

<p>Another logical extension is to include proximity data into the Bayesian estimates. If one Census Tract provides good evidence
against our model, but that evidence is distributed uniformly across Dissemination Areas within it, then our surprise map
will show weaker evidence at the dissemination area level simply because each area has a smaller base population. But we could
check if the deviation from the model is localized in just one Dissemination Area, or also present in neighbouring
Dissemination Areas, and include that information in our estimates. This approach would also help with the problem if the evidence
is concentrated in an area that is split between to Census Tracts and drowned out by outher data in these respective tracts. So
it won&rsquo;t show up at the Census Tract level because of the particular ways the boundaries were drawn (MAUP), and it will get
diluted out at the Dissemination Area level because of low base population counts. Adding in proximity measures could recover
this evidence at the Dissemination Area level.</p>

<p>There are lots of other interesting possibilities of using surprise maps while leveraging the dynamic nature of CensusMapper.
One may allow for several models and let
relative importance of the models self-adjust with the map view. The output would then be for each map view a linear combination
of the models that provides the best fit for the current map view, as well as the evidence each region in the current map view provides
against the model.</p>

<p>We will keep experimenting with surprise models and at some point open up some of it&rsquo;s capabilities to a wider group
of CensusMapper users.</p>
]]></content>
  </entry>
  
</feed>
