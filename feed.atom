<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Mountain Doodles]]></title>
  <link href="http://doodles.mountainmath.ca/feed.xml" rel="self"/>
  <link href="http://doodles.mountainmath.ca/"/>
  <updated>2017-03-03T10:27:14-08:00</updated>
  <id>http://doodles.mountainmath.ca/</id>
  <author>
    <name><![CDATA[MountainMath]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Transit Explorer]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/03/01/transit-explorer/"/>
    <updated>2017-03-01T12:10:29-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/03/01/transit-explorer</id>
    <content type="html"><![CDATA[<p><a href="https://www.mountainmath.ca/transit/map"><img src="http://doodles.mountainmath.ca/images/transit_vancouver.png" style="width:50%;float:right;margin-left:10px;"></a>
I have played with <a href="https://mapzen.com/documentation/mobility/isochrone/api-reference/#isochrone-service-api-reference">Mapzen&rsquo;s Isochrone serivce</a>
in the past with a simple <a href="http://doodles.mountainmath.ca/blog/2016/11/18/interactive-isochrones/">visualization of walksheds</a>.</p>

<p>Recently Mazen <a href="https://mapzen.com/blog/exclusion/">updated the isochrone API</a> to allow for a more
fine-grained selection of exactly what transit services to include
or exclude in transit routing, and they created an <a href="https://mapzen.com/mobility/explorer/">amazing mobility explorer</a>
based on that.</p>

<p>Partially motivated by chatting with two TransLink planners I decided to riff off of that and
<a href="https://mountainmath.ca/transit/map">take a look at how well TransLink serves different parts of Vancouver</a>.
At different times of day.
And how susceptible TransLink&rsquo;s network is
to Skytrain service disruptions.</p>

<!-- more -->


<p>To do this I decided to allow users to drag a location pin around that sets the start location, allow to change the time of day,
and call Mapzen&rsquo;s API to compute transit isochrones to visualize what areas can be reached
from the start location in 15, 30, 45 and 60 minutes.</p>

<p>To add some fun I made the Skytrain stations clickable, allowing the user to toggle the station status from open to closed,
so users can explore how mobility options change if a station is closed for boarding and no Skytrains pass through
any more. Essentially this cuts the transit network.</p>

<p>This does neglect bottlenecks that will emerge when alternative routes become overcrowded in the event of a skytrain failure,
and it does not take into account countermeasures by TransLink to deploy parallel buses, but it nonetheless gives
interesting conclusions about how crucial certain nodes are to the overall network.</p>

<p>Do you feel that your area is not served well enough by transit? Or under served in the evenings? Or are you worried about
what happens if the Skytrain breaks down somewhere? Just
<a href="https://mountainmath.ca/transit/map" target="_blank" class='btn btn-default'>launch the Vancouver Transit Explorer</a>
and play around to see how transit serves your needs.</p>

<p>Don&rsquo;t live in Vancouver and want to explore transit in your region? Not a problem. Use the search bar to jump to whatever city you
are interested in and click on the map to move the start location there. Then drag it around to explore that region.</p>

<p>If transit services in your city are already part of the <a href="https://transit.land/feed-registry/">TransitLand feed registry</a> that is.
If not, this visualization won&rsquo;t do you much good right now. If you are keen to use it to explore transit in your city,
just help TransitLand <a href="https://transit.land/news/2016/02/19/get-started-add-feeds.html">add your local transit agency to their feed registry</a>.</p>

<h3>Details</h3>

<p>I used settings that assume we have some happy walkers that are willing to walk quite a bit to get to and from transit, as
well as walking between stations. It seemed to me that the visualization is already overloaded with options that I did not want
to throw in another leaver.</p>

<p>The Mapzen Isochrone API also allows for routes or operators to be excluded from the calculations, so one can build more
complex &ldquo;what if&rdquo; type simulations.</p>

<p>And the service does not include bike share, which really is another piece in the whole mobility puzzle that can
significantly shorten travel time (or increase travel distance).</p>

<h3>Issues and Caveats</h3>

<p>Times after midnight may run into some issues, in some places, like e.g. Vancouver or Toronto, the early morning hour
isochrones won&rsquo;t work properly using this visualization. The technical reason seems to be that some GTFS used times past
24 hours, so 25:01 for one minute past 1AM the next day. And that breaks things somewhere. The good news is it&rsquo;s just a matter
of time for this to get fixed one way or another. But for now it&rsquo;s broken. :-(</p>

<p>Also, the tools this is built on are quite fresh. So there might be some glitches and opportunities to improve. Exciting times
when services like the isochrone API by Mapzen become publicly, and freely, available.</p>

<h3>5pm transit sheds around the world</h3>

<p><img src="http://doodles.mountainmath.ca/images/transit_vancouver.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_toronto.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_calgary.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_seattle.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_san_francisco.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_new_york.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_london.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_paris.png" style="display:inline-block; width:30%; padding:1%">
<img src="http://doodles.mountainmath.ca/images/transit_melbourne.png" style="display:inline-block; width:30%; padding:1%"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[More on Teardowns]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/02/21/more-on-teardowns/"/>
    <updated>2017-02-21T10:59:27-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/02/21/more-on-teardowns</id>
    <content type="html"><![CDATA[<p><a href="https://www.mountainmath.ca/teardowns"><img src="http://doodles.mountainmath.ca/images/teardowns_animated.gif" style="width:50%;float:right;margin-left:10px;"></a>
A little over a year ago we ran some analysis
<a href="http://doodles.mountainmath.ca/blog/2016/01/18/redevelopment/">on teardowns</a>
of single family homes in the City of Vancouver. We used the City of Vancouver
open data to understand why some single family homes got torn down and other&rsquo;s don&rsquo;t.</p>

<p>Relying entirely on open data, there were some important questions that could not
be answered. So together with Joe Dahmen at UBC&rsquo;s School Of Architecture And Landscape Architecture
we came back to the question
and folded in transaction data from BC Assessment to add some more details and rigor.</p>

<p>The result turned out quite similar to what our initial cruder methods came
up with, but it lead to some important refinements.</p>

<p>We won&rsquo;t go into the details of the findings here, you can
<a href="https://mountainmath.ca/teardowns" target="_blank" class='btn btn-default'>read the online data story</a>
if you are interested. Instead we will go into a little more details how
the analysis was done and what is still missing.</p>

<!-- more -->


<p>The most critical piece that we added was transaction data, that is
which properties got sold in what year. Almost all properties that got
torn down were associated with a property transaction in the 4 years
around it getting torn down rebuilt.</p>

<p>This allowed us to refine the question from &ldquo;why did building A get torn
own and building B did not&rdquo; to ask the same question only considering
transacted buildings.</p>

<p>Conditioning on the most important determinant of a building getting torn down,
the transaction, we could focus in much better on what building-specific
parameters are driving teardowns.</p>

<h3>Variables</h3>

<p>We had annual assessment data pegged at July 2005 through July 2016, although
we excluded the July 2016 data for some parts of the analysis as the value
gains that year where
<a href="http://doodles.mountainmath.ca/blog/2017/01/16/2017-assessment-data/">quite extraordinary</a>
and prices have come down
a bit since then. We felt that this most recent assessment may not be a good
launching point to project the future from.</p>

<p>Unfortunately, the number of variables for teardowns that we have is
quite limited. We only have good data on assessed land values, assessed
building values and lot area. For a very small subset of about 500 buildings
we also have the building age of the building that got torn down. We have
GFA estimates for buildings that got torn down after 2009 through the
<a href="http://doodles.mountainmath.ca/blog/2016/03/05/physical-sfh-form-over-time/">analysis of LIDAR data</a>
that we did, but those estimates are quite crude and again only cover a portion of our
time frame.</p>

<p>A crucial variable that we are still missing is the actual time of the building
demolition. We inferred this from the time a new building got completed on that
property, but this inevitably introduces noise to the data. It makes it
difficult to pick the right time to calculate the relative building value. Moreover,
there may be the occasional property that got built on vacant land, so nothing got torn down.
This was less an issue for the analysis part, where we had ways to filter out such properties,
but it did cause some problems with the visualization part of the project. We did filter out
some properties manually that we could identify as being built on vacant land within
the timeframe of the visualization, namely some properties on Deering Island.</p>

<p>On top of that, the decision to demolish the building was often made long
before the building got torn down. Waiting times on demolition permits can be quite long, depending
on the property. Having access to building permit data would help sharpen
this variable. The word from the friendly open data folks is that the
City of Vancouver is working on making these public, maybe an FOI request
can help them speed up the process.</p>

<h3>Noise</h3>

<p>The most important source of noise in our data is that fact that assessment
data is only accurate <em>on average</em>. For particular buildings it can be substantially
off. We suspect that this is one of the reasons why for
buildings that are assessed to be essentially worthless,
the teardown probability tops out at a little above 60%. So someone
paying $2.5 million for a house that is worth only $10,000 to move in and live
in that house makes absolutely no sense. If the building like this did not get torn down,
we hypothesize one of three scenarios:</p>

<ol>
<li>The building was purchased as a pure investment vehicle and rented out
until an opportune time to re-develop or sell the property.</li>
<li>The assessment grossly undervalued the building.</li>
<li>The building was extensively renovated.</li>
</ol>


<p>We have looked through the data and have found little evidence that scenario 3 is
playing out in significant numbers. Extensive renovations show up in assessment
data via building value gains and the &ldquo;year improved&rdquo;. We don&rsquo;t have
data to assess the other two hypotheses.</p>

<h3>Model</h3>

<p>Given that limited variables we trained a handful of models on our data to see
how to best predict future teardowns. In all models we used, the relative
building value was the single most predictive variable, accounting for well over
80% of explanatory power no matter what methods we used. Moreover, the
performance of more complex machine learning models was not markedly better
that using a simple logistic regression. Similarly, dropping all other variables
except the relative building value only slightly decreased the skill of our
model.</p>

<p>One way to improve on our model is to use a proper survival analysis that
can better account for data that is only available for certain time frames.
For example, teardown early in our time frame suffer from the shortcoming that
we don&rsquo;t have transaction data reaching back far enough to link the teardown
to a transaction. Or more to the point, be able to compare it to other
transacted properties that didn&rsquo;t get torn down. Similar problems occur
at the end of our time frame, and with variables that are only available
in certain sub time frames.</p>

<script>
function resetImages(){
    $('img').each(function(img){
        imgsrc = $(img).attr('src');
        if (imgsrc.slice(imgsrc.length-4)=='.gif') {
            $(img).attr('src', '');
            $(img).attr('src', imgsrc);

        }
    });
    setTimeout(function(){
        resetImages();
    },25000);
}
setTimeout(function(){
    resetImages();
},25000);
</script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2016 Census Data - Part 1]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/02/10/2016-census-data/"/>
    <updated>2017-02-10T20:27:10-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/02/10/2016-census-data</id>
    <content type="html"><![CDATA[<p><a href="https://censusmapper.ca/maps/583"><img src="http://doodles.mountainmath.ca/images/van_pop_change.png" style="width:50%;float:right;margin-left:10px;"></a>
Finally the first batch of 2016 census data has arrived on Tuesday AM and
CensusMapper was updated with the new census numbers by mid-morning.</p>

<p>Dissemination Block data was a little harder to find, but with the help
of some friendly StatCan people I finally managed to locate the data and
add that too this afternoon.</p>

<p>Time for writing up some observations. I am hoping to find time to do
this regularly as more data gets released.</p>

<!-- more -->


<p>The first batch of data only comes with three variables: Population, dwellings and households.
And two more, a data quality flag indicating areas with incomplete enumeration and the area of
each geographic region. Area itself is more tricky than it seems at first, one has
to make decisions what to count. Lakes? Rivers? National or Regional Parks?</p>

<p>Next to these variables, we also got the corresponding 2011 population for all geographic
regions at the CT/CSD level and above to aid the comparison, but these
were not available at the DA or DB level.</p>

<p>The variables seem straight forward, but nothing is simple when it comes to big projects like a census,
so it might we worthwhile to spend a little bit of time looking at them.</p>

<h3>Population</h3>

<p><a href="https://censusmapper.ca/maps/591"><img src="http://doodles.mountainmath.ca/images/van_pop_density.png" style="width:50%;float:right;margin-left:10px;"></a>
The quintessential census variable counts the number of people in each census region. With the exception
of people that have a primary residence elsewhere in Canada or abroad. There are several reasons for this,
the simples one is to avoid the double-counting of people.</p>

<h3>Dwellings</h3>

<p>&ldquo;Dwellings&rdquo; is short for &ldquo;private dwellings&rdquo;, this does not count collective dwellings
like prisons, student dorms, hospitals or nursery homes or even some coops. This can lead
to interesting situation where there are zero private dwellings (and zero households) but non-zero population.
Metro Vancouver has 45 such dissemination blocks. But these people are
only counted if they don&rsquo;t have a primary residence somewhere else, which
often is the case for students in dorms. But not for all students, as the
Dissemination Block on UBC campus that&rsquo;s wedged between NW Marine, University,
Lower Mall and Agronomy shows.
It has zero dwellings, zero households, but a population of 890 people.</p>

<h3>Households</h3>

<p>The &ldquo;dwellings, occupied by usual residents&rdquo; is also called &ldquo;households&rdquo;. It
refers to a private dwelling that is used as a primary residence, and the inhabitants
make up a household. If inhabitants of a dwelling only live there temporarily and/or has
a primary residence somewhere else in Canada or abroad, then they are not
counted in the population nor the household counts.</p>

<h3>Unoccupied Dwellings</h3>

<p><a href="https://censusmapper.ca/maps/584"><img src="http://doodles.mountainmath.ca/images/van_unoccupied.png" style="width:50%;float:left;margin-right:10px;"></a>
The difference between dwellings and households is &ldquo;dwellings, not occupied by usual residents&rdquo;. Essentially, that&rsquo;s
dwellings that are not used as primary residences. It&rsquo;s a fun variable to look at, and it
is available at the very fine Census Block level. In some cases, a Census Block can contain just one apartment building.</p>

<h3>Mixing Variables</h3>

<p>The fun starts when we mix these variables. And compare them to the previous
censuses. And there are lots of ways to do that, here are a few:</p>

<h4>Population Change</h4>

<p><a href="https://censusmapper.ca/maps/583"><img src="http://doodles.mountainmath.ca/images/van_pop_change.png" style="width:50%;float:right;margin-left:10px;"></a>
The most immediate variable to look at is population change. We have
complete Canada-wide data at the CT level or above, but if we are really
interested we can also view this data for DAs and DBs that stayed the same
across the census years. The issue with doing that is that some regions will have
not data, and one has to be very careful not to read too much into an incomplete
dataset. Which is why I usually don&rsquo;t like giving out maps that contain incomplete data like this.
But this is great for diving into specific regions to get more information.</p>

<h4>Dwelling Change</h4>

<p><a href="https://censusmapper.ca/maps/588"><img src="http://doodles.mountainmath.ca/images/van_dw_change.png" style="width:50%;float:left;margin-right:10px;"></a>
This is a great way to see where more dwellings got built. This only measures
net changes, so even if a region shows zero dwelling increase, there could have
been quite a bit of construction in the area. In particular, if houses with secondary
suites get torn down and replaced by houses without secondary suites, it will
show up as a decline in the number of dwelling units.</p>

<h4>Non-primary residence dwellings</h4>

<p><a href="https://censusmapper.ca/maps/586"><img src="http://doodles.mountainmath.ca/images/van_uo_change.png" style="width:50%;float:right;margin-left:10px;"></a>
More formally, these are &ldquo;dwellings not occupied by usual residents&rdquo;, it&rsquo;s
the difference between dwellings and households and the object of continued
scrutiny in Vancouver. And a good portion of these are the target of the
upcoming empty home tax to either monetize non-primary resident homes or
nudge them into the rental market.</p>

<h4>Household size change</h4>

<p><a href="https://censusmapper.ca/maps/590"><img src="http://doodles.mountainmath.ca/images/van_hs_change.png" style="width:50%;float:left;margin-right:10px;"></a>
A big part of population change is the change in household size. Canada wide the
trend to smaller households is continuing. That means that if the number of dwellings
and the rate of unoccupied dwellings in a region remain unchanged, then the
population in the area will decline if it follows the national trend to
smaller household size.</p>

<h3>Population Change Null Sum Game</h3>

<p>From looking at CensusMapper, the variable that got by far the most attention
nationally in the past three days is Population Change. It&rsquo;s great to
see where population grew or declined. But almost immediately people wonder
why population change was different in one region compared to another.</p>

<p>The first step to this is the Population Null Sum Game. You need the</p>

<ul>
<li>Dwelling Change</li>
<li>Change in Unoccupied Dwellings</li>
<li>Change in Household size</li>
</ul>


<p>to play. The game is then to express Population Change in terms of those three,
and thus &ldquo;explaining&rdquo; population change in terms of these variables. There are
of course other ways to split up the Population Change variable, but I find
this a useful one.</p>

<p>Nathaniel Lauster kicked the game off
<a href="https://homefreesociology.wordpress.com/2017/02/10/if-you-build-it-will-they-come/">with this great post</a>.
Let&rsquo;s follow up his inter-municipal level analysis with some intra-municipal numbers.</p>

<p>We will focus on the City of Vancouver only. People are welcome to use CensusMapper
to repeat this for whatever region they are interested in. Vancouver has the
nice advantage that at the dissemination area geography only on change was made.
A 2011 downtown DA got split into two for 2016. That makes it very easy to carry
this out at the DA level.</p>

<h3>Components of Population Change</h3>

<p>First we refine our variables a little bit it seems more interesting to use the rate of unoccupied builings as a variable,
rather than the number of these. We want to express population change <code>Δpop</code> as a
linear combination of</p>

<ul>
<li>Dwelling change <code>Δdw</code></li>
<li>Change in ratio of unoccupied dwellings <code>Δur</code></li>
<li>Change in household size <code>Δhs</code></li>
</ul>


<p>More formally:</p>

<pre><code>Δpop = hs₁₁ * (1-ur₁₁) * Δdw - hs₁₁ * dw₁₆ * Δur +  hh₁₆ * Δhs
</code></pre>

<p>where <code>hs₁₁=pop₁₁/hh₁₁</code> is the household size in 2011 as computed by dividing the population by the number of households,
<code>ur₁₁</code> is the rate of unoccupied dwellings in 2011, <code>dw₁₆</code> is the number of dwellings in 2016 and <code>hh₁₆</code> is the number of households in 2016.</p>

<p>It is simple algebra to check that the identity holds.</p>

<p><a href="https://censusmapper.ca/maps/596"><img src="http://doodles.mountainmath.ca/images/van_pop_comp.png" style="width:50%;float:right;margin-left:10px;"></a>
The first term gives the contribution to population growth due to the growth in dwellings, assuming that household size and the rate of unoccupied dwellings
are unchanged from 2011.</p>

<p>The second term give the population growth due to the change in the rate of unoccupied dwellings and the third term gives the
population growth due to a change in household size.</p>

<p>Great, all that&rsquo;s left to do is to type the formula into CensusMapper and graph the relative contribution of each of these terms. To make this work
we will have to make due with using only the magnitude of each term, but we can visualize the sign in the bar graph widget when
we hover over an area.</p>

<p>This makes it very easy to compare different areas and see how the different components contribute to the change in
population in each area.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Jane Jacobs' Vancouver]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/01/25/jane-jacobs-vancouver/"/>
    <updated>2017-01-25T21:57:05-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/01/25/jane-jacobs-vancouver</id>
    <content type="html"><![CDATA[<p>Some time ago I saw <a href="https://twitter.com/gboeing/status/816331801266262017">Geoff Boeing&rsquo;s excellent package</a>
to generate Jane Jacobs style street grid images. It&rsquo;s lots of fun to compare different cities that way.</p>

<p>It can be hard to represent one city by one square mile, so I thought it would be neat to use this
to compare different parts of Vancouver. Some common themes emerge for the central parts,
the more outlying areas display very differnet patterns.</p>

<!-- more -->


<p>So I <a href="http://bl.ocks.org/d/88803d79ab2a3e637e2cce7fc151423d">dropped a couple of points on a map</a>, downloaded
the geojson and ran the script below. These are the results:</p>

<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Downtown.png" ><p>Downtown</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/West%20End.png" ><p>West End</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Grandview%20Woodlands.png" ><p>Grandview Woodlands</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Kitsilano.png" ><p>Kitsilano</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/North%20Vancouver.png" ><p>North Vancouver</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/New%20West.png" ><p>New West</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Surrey.png" ><p>Surrey</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Metrotown.png" ><p>Metrotown</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Richmond.png" ><p>Richmond</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/West%20Vancouver.png" ><p>West Vancouver</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Langley.png" ><p>Langley</p></div>


<div class="jacobs"><img src="http://doodles.mountainmath.ca/images/jacobs/Port%20Moody.png" ><p>Port Moody</p></div>


<p>If you want to make your own, just grab the <a href="https://github.com/gboeing/osmnx/blob/master/examples/09-example-figure-ground.ipynb">lightly adapted</a> code below.
Yes, it is that easy.</p>

<h4>Code to generate the images</h4>

<pre><code># jane_jacobs.py
import geojson
import osmnx as ox
from IPython.display import Image
ox.config(log_file=True, log_console=True, use_cache=True)

file="data/van_cities.geojson"
img_folder = 'images'
extension = 'png'
size = 350
dpi = 90

cities=geojson.loads(open(file,"r").read())
for city in cities.features:
    place = city.properties['name']
    point = (city.geometry.coordinates[1],city.geometry.coordinates[0])
    fig, ax = ox.plot_figure_ground(point=point, filename=place)
    Image('{}/{}.{}'.format(img_folder, place, extension), height=size, width=size)
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bumper Year for Thumb Twiddlers]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/01/18/bumper-year-for-thumb-twiddlers/"/>
    <updated>2017-01-18T11:10:43-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/01/18/bumper-year-for-thumb-twiddlers</id>
    <content type="html"><![CDATA[<p><a href="https://www.mountainmath.ca/map/assessment?zoom=12&amp;lat=49.2494&amp;lng=-123.1241&amp;layer=12"><img src="http://doodles.mountainmath.ca/images/twiddling_thumbs_2006_2017.png" style="width:50%;float:right;margin-left:10px;"></a>
Almost a year has passed since we first noticed how
<a href="http://doodles.mountainmath.ca/blog/2016/01/24/work-vs-twiddling-thumbs/">sitting on single family homes and twiddling thumbs generates more income than working</a>.
And not just at the level of individual single family households. In the
City of Vancouver, the cumulative
land value gains of just the single family homes eclipsed the cumulative taxable earnings
reported to the CRA for the entire population.</p>

<p>With the new assessment data available now, it is time to run the numbers
and see how our thumb-twiddlers fared vs workers this year. If you thought
last year&rsquo;s twiddling thumbs returns were crazy high, you better hold onto
your hats!</p>

<!-- more -->


<h3>Work</h3>

<p>Not much changed in terms of the income people earned. CANSIM does not make the
taxfiler data freely available at the municipal level, we we will again estimate
the cumulative income for residents of the City of Vancouver by using 2010
Census data and extrapolating by applying the Metro Vancouver rate of income
growth.</p>

<p>This way we get a cumulative $22.3bn pre-tax or $18.6bn after-tax income in 2010,
<a href="http://www5.statcan.gc.ca/cansim/a26?lang=eng&amp;retrLang=eng&amp;id=1110009&amp;&amp;pattern=&amp;stByVal=1&amp;p1=1&amp;p2=37&amp;tabMode=dataTable&amp;csid=">which grew around 13% between 2010 and 2014</a>.
Extrapolating this for another two years to 2016 we estimate an income growth of around 20% since 2010,
which then pegs the cumulative income for the City of Vancouver at
$26.8bn pre-tax or $22.3bn after-tax (ignoring financial drag and other issues).</p>

<h3>Twiddling Thumbs</h3>

<p>Let&rsquo;s compare this to how much Vancouver home owner households &ldquo;earned&rdquo; last year by twiddling thumbs while sitting on their
property. To keep things simple and consistent with last year, we again focus on just the single family homes (SFH).
And again, we only consider land value changes, after all changing the
building value because of renovation or rebuilding certainly does not happen by twiddling thumbs.</p>

<p>The median SFH land value increased was $435,000 (the average was $594,005), for a cumulative land value increase
of $46.7bn, accounting for about half of the
<a href="http://doodles.mountainmath.ca/blog/2017/01/16/2017-assessment-data/">total land value increase of the City of Vancouver</a>
or two thirds of the land value increase for residential (and mixed) land uses.</p>

<p>So while last year the twiddling thumbs return were still comparable to the cumulative income in the City of Vancouver,
this year the thumb twiddlers blow the income earners out of the water.
<span style="font-weight:bolder;">Just by by twiddling their thumbs, the SFH property owners alone earned twice as much
as the entire population of the
City of Vancouver did by actually working</span>. And in most cases homeowners won&rsquo;t pay taxes on
their thumb-twiddle earnings, although the
<a href="http://doodles.mountainmath.ca/blog/2016/10/04/secondary-suites-and-taxes/">CRA recently made it harder with their new reporting rules</a>.</p>

<p>We are glossing over a couple of details here, for example the numbers are not adjusted for inflation, and costs like
property taxes and property transfer tax are not taken into account.</p>

<p>Of course, comparing income from work to income from twiddling thumbs is not entirely fair. The income from twiddling thumbs
is frozen in the property until the owner sells. But gains accumulate over the years, and eventually everyone sells and realizes
the gains (or passes them on to the next generation). And it&rsquo;s always good to remember that
&ldquo;<a href="https://twitter.com/GRIDSVancouver/status/813516103490015232">house-rich cash-poor homeowners are one transaction away from simply being rich renters</a>&rdquo;.</p>

<h3>The Long Term</h3>

<p><a href="https://www.mountainmath.ca/map/values?filter=sfh&zoom=13&lat=49.2482&lng=-123.1213&layer=25&mapBase=2&year=2016"><img src="http://doodles.mountainmath.ca/images/twiddling_thumbs_animated_2017.gif" style="width:50%;float:left;margin-right:10px;"></a>
Most people don&rsquo;t trade houses like stocks, so what really matters is the long term gains, not the year to year changes. The 11 year
timeframe for which we have data roughly matches the average holding time for a single family house. The year over year
changes in land value vary dramatically, as the image shows and can be explored further using the
<a href="https://www.mountainmath.ca/map/values?filter=sfh&amp;zoom=13&amp;lat=49.2482&amp;lng=-123.1213&amp;layer=25&amp;mapBase=2&amp;year=2016">interactive version</a>.</p>

<p>Over 11 years, the single family home land value quadrupled. The median (nominal) single family home land value increase over that timespan
was $1,233,000, or $112,000 per year. Broken down further, that&rsquo;s $2,339,000 ($213,000 per year) for the median west side home
and $1,031,000 ($94,000 per year) for the median east side home.</p>

<p><a href="https://www.mountainmath.ca/map/assessment?filter=sfh&amp;zoom=13&amp;lat=49.2494&amp;lng=-123.1241&amp;layer=12"><img  src="http://doodles.mountainmath.ca/images/twiddling_thumbs_2006_2017.png" style="width:50%;float:right;"></a>
We <a href="https://www.mountainmath.ca/map/assessment?filter=sfh&amp;zoom=13&amp;lat=49.2494&amp;lng=-123.1241&amp;layer=12">mapped the land value gain averaged over 11 years</a>.
We can observe that the average yearly increase depends on the square footage of the property as well as the location. The rates are mostly uniform
throughout the city (with some notable exceptions), but properties starting out with a higher value will see higher total value
increases. It&rsquo;s probably fair to say that even using the 11 year average, most homeowners &ldquo;earned&rdquo; more money twiddling thumbs
than pursuing a more traditional employment.</p>

<h3>Hourly Rate for Twiddling Thumbs</h3>

<p>Using the <a href="http://doodles.mountainmath.ca/blog/2016/01/24/work-vs-twiddling-thumbs/">same methods as last year</a>
we can compute the hourly earnings of thumb twiddlers. For the July 2016 to July 2017 timeframe, thumb twiddlers
in the City of Vancouver averaged a tidy $239 per hour.
Using the 11 year averaged numbers instead of focusing on just the last year we still get a healthy average
thumb twiddling rate of $62 per hour.</p>

<p>Another bumper year for thumb twiddlers!
Considering to change your line work to thumb twiddling? To bad thumb twiddling is so unaffordable!</p>

<h3>Data Dump</h3>

<p>Here is the raw output of the stats run on the single family properties for anyone interested.</p>

<h5>SFH Land Value Rise (2016 - 2017)</h5>

<ul>
<li>City Wide: Average $594,005 Median $435,000, Count: 78648, Total: $46,717,325,799, Hourly: $239</li>
<li>Eastside: Average $373,306 Median $358,000, Count: 47988, Total: $17,914,233,199, Hourly: $150</li>
<li>Westside: Average $939,435 Median $866,000, Count: 30660, Total: $28,803,092,600, Hourly: $378</li>
</ul>


<h5>SFH Land Value Rise (2006 - 2017)</h5>

<ul>
<li>City Wide: Average $153,777 Median $112,090, Count: 77809, Total: $11,965,271,272, Hourly: $62</li>
<li>Eastside: Average $96,892 Median $93,727, Count: 47545, Total: $4,606,748,985, Hourly: $39</li>
<li>Westside: Average $243,144 Median $212,636, Count: 30264, Total: $7,358,522,287, Hourly: $98</li>
</ul>


<p>The total number of units for the 2006 to 2017 analysis are a little lower since not all properties can be traced over that time
period without resorting to more tedious analysis.</p>

<script>
function resetImages(){
    $('img').each(function(img){
        imgsrc = $(img).attr('src');
        if (imgsrc.slice(imgsrc.length-4)=='.gif') {
            $(img).attr('src', '');
            $(img).attr('src', imgsrc);

        }
    });
    setTimeout(function(){
        resetImages();
    },25000);
}
setTimeout(function(){
    resetImages();
},25000);
</script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Coveted $1.2m - $1.6m Vote]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/01/17/the-coveted-2m-6m-vote/"/>
    <updated>2017-01-17T16:19:03-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/01/17/the-coveted-2m-6m-vote</id>
    <content type="html"><![CDATA[<p><a href="https://mountainmath.ca/map/special/81?layer=101&amp;mapBase=2"><img  src="http://doodles.mountainmath.ca/images/coveted_vote.png" style="width:50%;float:right;margin-left:10px;"></a>
Earlier this month the province increased the threshold for the homeowner grant from $1.2 million to $1.6 million dollars.
It&rsquo;s an election year, and with the BC Assessment data for the City of Vancouver now being available via their
<a href="http://vancouver.ca/your-government/open-data-catalogue.aspx">open data catalogue</a>
we can ask who exactly this move was targeting.</p>

<p>Restricted to the City of Vancouver, the answer is quite simple. There are about 24,000 single family homes, 1,200 duplex units and 4,000 condo units
in that bracket.</p>

<p>Let&rsquo;s take a closer look.</p>

<!-- more -->


<p><a href="https://mountainmath.ca/map/assessment?filter=[sfh,total_1200000_1600000]&amp;layer=101&amp;mapBase=2"><img  src="http://doodles.mountainmath.ca/images/coveted_sfh_vote.png" style="width:50%;float:left;margin-right:10px;"></a>
If we focus in on just the
<a href="https://mountainmath.ca/map/assessment?filter=[sfh,total_1200000_1600000]&amp;layer=101&amp;mapBase=2">single family homes</a>,
which make up the vast majority of the units in that bracket, we see that they
are (almost) entirely located in East Vancouver. In fact, we can see how Main Street delineates these properties quite neatly.
In fact, there are fewer than 500 single family homes west of Main in that bracket.</p>

<p>One could be lead to think that Main Street is the &ldquo;$1.6m line&rdquo;. But of the single family homes
east of Main, these only make up just over half of the properties there,
there are almost as many that are
<a href="https://mountainmath.ca/map/assessment?filter=[sfh,total_1600000]&amp;layer=101&amp;mapBase=2">assessed over $1.6m</a>
and <a href="https://mountainmath.ca/map/assessment?filter=[sfh,total__1200000]&amp;layer=101&amp;mapBase=2">almost 2,000 assessed under $1.2m</a>.</p>

<h4>Changing Homeowner Grant Status</h4>

<p>There are a number of single family homes where the homeowner grant status changed between 2016 and 2017.
There are about 3,100 single family homes who did not qualify for the homeowner
grant in 2016, but do now. And about 1000 that did qualify in 2016 but won&rsquo;t this year.</p>

<p>Yes, that&rsquo;s right, there are
1000 single family homes with 2016 assessment below $1.2m and 2017 assessment over $1.6m. I pity them,
having to pay an extra $50/month in property taxes just because the province did not care about them
enough to set the new threshold higher than $1.6m.</p>

<p>To round things up, there were a little under 500 duplex and condo units that did not qualify for the homeowner
grant in 2016 and do in 2017, and under 200 that did qualify in 2016 and don&rsquo;t now.</p>

<h3>How to get the grant if you are renting?</h3>

<p>You can&rsquo;t. And your landlord can&rsquo;t either. No matter how much your unit is worth, the province won&rsquo;t be cutting
any checks to lower your rent by $50/month.
The homeowner grant is just one of the many perks exclusively available home owners.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2017 Vancouver Assessment Data]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2017/01/16/2017-assessment-data/"/>
    <updated>2017-01-16T19:04:19-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2017/01/16/2017-assessment-data</id>
    <content type="html"><![CDATA[<p><a href="https://mountainmath.ca/map/values?filter=[sfh]&amp;zoom=13&amp;layer=9"><img  src="http://doodles.mountainmath.ca/images/value_animated.gif" style="width:50%;float:right"></a>
The friendly folks at
<a href="http://vancouver.ca/your-government/open-data-catalogue.aspx">Vancouver Open Data</a> just
<a href="https://twitter.com/VanOpenData/status/688060388190097408">updated their property assessment data</a> with the fresh 2017
property tax assessments. Time to run the script to update the <a href="https://mountainmath.ca/map/assessment">Vancouver Assessment Map</a>
with the new data, just <a href="http://doodles.mountainmath.ca/blog/2016/01/17/updated-vancouver-assessment-data/">like we did last year</a>.</p>

<p>For now we just updated our standard visuals and computed some overall statistics. We will take a closer look at the data over the coming days.</p>

<h4>Maps</h4>

<!-- more -->


<p>By now we have a variety of maps that highlight different aspects of Vancouver real estate, and after running the import scripts they
automatically serve the newest data. Our basic
<a href="https://mountainmath.ca/map/assessment">interactive assessment map</a> offers a variety of ways to slice and display the data. It&rsquo;s
mostly focused on functionality, some of which we described in
<a href="http://doodles.mountainmath.ca/blog/2016/01/17/updated-vancouver-assessment-data/">last year&rsquo;s post</a>, as well as other posts like
the one on <a href="http://doodles.mountainmath.ca/blog/2016/01/24/work-vs-twiddling-thumbs/">twiddling thumbs vs working</a>.</p>

<p>We also have interactive views focusing on how real estate prices varied over time, for example the <a href="http://doodles.mountainmath.ca/blog/2016/04/01/on-dirt-and-houses/">houses and dirt map</a>
that separates out (inflation adjusted) values of the structures and the land, and also allows to filter by type of housing, to animate changes over time.</p>

<p>For people that like simpler maps we also have a <a href="https://mountainmath.ca/map/values?filter=[sfh]&amp;zoom=13&amp;layer=9">plain total (nominal) value over time map</a>
that allows to interactively step through the years and see how single family house values in Vancouver changed over time. Here we also
added the ability to visualize year-over-year value changes, which also hints at how BC Assessment changed their valuation
algorithm over the years.</p>

<h4>The Data</h4>

<p>The data originates with BC Assessment, which estimates land and building values of each property based on recent sales
of comparable properties. The values are pegged at July 1 of each year, with the the most recent available now being July 1 2016.
The estimates for the values do not reflect changes in the market since then. Moreover, the estimates can be quite off on an individual
property level, but are unbiased. That means that any statistics derived from a large subsample should fairly accurately
reflect actual market conditions for July 1st. Lastly, the assessed values will still change a bit as some will be successfully appealed.</p>

<p>City of Vancouver, as well as the City of Surrey, make this data available for general use through their open data portal, which
allows us to create these maps. The format of the data the municipalities are giving out through their open data portal is
different, so lazy me is only importing data from City of Vancouver. Sadly, BC Assessment does not make this data
generally available province wide for us to make province wide maps.</p>

<p>While BC Assessment makes this data available on their <a href="https://evaluebc.bcassessment.ca">eValue website</a> for browsing individual
properties and also provides it in bulk to researchers, the attached license does not allow the thematic mapping of individual properties.</p>

<p>The motivation behind the map was to understand the building stock, so in the maps as well as the summary statistics below
we filter out parks and some other properties.</p>

<p>The new city dataset does not include the 2017 tax levy, so our maps still only show the 2016 tax levies until CoV updated their dataset.</p>

<h4>History</h4>

<p>In the spirit of <a href="http://doodles.mountainmath.ca/blog/2016/01/17/updated-vancouver-assessment-data/">last year&rsquo;s post</a> we ran some
quick summary statistics to break down the numbers by neighbourhood. Instead of listing the most recent land and building value
increases by neighbourhood we stuck everything into an interactive graph for the entire time span between 2006 and 2017 tax years.
Use the dropdown menus to drill down
into city neighbourhoods, view values for all properties or just residential properties and display as total value or year-over-year
percentage change.</p>

<p>The last year again
saw an huge increase in property values. For the City of Vancouver land values were up 35% and building values 10%, with the land
value increase setting a record for the timeframe for which we have data. The increases become even more pronounced when we zero in
on residential property only.</p>

<div style="margin:10px 50px;padding:5px;border: 1px solid black;border-radius:5px;">
<select id="nbhd-select"></select>
<select id="keys-select"></select>
<select id="type-select">
<option value='total'>Total Value</option>
<option value='percent'>Percentage Change</option>
</select>
<div id="graph" style="height:200px;max-width:640px;" data-lines="/data/detail_history.json"></div>
<div class="legend no-margin">
</div>
</div>




<script>
var ready_for_graph = function() {
    var d3lines=[];
    var padding = {top: 20, right: 20, bottom: 30, left: 90};
    var prevChartWidth = 0, prevChartHeight = 0;
    var updateTransistionMS = 750; // milliseconds
    var jsonData, xScale, yScale, line,neighbourhoods;

    var currentValue='City of Vancouver';
    var currentKeys=['land','building'];
    var currentModePercentage=false;

    var hash={
            land: {label:"Land Value", color:"green"},
              building: {label:"Building Value", color:"blue"},
              res_land: {label:"Residential Land Value", color:"darkgreen"},
              res_building: {label:"Residential Building Value", color:"darkblue"},
              land_p: {label:"Land Value Increase", color:"green"},
              building_p: {label:"Building Value Increase", color:"blue"},
              res_land_p: {label:"Residential Land Value Increase", color:"darkgreen"},
              res_building_p: {label:"Residential Building Value Increase", color:"darkblue"}
                };
    var keys=Object.keys(hash);

    var symbol;
    var prefix;
    var numberFormatter = function (y) {
        return '$' + Math.round(prefix.scale(y*10))/10.0 + symbol;
    };

    var graphs=d3.select("#graph");
    var div=graphs[0][0];
    if (div==null|| div.childElementCount!=0) {return;}
    var data_url=div.dataset.url;

    // create svg and g to contain the chart contents
    var baseSvg = graphs.append("svg");
    var chartSvg=baseSvg
        .append("g")
        .attr("class", "chartContainer")
        .attr("transform", "translate(" + padding.left + "," + padding.top + ")");

    // create the x axis container
    chartSvg.append("g")
        .attr("class", "x axis");

    // create the y axis container
    chartSvg.append("g")
        .attr("class", "y axis");
    var line;
    var largest=null;
    var lineData;
    if (div.dataset.lines) {
        d3.json(div.dataset.lines,function(error,json){
        jsonData=json;
        neighbourhoods=Object.keys(jsonData);
        var keyHash={all:{label: 'All Properties',data:['land','building']},res:{label: 'Residential Properties',data:['res_land','res_building']}};
        var keyOptions=Object.keys(keyHash);
        d3.select('#nbhd-select').selectAll('option').data(neighbourhoods).enter().append('option').attr('value',function(d){return d}).text(function(d){return d});
        $('#nbhd-select').on('change',function(d){
            currentValue=this.value;
            updateChart({init:true,keys:currentKeys,data:jsonData[currentValue],percentage:currentModePercentage})
        });
        d3.select('#keys-select').selectAll('option').data(keyOptions).enter().append('option').attr('value',function(d){return d}).text(function(d){return keyHash[d].label});
        $('#keys-select').on('change',function(d){
            currentKeys=keyHash[this.value].data;
            updateChart({init:true,keys:currentKeys,data:jsonData[currentValue],percentage:currentModePercentage})
        });
        $('#type-select').on('change',function(d){
            currentModePercentage=this.value=='percent';
            updateChart({init:true,keys:currentKeys,data:jsonData[currentValue],percentage:currentModePercentage})
        });
        lineData=json[currentValue];
        var domain=[null,null];
        var range=[null,null];
        lineData.forEach(function(d) {
             d.date = +d.date;
             if (domain[0]==null || domain[0]> d.date) domain[0]= d.date;
             if (domain[1]==null || domain[1]< d.date) domain[1]= d.date;
             keys.forEach(function(k){
                d[k]=+d[k];
                if (range[0]==null || range[0]> d[k]) range[0]= d[k];
                if (range[1]==null || range[1]< d[k]) range[1]= d[k];
            });
        });
        xScale=d3.scale.linear().domain(domain);
        var toAdd=(range[1]-range[0])/10;
        range[0]-=toAdd;
        range[1]+=toAdd;
        yScale=d3.scale.linear()
            .domain(range);

        line = d3.svg.line()
            .x(function(d) { return xScale(d.date); })
            .y(function(d) { return yScale(0); })
            .interpolate("linear");
        xAxis = d3.svg.axis()
            .scale(xScale)
            .orient("bottom")
            .tickFormat(d3.format("d"));
            //.ticks(5);
            //.tickValues(domain);

        yAxis = d3.svg.axis()
            .scale(yScale)
            .orient("left")
            .tickFormat(numberFormatter)
            .ticks(5);

        prefix = d3.formatPrefix(range[1]);
        if (prefix.symbol=='K') {
            symbol='k'
        } else if (prefix.symbol=='M') {
                symbol='m'
        } else if (prefix.symbol=='G') {
            symbol='bn'
        } else if (prefix.symbol=='T') {
            symbol='tn'
        }
        updateChart({init:true,keys:currentKeys,data:jsonData[currentValue],percentage:currentModePercentage});
        });

    }


    function updateChart(options)
    {
        var lineData=options.data;
        var init=options.init;
        var keys=options.keys;

        lineData.forEach(function(d,i) {
             keys.forEach(function(k){
                d[k]=+d[k];
                if (i>0) d[k+'_p']=d[k]/lineData[i-1][k]-1;
             });
        });

        if (options.percentage) {
            keys=keys.map(function(k){return k+'_p'});
            lineData=lineData.slice(1);
        }

        var domain=[null,null];
        var range=[null,null];
        lineData.forEach(function(d,i) {
             d.date = +d.date;
             if (domain[0]==null || domain[0]> d.date) domain[0]= d.date;
             if (domain[1]==null || domain[1]< d.date) domain[1]= d.date;
             keys.forEach(function(k){
                if (range[0]==null || range[0]> d[k]) range[0]= d[k];
                if (range[1]==null || range[1]< d[k]) range[1]= d[k];
            });
        });

        //if (options.percentage) domain[0]+=1;

        var toAdd=(range[1]-range[0])/10;
        range[0]-=toAdd;
        if (!options.percentage) range[0]=Math.max(0,range[0]);
        range[1]+=toAdd;
        yScale.domain(range);
        xScale.domain(domain);
        var formatter;
        if (options.percentage) {
            formatter=d3.format('.1%');
        } else {
            formatter=numberFormatter;
        }
        yAxis.tickFormat(formatter);

        var legend=d3.select('.legend');
        legend.empty();
        legend.selectAll('.item').data(keys)
            .enter().append('p').attr('class','item')
            .html(function(k){return '<i style="background:'+hash[k].color+'"></i> '+hash[k].label+' <span style="float:right;margin-right:10px;" id="'+k+'_value"></span>'});
        //legend.selectAll('.item').exit().remove();


        // get the height and width subtracting the padding
//    var innerHeight = window.innerHeight - 20;
        var innerWidth = window.innerWidth - 20;
        var divWidth=$(div).width();
        if (divWidth==0) divWidth=$(div.parentElement.parentElement).width();
        var maxWidth=parseInt($(div).css('max-width'));
        if (divWidth==0) divWidth=innerWidth*0.8;
        if (divWidth>maxWidth) divWidth=maxWidth;
        var chartWidth = divWidth-padding.left-padding.right;//960 - margin.left - margin.right,
        var chartHeight = $(div).height()-padding.top-padding.bottom;//500 - margin.top - margin.bottom;


        // only update if chart size has changed
        if (true || (prevChartWidth != chartWidth) || (prevChartHeight != chartHeight)) {
            prevChartWidth = chartWidth;
            prevChartHeight = chartHeight;

            //set the width and height of the SVG element
            chartSvg.attr("width", chartWidth + padding.left + padding.right)
                .attr("height", chartHeight + padding.top + padding.bottom);
            baseSvg.attr("width", chartWidth + padding.left + padding.right)
                .attr("height", chartHeight + padding.top + padding.bottom);

            // ranges are based on the width and height available so reset
            xScale.range([0, chartWidth]);
            yScale.range([chartHeight, 0]);




            if (init) {
                // if first run then just display axis with no transition
                chartSvg.select(".x")
                    .style({ 'stroke': 'grey', 'fill': 'none', 'stroke-width': '1px'})
                    .attr("transform", "translate(0," + chartHeight + ")")
                    .call(xAxis);

                chartSvg.select(".y")
                    .style({ 'stroke': 'grey', 'fill': 'none', 'stroke-width': '1px'})
                    .call(yAxis);

                chartSvg.select('.x.axis path').style('display','inherit');
            }
            else {
                // for subsequent updates use a transistion to animate the axis to the new position
                var t = chartSvg.transition().duration(updateTransistionMS);

                t.select(".x")
                    .attr("transform", "translate(0," + chartHeight + ")")
                    .call(xAxis);

                t.select(".y")
                    .call(yAxis);
            }

            var sourceData=lineData;

            function addSeries(key){
                var g=d3.select(this);
                var color=hash[key].color;
                var label=hash[key].label;
                var className=key;

                // bind up the data to the line
                var lines = g.selectAll("path.line")
                    .data([sourceData]); // needs to be an array (size of 1 for our data) of arrays

                var valueFunction=function(d){return d[key]};
                var yFunction=function(d){return yScale(valueFunction(d))};
                var ff=key[key.length-1]=='p' ? d3.format('.1%') : numberFormatter;
                var formatFunction=function(d){return ff(valueFunction(d))};

                function tooltipFunction(d,el){
                  var key=d3.select(el.parentElement).datum();
                  var ff=key[key.length-1]=='p' ? d3.format('.1%') : numberFormatter;
                  return d.date + ': ' + ff(d[key]);
                }

                 var line=d3.svg.line()
                      .x(function(d) { return xScale(d.date); })
                      .y(yFunction)
                      .interpolate("linear");

               // transistion to new position if already exists
                lines.transition()
                    .duration(updateTransistionMS)
                    .attr("d", line);


                // add line if not already existing
                lines.enter().append("path")
                    .attr("class", "line")
                    .attr("stroke", color)
                    .attr("stroke-width", 2)
                    .attr('fill','none')
                    .attr("d", line);

                lines.exit().remove();

                // bind up the data to an array of circles
                var circles = g.selectAll("circle")
                    .data(sourceData);

                // if already existing then transition each circle to its new position
                circles.transition()
                    .duration(updateTransistionMS)
                    .attr("cx", function (d) {
                        return xScale(d.date);
                    })
                    .attr("cy", yFunction);

                // if new circle then just display
                circles.enter().append("circle")
                    .attr("class", className)
                    .attr("cx", function (d) {
                        return xScale(d.date);
                    })
                    .attr("cy", yFunction)
                    .attr("r", 4)
                    .attr('fill', 'transparent')
                    .style("stroke", color)
                    .style("stroke-width", 8)
                    .on('mouseover',function(d){
                       d3.select('#'+this.classList[0]+'_value').text(tooltipFunction(d,this))
                    }).on('click',function(d){
                       d3.select('#'+this.classList[0]+'_value').text(tooltipFunction(d,this))
                    }).on('touch',function(d){
                       d3.select('#'+this.classList[0]+'_value').text(tooltipFunction(d,this))
                    }).on('mouseout',function(){d3.select('#'+this.classList[0]+'_value').text('')});
                circles.exit().remove();
                }
            }

            var selection=chartSvg.selectAll('g.series').data(keys);
            selection.exit().remove();
            selection.enter().append('g').attr('class','series');
            chartSvg.selectAll('g.series').each(addSeries);
    }

    // look for resize but use timer to only call the update script when a resize stops
    var resizeTimer;
    window.onresize = function(event) {
        clearTimeout(resizeTimer);
        resizeTimer = setTimeout(function()
        {
                updateChart({init:false,keys:currentKeys,data:jsonData[currentValue],percentage:currentModePercentage});
        }, 100);
    }


};
ready_for_graph();



function resetImages(){
    $('img').each(function(img){
        imgsrc = $(img).attr('src');
        if (imgsrc.slice(imgsrc.length-4)=='.gif') {
            $(img).attr('src', '');
            $(img).attr('src', imgsrc);

        }
    });
    setTimeout(function(){
        resetImages();
    },25000);
}
setTimeout(function(){
    resetImages();
},25000);

</script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Updated Property Tax Data]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2016/12/13/updated-property-tax-data/"/>
    <updated>2016-12-13T20:10:22-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2016/12/13/updated-property-tax-data</id>
    <content type="html"><![CDATA[<p>The property tax data for the City of Vancouver has been available for a while now, and with new assessment data becoming
available soon everyone&rsquo;s worried about what their property taxes will look like. The City just passed a 3.9% increase
in their budget, so on average everyone will pay 3.9% more taxes than they did last year.</p>

<p>The exact change in property taxes varies from property to property. There is a <a href="https://patrickjohnstone.ca/2013/01/on-assessments-and-mil-rates.html">nice overview</a>
on how this works in general, for the City of Vancouver there is an added complication of land value averaging meant to
soften sudden land value increases, that effectively serves to lower taxes for single family homeowners in a rising market.</p>

<p>If that&rsquo;s all to abstract for you, keep reading.</p>

<!-- more -->


<p><a href="https://mountainmath.ca/assessment_gl/map?zoom=15&lat=49.2672&lng=-123.1449" target="_blank"><img  src="http://doodles.mountainmath.ca/images/pt_animated.gif" style="width:50%;float:left;margin-right:10px;"></a>
To make the change in property taxes a little more transparent I have added a time slider to my
<a href="https://mountainmath.ca/assessment_gl/map?zoom=15&amp;lat=49.2672&amp;lng=-123.1449">Tax Density by Land Use Map</a> that I have
<a href="http://doodles.mountainmath.ca/blog/2016/03/02/property-taxes-and-land-use/">described previously</a>. So now people can
go back in time and see how property taxes changed and compare it to their neighbours. At the same time I
have updated the data on my <a href="">regular assessment data maps</a> to be based on the 2016 tax data, more background on the
tax data is in <a href="http://doodles.mountainmath.ca/blog/2015/05/31/density-in-vancouver/">this post</a>.</p>

<p>Check out the <a class='btn' href="https://mountainmath.ca/assessment_gl/map?zoom=14&lat=49.2814&lng=-123.1312" target="_blank">interactive map</a>.</p>

<p>This map also serves as a good reality check on the tax productivity of the land.</p>

<p>Some caveats: I am missing data for some years or some
properties, and this map aggregates property taxes for
all strata lots in a stratified property, you will have to dive into the data yourself if you want to see how it changed
on individual strata lots. Zoning and land use data stay at 2016 and don&rsquo;t animate back in time because of availability.</p>

<p>Special thanks to <a href="https://mapzen.com">Mapzen</a> for making it so ridiculously easy to make these maps and for
<a href="http://vancouver.ca/your-government/open-data-catalogue.aspx">Vancouver Open Data</a> and
<a href="http://www.metrovancouver.org/data">Metro Vancouver Open Data</a> for making that data available.</p>

<script>
function resetImages(){
    $('img').each(function(img){
        imgsrc = $(img).attr('src');
        if (imgsrc.slice(imgsrc.length-4)=='.gif') {
            $(img).attr('src', '');
            $(img).attr('src', imgsrc);

        }
    });
    setTimeout(function(){
        resetImages();
    },25000);
}
setTimeout(function(){
    resetImages();
},25000);
</script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Character Retention]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2016/11/26/character-retention/"/>
    <updated>2016-11-26T20:28:45-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2016/11/26/character-retention</id>
    <content type="html"><![CDATA[<p>Today I went to the City of Vancouver Character Retention open house. It was quite informative, city staff were helpful and knowledgeable,
and the display board and feedback form asked many good questions. But I came away with a couple of points that I think need to be addressed further:  </p>

<ul class="indented">
<li>Faux character retention vs character design guidelines. </li>
<li>Understanding economic drivers of teardown decisions.</li>
<li>Evaluation of RT character retention policies.</li>
<li>Need to separate character retention from gentle ground-oriented density. </li>
<li>New Carrots</li>
</ul>


<h3>TL;DR</h3>

<p>It gets a little wonky, so here the very short version:</p>

<ul class="indented bordered">
<li>
Current and proposed &#8220;character retention&#8221; is hollow, just retains shell. Should be handled in design guidelines.
</li>
<li>
Real character (or heritage) retention should take closer look at underlying economic drivers to become more effective.
</li>
<li>
Gentle, ground-oriented density like 4-plexes is desperately needed in RS and RT, should be decoupled from &#8220;character retention&#8221;.
</li>
</ul>


<!-- more -->


<h3>Faux Retention  </h3>

<p><img  src="http://doodles.mountainmath.ca/images/4-plex.png" style="width:50%;float:right;margin-left:10px;"> 
The existing character retention guidelines in RT, which seem to serve as a model for the expansion of character retention 
to RS, often don&rsquo;t &ldquo;retain&rdquo; all that much. </p>

<p>What the existing character retention process entails is essentially a &ldquo;character home&#8221; 
being gutted down to the studs (in most cases), potentially moved to a corner of the property and a foundation added. Then 
the entire house, including structural elements, gets build up again and infill added to the back.  </p>

<p>The result of the process is a main house with exterior form resembling a character home, and infill in the back matching
 the style. This process is almost indistinguishable from a new built to &ldquo;character design guidelines&rdquo;. The difference in 
landfill waste is minimal (and much better addressed through recycing policies) and there is no difference to the eye, 
as can easily be seen when comparing the new built infill to the &ldquo;retained&rdquo; front house, like in the Mt Pleasant 4-plex pictured above. </p>

<h3>Economics</h3>

<p>  Character retention is hard to do. It takes incentives to make it happen. The more the character retention process 
can leverage some underlying economic drivers, the more effective it will be.</p>

<p>  A while back <a href="http://doodles.mountainmath.ca/blog/2016/01/18/redevelopment/">we ran some analysis</a>
on 11 years of property-level assessment data in the City of Vancouver that was made available 
through the open data catalogue. The upshot is that the single most important factor that predicts if a building gets
 torn down is the (assessed) value of the building alone relative to the total value of the property. We call this 
quotient the &ldquo;teardown coefficient&rdquo; and found that if it is below 5%, the building has a 1/6 chance to get torn down 
within 8 to 10 years. More details and background on this
 <a href="http://doodles.mountainmath.ca/blog/2016/01/18/redevelopment/">can be found here</a>, a refinement of this analysis is works in progress.  
Currently, 34% of the SFH building stock in Vancouver fall into that category. Often people assume that the risk of a 
building getting torn down simply depends on the building age. But the relationship is not that simple as the following graph shows.  </p>

<div style="margin:10px 50px;padding:5px;border: 1px solid black;border-radius:5px;"> 
<div id="graph_sfh" style="height:200px;max-width:640px;" data-url="/data/sfh_age.json"></div> 
<div class="legend no-margin"></div> 
</div>


<p>  </p>

<p>The blue denotes properties facing little teardown pressure, the red is for properties with high teardown pressure. 
We can see that the pre-1920 building stock holds up reasonably well. In fact, 33% of the pre-1920 building stock with
 high teardown risk. For the 1920 to 1935 stock we have 59% of buildings in teardown territory, and for 1935 to 1965
 buildings that number jumps to 78%. This makes the particular choice of the character cutoff year 1940 a bit of a head-scratcher.</p>

<p>  <a href="https://mountainmath.ca/map/assessment?filter=[sfh,teardowns]&layer=100&zoom=13&lat=49.2489&lng=-123.1081&mapBase=2" target="_blank"><img  src="http://doodles.mountainmath.ca/images/teardowns2.png" style="width:50%;float:right;margin-left:10px;"></a> 
This informs the scale of the teardown pressure the building stock of a particular vintage is facing. We can similarly 
map the individual properties to understand their geographic distribution. One should note that assessment data, while 
unbiased in aggregate, can be quite off when looking at specific buildings. So when mapping for example
 <a href="https://mountainmath.ca/map/assessment?filter=[sfh,teardowns]&amp;layer=4">all single family homes with high teardown pressure</a> 
it might mis-identify some buildings as teardown candidates, or miss others. However, in aggregate the data will be
 quite robust and one can easily see that there are no obvious geographic biases in teardown risk. To quantify some of 
this, 31% of eastside SFH vs 39% of westside SFH face high teardown risk.  </p>

<p>Understanding the teardown pressure, as well as the geographic distribution and the pressures by vintage, gives an 
important baseline to the heritage and the character discussions. Houses far above the 5% threshold face little
 teardown pressure, and they need little, if any, policy protection to retain them. On the other hand, for houses
 below the teardown cutoff it makes very little economic sense to retain a building, and will require a 
lot of effort and policy protection to try and retain them. And even with these protections, there is a good chance
 that the building will eventually go or face &ldquo;demolition by neglect&rdquo;.  </p>

<p><img  src="http://doodles.mountainmath.ca/images/demo_by_neglect.png" style="width:40%;float:left;margin-right:10px;">  
One example of this is the property at 4755 Belmont Ave, which the city lists as heritage building of primary significance. </p>

<p>Effective retention policies are likely going to aim at the building stock around and somewhat above the teardown 
threshold of 5%. Ideally character retention policies should aim to strengthen the economic viability of buildings with
character merit so that they don’t fall into the range where the teardown pressure becomes overwhelming.</p>

<p>With this in mind, and setting the age cutoff to 1935 instead of 1940, we can investigate the existing pre-1935 building
 stock by teardown pressure, separating out the stock that faces 
<a href="https://mountainmath.ca/map/assessment?filter=[sfh,years_1935,tdc__0.05]&amp;layer=100&amp;zoom=13&amp;lat=49.2489&amp;lng=-123.1081&amp;mapBase=2">high teardown pressure</a> 
from the <a href="https://mountainmath.ca/map/assessment?filter=[sfh,years__1935,tdc_0.05_0.1]&amp;layer=101&amp;zoom=13&amp;lat=49.2489&amp;lng=-123.1081&amp;mapBase=2">stock with moderate teardown pressure</a> 
and the <a href="https://mountainmath.ca/map/assessment?filter=[sfh,years__1935,tdc_0.1]&amp;layer=102&amp;zoom=13&amp;lat=49.2489&amp;lng=-123.1081&amp;mapBase=2">stock with low teardown pressure</a>. 
  <a href="https://mountainmath.ca/map/assessment?filter=[sfh,years__1935]&layer=110&zoom=13&lat=49.2489&lng=-123.1148&mapBase=2" target="_blank"><img  src="http://doodles.mountainmath.ca/images/teardown_pressure.png" style="width:50%;float:right;margin-left:10px;"></a> 
And we can view <a href="https://mountainmath.ca/map/assessment?filter=[sfh,years__1935]&amp;layer=110&amp;zoom=13&amp;lat=49.2489&amp;lng=-123.1148&amp;mapBase=2">all three at the same time</a>.   </p>

<p>Without taking these underlying economic factors into consideration, character (as well as heritage) retention policies are 
likely to be less effective at retention than they otherwise would be. And have broader adverse effects on buildings
 without significant heritage or character merit.</p>

<p>The city’s approach to deal with heritage retention seems to be to target all properties built before 1940,
indiscriminate of what shape the buildings are in. In the next days the consultant report the city ordered will become
available, maybe there are some nuggets in there that make this whole endeavour sound reasonable.</p>

<h3>RT </h3>

<p>The current character retention effort is entirely focused on RS.  This seems to be motivated by the fact that RT already
 has character retention guidelines. The way it works is that much of RT is downzoned, with extra density conditional on
 character retention. This seems to be the basic blueprint of the proposal for RS, so let&rsquo;s take a close look how this works.  </p>

<p><a href="https://mountainmath.ca/map/assessment?filter=[zone_RT-6]&layer=20&zoom=16&lat=49.2587&lng=-123.1063&mapBase=2" target="_blank"><img  src="http://doodles.mountainmath.ca/images/rt-6.png" style="width:50%;float:right;margin-left:10px;"></a> 
Mount Pleasant gives a good example of what this can look like. In 
<a href="https://mountainmath.ca/map/assessment?filter=[zone_RT-6]&amp;layer=20&amp;zoom=16&amp;lat=49.2587&amp;lng=-123.1063&amp;mapBase=2">RT-6 zoning</a> 
we have allowed stratified 4 and 5-plexes on single family lots under the character retention policies. We have 
<a href="http://doodles.mountainmath.ca/blog/2016/08/04/rt/">looked at this before</a>, this results in the property getting sliced up and stratified into
 3 to 5 family-sized ground-oriented units. In terms of prices, the assessments pegged at July 2015 
(which became surprisingly accurate again) puts RT-6 single family lots between $1m and $6m (median $1.9m), and units in those
 multiplexes between $300k and $1.8m (median $800k).</p>

<p>  <a href="https://mountainmath.ca/map/assessment?filter=[zone_RT-7]&layer=20&zoom=15&lat=49.2636&lng=-123.1706&mapBase=2" target="_blank"><img  src="http://doodles.mountainmath.ca/images/rt-7.png" style="width:50%;float:left;margin-right:10px;"></a> 
This kind of development is great. We need more of that, much more. 
But this same model can&rsquo;t be immediately taken and expanded across the city. One look across town to 
<a href="https://mountainmath.ca/map/assessment?filter=[zone_RT-7]&amp;layer=20&amp;zoom=15&amp;lat=49.2636&amp;lng=-123.1706&amp;mapBase=2">RT-7</a>, 
where similar guidelines are in place, shows that multi-plexes only appear in the pocket at 16th and Arbutus. That&#8217;s 
mainly because the Mt Pleasant model of character &ldquo;retention&rdquo; requires large lots, and most of RT-7 is on smaller lots
 that make the process of &ldquo;retention&rdquo; into multi-plexes according to current city rules unattractive. The rules need to 
be amended to take lots size (and other parameters) into account to unlock this kind of development across the city.  </p>

<p>This resulted in RT-6 only having 12% of the building stock currently facing high teardown pressure, compared to 34% of
 RT-7. In the pocket of RT-7 east of MacDonald, where lots are larger and more properties underwent the character retention
 process, only 17% of the building stock faces high teardown pressure. And yes, RT-6 started out with buildings in a
better state than RT-7. Which is another part of the reason why the character retention program was more successful in RT-6.  </p>

<p>We can try to understand better where the character retention program was utilized and where it wasn&rsquo;t by looking at 
<a href="https://mountainmath.ca/map/assessment?filter=[zone_RT,years_2000,nzone_RT-11]&amp;layer=20&amp;zoom=13&amp;lat=49.2497&amp;lng=-123.1232&amp;mapBase=2">all the properties that have been built since 2000 in RT</a>, 
keyed by whether it was a single family, duplex or multi-plex that got built. We removed RT-11 from the map, it is too
 new to be meaningful. It&rsquo;s amazing to me how in some pockets almost no multi-plexes get built. We should try and fine-tune 
this process before transplanting it to RS.  RT-11 offers a cautionary tale. Looking at what got
<a href="https://mountainmath.ca/map/assessment?filter=[zone_RT-11,years_2000]&amp;layer=20&amp;zoom=15&amp;lat=49.2393&amp;lng=-123.0509&amp;mapBase=2">built in current RT-11 after 2000</a> 
we see lots of single family homes. A huge missed opportunity. If we had upzoned that area a decade earlier we could 
have allowed for homes that suit our families much better. </p>

<p>In summary, we should look carefully at how character retention performed in RT and going forward devise policies for RS and RT.
It’s time to drop that artificial divide that has been overtaken by the reality that RS already allows 3 units on each property, more than RT.</p>

<h3>Hostage Taking</h3>

<p>The display boards suggests that the current plan for &ldquo;character retention&rdquo; in RS is essentailly to copy over the RT
blueprint with some fine-tuning. Downzone RS and give density for undergoing &ldquo;character retention&rdquo;.</p>

<p>  In essence that&rsquo;s holding gentle, ground-oriented density hostage to character retention, and it&rsquo;s a terrible thing to do. Whatever the 
question is, downzoning can&rsquo;t be part of the answer any more. Vancouver is starved for gentle, sensible, ground-oriented 
family-friendly development.</p>

<p>  Originally, when the character retention guidelines for RT were made, this kind of gentle density came in the Trojan horse 
of character retention. And even if much of that was faux character, I don&rsquo;t mind. I take that kind of density any way I can.  
But we are quite a bit further along now. Unaffordability skyrocketed. Families are starved for housing options. </p>

<p>We need to scale this process up. And just expanding  the area where we deploy it to also cover RS won&rsquo;t do the trick.
We average about 10 RT character retention projects 
a year. Out of 11k RT properties. If we scale that up to all 68k RS properties, we will increase that number to about 70 
a year. Just for perspective to see how inadequate that is, we tear down around 1000 single family homes a year. 
And replace them with single family homes.  </p>

<p>What we need is a program that brings this type of density to RS and RT independent of the character retention program.
And let’s drop the &ldquo;retention&rdquo; pretence. If the character home look is what Vancouverites want in return for gentle
density, then let&rsquo;s prescribe the exterior look of new-builts and let the design review process  handle it.  </p>

<h3>New Carrots  </h3>

<p>If density won&rsquo;t be the main carrot (or a stick) for character retention, than what can pull up the slack? Property taxes is an obvious one.
 The owner could be allowed to re-claim property taxes against improvements and maintenance that aim to maintain or
 underline the character merit of the home. And these re-claimed taxes become cumulatively payable, with interest, in the
 event of demolition. Of course this would raise everyone else&rsquo;s property taxes, but I think that&rsquo;s only fair in return
 for the community dictating character-homeowners the exterior look of their home.</p>

<p>  The idea behind this is that this aims to directly strengthen the economic viability of the building, thus removing the 
economic drivers that favour tearing down the building. And over time accumulating a penalty that dissuades from
 tearing down the building.  </p>

<p>Density can still be part of the mix, but not in a way that it precludes smart gentle density to be built without
 it. The reality is that much of our building stock will go, the economic drivers are just too strong. And we all know that 
we should not replace those single family homes with yet another single family home that at best the top 5% income households 
can afford. We should allow these houses to be replaced with ground-oriented units a much larger portion of Vancouver 
families can afford.  </p>

<p>Smarter people than me have probably though about this for quite some time now. I would love to hear more ideas how 
character retention can be structured so that it does not get in the way of gentle density for new builts.   </p>

<script>

function stacked_bar_graph(div,shiftAxis,domainFormatter,rangeFormatter,domainLabelFormatter){
    if (!domainFormatter) domainFormatter=d3.format("d")
    if (!rangeFormatter)
     rangeFormatter = function (y) {
        return y;
     };
     if (!domainLabelFormatter) domainLabelFormatter=domainFormatter;

var margin = {top: 20, right: 20, bottom: 40, left: 70},
    width = parseInt(div.style("width")) - margin.left - margin.right,
    height = parseInt(div.style("height")) - margin.top - margin.bottom;

var x = d3.scale.ordinal()
    .rangeRoundBands([0, width], .1);

var y = d3.scale.linear()
    .range([height, 0]);


var xAxis = d3.svg.axis()
    .scale(x)
    .tickFormat(domainFormatter)
    .orient("bottom");


var yAxis = d3.svg.axis()
    .scale(y)
    .orient("left")
    .tickFormat(rangeFormatter)
    .ticks(5, rangeFormatter);

var svg = div.append("svg")
    .attr("width", width + margin.left + margin.right)
    .attr("height", height + margin.top + margin.bottom)
  .append("g")
    .attr("transform", "translate(" + margin.left + "," + margin.top + ")");

var data_url=div[0][0].dataset.url;
var legend=d3.select(div.node().parentNode).select('.legend');


d3.json(data_url, function(error, json) {
  if (error) throw error;
  var graphData=json[0];
  var data=graphData.data;
  var color = d3.scale.ordinal().domain(graphData.colors.map(function(d,i){return i}))
  .range(graphData.colors);
  var domain=data.map(function(d){return d.date;});
  x.domain(domain);

  function graphValueId(i){
      return graphData.class + '_' + i + '_value'
  }

  graphData.labels.forEach(function(text,i){
    var color=graphData.colors[i];
    var html='<i style="background:' + color + '"></i> ' + text + ' <span style="float:right;margin-right:10px;" id="' + graphValueId(i) + '"></span>'
    legend.append('p').html(html);
  });

  data.forEach(function(d) {
      var y0 = 0;
      d.values = color.domain().map(function(i) { return {date: d.date, y0: y0, y1: y0 += +d.count[i]}; });
      d.total = d.values[d.values.length - 1].y1;
  });
  y.domain([0, d3.max(data, function(d) { return d.total; })]);

  var domainTickValues=[];
  var skip=Math.round(40/x.rangeBand());
  if (skip<=0) skip=1;
  for (var i=0;i<x.domain().length;i++) {
    if (i % skip==0) domainTickValues.push(x.domain()[i]);
  }
  if (x.domain().length % 5 !=0) domainTickValues.push(x.domain()[x.domain().length-1]);
  xAxis.tickValues(domainTickValues);

  var xShift=shiftAxis ?  x.rangeBand()/2.0 * 1.1 : 0;

  svg.append("g")
      .attr("class", "x axis")
      .attr("transform", "translate(" + xShift + "," + height + ")")
      .call(xAxis);

  svg.append("g")
      .attr("class", "y axis")
      .call(yAxis);
//    .append("text")
//      .attr("transform", "rotate(-90)")
//      .attr("y", 6)
//      .attr("dy", ".71em")
//      .style("text-anchor", "end")
//      .text("Probability");

    function updateTooltip(d,i){
       color.domain().forEach(function(j){
             var value=d && i==j ? (domainLabelFormatter(d.date) + ': ' +rangeFormatter(d.y1-d.y0)) : '';
             d3.select('#'+graphValueId(j)).text( value);
       });
    }

  var year=svg.selectAll(".year")
    .data(data)
        .enter().append("g")
          .attr("class", "g");
  year.selectAll(".color-bar")
      .data(function(d) { return d.values; })
    .enter().append("rect")
      .attr("class", graphData.class + " color-bar")
      .attr("fill", graphData.color)
      .attr("x", function(d) { return x(d.date); })
      .attr("width", x.rangeBand())
      .attr("y", function(d) { return y(d.y1); })
      .attr("height", function(d) { return Math.max(0, y(d.y0) - y(d.y1)); })
      .attr("fill",function(d,i) {return color(i);})
      .on('mouseover',updateTooltip)
      .on('click',updateTooltip)
      .on('touch',updateTooltip)
      .on('mouseout',function(){updateTooltip(null,i)});


});

}


var priceFormatter2=d3.format("$,");
    var priceFormatter = function (y) {
        return y>=1000000 ? (priceFormatter2(y/1000000) + 'm') : (priceFormatter2(y/1000) + 'k');
    };
    var brackets=[100000,200000,300000,400000,500000,600000,700000,800000,900000,1000000,2000000,10000000,20000000,40000000]

var binFormatter=function(top){
    var bottom=0;
    if (top<=1000000) bottom=top-100000;
    else if (top==2000000) bottom= 1000000;
    else if (top==10000000) bottom= 2000000;
    else if (top=20000000) bottom= 10000000;
    else bottom=20000000;
    return priceFormatter(bottom) + ' - ' + priceFormatter(top);
}
var numberFormatter=d3.format(",");
var numberBinFormatter=function(top){
    var     bins=[0,1,2,4,8,10,16,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,300,400,500,700];
    var index=0;
    while (bins[index]<top && index<bins.length) index ++;
    bottom=bins[index-1]+1;
    return (bottom == top) ? numberFormatter(bottom) : numberFormatter(bottom) + ' - ' + numberFormatter(top);
}
stacked_bar_graph(d3.select("#graph_sfh"));
</script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interactive Isochrones]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2016/11/18/interactive-isochrones/"/>
    <updated>2016-11-18T10:22:29-08:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2016/11/18/interactive-isochrones</id>
    <content type="html"><![CDATA[<p><img  src="http://doodles.mountainmath.ca/images/isochrone.png" style="width:50%;float:right;margin-left:10px;">
Mapzen again upped their game by publishing their <a href="https://mapzen.com/documentation/mobility">Mobility API</a>. This is
super exciting for anyone interested in a whole range of mobility questions. A <a href="https://twitter.com/dnproulx/status/799644235720900608">question I have seen</a> is how to adapt that
to specific needs. So here is a quick example how to customize walksheds.</p>

<!-- more -->


<p>All we do is set up a quick map that computes the 5 and 10 minute
walksheds when the user clicks on the map.</p>

<iframe src="http://doodles.mountainmath.ca/isochrone.html#14/49.2775/-123.1292" width="80%" height="450" style="margin: 5px 10%;"></iframe>


<p>To get a better view you can also
<a href="http://doodles.mountainmath.ca/isochrone.html" target="_blank" class='btn btn-default'>take the map full-screen</a>.</p>

<p>Feel free to just <a href="http://doodles.mountainmath.ca/isochrone.html" download>grab the html</a> and adjust it for your needs. Please go and
register for your <a href="https://mapzen.com/developers/sign_in">free Mapzen API key</a> and replace the key in the downloaded
html file with yours. Refer to the <a href="https://mapzen.com/documentation/mobility">Mobility API</a> to customize this for your
needs.</p>

<p>Here is the relevant code to generate the isochrones:</p>

<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>var mapzenApiKey="&lt;your api key&gt;";
</span><span class='line'>var marker,isochrone;
</span><span class='line'>
</span><span class='line'>function httpGetAsync(theUrl, callback)
</span><span class='line'>{
</span><span class='line'>    var xmlHttp = new XMLHttpRequest();
</span><span class='line'>    xmlHttp.onreadystatechange = function() {
</span><span class='line'>        if (xmlHttp.readyState == 4 && xmlHttp.status == 200)
</span><span class='line'>            callback(xmlHttp.responseText);
</span><span class='line'>    };
</span><span class='line'>    xmlHttp.open("GET", theUrl, true); // true for asynchronous
</span><span class='line'>    xmlHttp.send(null);
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>map.on('click',function(e) {
</span><span class='line'>    if (marker) marker.removeFrom(map);
</span><span class='line'>    marker = L.marker(e.latlng).addTo(map);
</span><span class='line'>    var json={locations:[{lat:e.latlng.lat,lon:e.latlng.lng}],costing:"pedestrian",contours:[{time:5,color:"006400"},{time:10,color:"006400"},{time:15,color:"006400"}]};
</span><span class='line'>    var url='http://matrix.mapzen.com/isochrone?json='+JSON.stringify(json)+'&api_key='+mapzenApiKey;
</span><span class='line'>    httpGetAsync(url,function(data){
</span><span class='line'>        var geojsonFeatures=JSON.parse(data);
</span><span class='line'>        geojsonFeatures.features.forEach(function(f){
</span><span class='line'>            f.geometry.type="Polygon";
</span><span class='line'>            f.geometry.coordinates=[f.geometry.coordinates];
</span><span class='line'>        });
</span><span class='line'>        if (isochrone) isochrone.removeFrom(map);
</span><span class='line'>        isochrone=L.geoJSON(geojsonFeatures, {style: function(feature){return {color:'#'+feature.properties.color, opacity:feature.properties.opacity}}}).addTo(map);
</span><span class='line'>    });
</span><span class='line'>});</span></code></pre></td></tr></table></div></figure></notextile></div>


<p>Happy mapping.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Trick-or-Treat 2016]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2016/10/21/trick-or-treat-2016/"/>
    <updated>2016-10-21T20:38:14-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2016/10/21/trick-or-treat-2016</id>
    <content type="html"><![CDATA[<p><a href="https://censusmapper.ca/maps/529" target="_blank"><img  src="http://doodles.mountainmath.ca/images/tot_density.png" style="width:50%;float:right;margin-left:10px;"></a>
A year ago, as were were just getting CensusMapper up and running, we put out three Halloween-themed census maps. Those
maps almost broke our servers when they went viral. At least as viral as census data goes. They were viewed by over
150,000 Canadians over the course of three days. And many of those came back to view the maps more than once.</p>

<p>Lots of things have happened at CensusMapper since last year, and we heeded the call and put some of CensusMapper&rsquo;s prowess
to use to make some important improvements for this Halloween.</p>

<!-- more -->


<p>We are stuck in a weired place this year. We just completed the
<a href="https://twitter.com/NavdeepSBains/status/770281404848566273">most successful census in the Canadian history</a> this May,
but the results are still undergoing quality control and will only get released starting this coming spring. The 2011
census, that last year&rsquo;s maps are based on, is now 5 years old. Some children that were of prime trick-or-treating age
(which we take as 5 to 14 years old) in 2011 are now in College. And some that weren&rsquo;t even borne in 2011 will be out
knocking on doors this Halloween.</p>

<p>As people move around, the composition of neighbourhoods does not change all that much over time. Young kids grow up to take
the place of the older kids in the neighbourhood. That was our take last year, as we were still mapping 2011 data to
give people an idea how many kids would show up on their door or where to expect the most foot traffic.</p>

<h3>The maps</h3>

<p>Last year we made three maps, the
<a href="https://censusmapper.ca/maps/137">Trick-or-Treat Density map</a> that visualized the expected trick-or-treat foot traffic,
the <a href="https://censusmapper.ca/maps/136">Trick-or-Treat Onslaught Map</a> that visualized how many kids to expect at your
door and the <a href="https://censusmapper.ca/maps/138">Haunted House Map</a>
that&rsquo;s mapping homes occupied by ghosts and other &ldquo;unusual residents&rdquo;.</p>

<p>This year we improved on those maps by building a dynamic estimator that estimates conditions on the ground this Halloween. We
have:</p>

<table>
<tr>
<td style="width:25%;padding:3%">
<a href="https://censusmapper.ca/maps/529" target="_blank"><img  src="http://doodles.mountainmath.ca/images/tot_density.png" style="width:100%"></a>
</td>
<td style="width:25%;padding:3%">
<a href="https://censusmapper.ca/maps/528" target="_blank"><img  src="http://doodles.mountainmath.ca/images/tot_onslaught.png" style="width:100%"></a>
</td>
<td style="width:25%;padding:3%">
<a href="https://censusmapper.ca/maps/138" target="_blank"><img  src="http://doodles.mountainmath.ca/images/tot_haunted_houses.png" style="width:100%"></a>
</td>
<tr> 
</table>


<ul>
<li><p><a class='btn btn-success' href="https://censusmapper.ca/maps/529" target="_blank">Trick-or-Treat Density Estimator</a>
that estimates the number of children of prime trick-or-treat age per area, so the expected trick-or-treat foot traffic
in each area. Use this map if you plan on taking your kids out trick-or-treating and want to make sure you find the area
in your neighbourhood with the most kids out on the street.</p></li>
<li><p><a class='btn btn-success' href="https://censusmapper.ca/maps/528" target="_blank">Trick-or-Treat Onslaught Estimator</a>
that estimates the number of children of prime trick-or-treat age per doorbell. Use this map if you are guarding the door
and want to know how much candy you should have ready.</p></li>
<li><p><a class='btn btn-success' href="https://censusmapper.ca/maps/528" target="_blank">Haunted Houses Map</a> that shows
the houses that were occupied only by ghosts or <em>unusual residents</em> in May 2011. As ghosts and <em>unusual residents</em> tend
to be restless we were not comfortable making estimates where they may be now,
even with all of CensusMapper&rsquo;s power behind it. So we only have the 2011 map to give some inspiration where the best
chances might be to run into ghosts or cross paths with <em>unusual residents</em>.</p></li>
</ul>


<h3>How did we estimate things for 2016 Halloween?</h3>

<p>An skillful estimator strikes a balance between simplicity and effectiveness. We decided to make use of the
following data:</p>

<ul>
<li>The number of children in the age brackets 0-4, 5-9 and 10-14 in each area in 2011.</li>
<li>The number of children in the age brackets 0-4, 5-9 and 10-14 in each area in 2006.</li>
<li>The percentage of the population in each area in 2011 that did not move between 2006 and 2011.</li>
</ul>


<p>Based on this, we split the estimate of the number of children in each area in 2016 into two groups. Children that
already lived in the are in 2011 and still live there in 2016, and children that moved into the area between 2011 and 2016.
We estimate the proportion by using the proportion of people that did not move between 2006 and 2011 as a proxy.</p>

<p>Then estimating the number of children that did not move is easy, we simply age the children we saw in 2011 forward by
five years and weight them by the proportion of non-movers.</p>

<p>To estimate the number of children moving into the area take into account at the trends from 2006 to 2011 in each area
and extrapolate from there to 2016. And weight the number by the proportion of the population that did move and also
allow for some population growth according to the 2006 to 2011 trend.</p>

<p>I will spare you the exact formula. It is possible that refining the model and adding in more variables could make some
improvements to the estimates, but overcomplicating the model also leads to risks of exaggeratig biases. We feel that
our simplistic model strikes a good balance between simplicity and effectiveness. It will be interesting to see how we
did when 2016 data comes in.</p>

<h3>The Super Nerdy Details</h3>

<p>For the data nerds still reading, the CensusMapper servers actually don&rsquo;t do any of that work. They just server straight-up
census data. Plus the instructions of how to use the data to make the map. All the computations and drawings are then
done locally on each user&rsquo;s browser. That&rsquo;s what keeps our servers
lean, responsive, and most importantly maintains maximum flexibility. With the same process we can easily map any function
built from census variables. Canada-wide and across all the entire geographical census hierarchy, from all of Canada down
to Dissemination Areas and, for some data, even Dissemination Blocks. Bwetween the 2006 and 2011 census
variables and all the different geographic regions we have about 1 billion fields in our database that we can map
dynamically. Still a far cry from &ldquo;big data&rdquo;, but enough to require some careful architecture choices.</p>

<h3>Census Mapping for Everyone</h3>

<p>Census data can be very complex and mixing various variables is powerful yet prone to produce meaningless maps due to
misinterpretation of the census variables. Since last Halloween and now we are proud to have been able to open up some
of CensusMapper&rsquo;s capabilities to the general public. Everyone can now make Canada-wide interactive maps based on single
2011 census variables via a couple of mouse clicks and share the freely. You can read more about this
<a href="http://doodles.mountainmath.ca/blog/2016/05/04/census-mapping-for-everyone/">in a previous blog post</a> or
<a href="https://censusmapper.ca/maps/new">jump right in and make your own map</a>.</p>

<h3>FAQ</h3>

<p>Here are some of the questions we got most last year:</p>

<h5>Are the maps only for Vancouver?</h5>

<p>No. All CensusMapper maps are fully interactive and by default Canada-wide. Use the search function or geo-location
button to switch to any place in Canada that tickles your interest. Pan and zoom around to explore. You can always share
the current view of the map with your friends by grabbing the URL in your browser address bar or using the build in share buttons.</p>

<h5>What&rsquo;s the difference between the Trick-or-Treat Density and the Trick-or-Treat Onslaught map?</h5>

<p>The maps are related, both map the number of children of prime trick-or-treat age, but they are normalized differently.
The Density map considers the number of children per area. This estimates how many you will see out on the street in the area.
The Onslaught map considers the number of children per door, so you can estimate how many will come knocking.
The difference can be seen in high density areas like Yaletown in Vancouver. There are a lot of kids living in Yaletown
in a fairly small area, so the expected foot traffic is high. But these kids distribute over the units in the highrises
there and on a per household (or per door) basis, the number of kids per household does not stand out.</p>

<h5>How accurate are the predictions?</h5>

<p>Accuracy of predictions vary. Some parents will drive their kids halfway across town to find the best area for
trick-or-treating. Some areas change too fast for our estimator to catch on. And some neighbourhoods have traditions and
local areas where kids congregate that we don&rsquo;t have data for. So these maps are best use in conjunction with local data.</p>

<h5>Won&rsquo;t your maps lead to more people trick-or-treating outside of their neighbourhood?</h5>

<p>While our maps can be used to facilitate driving kids across town to trick-or-treat, we encourage everyone to also
use the map to find areas near
where they live, and where the kids can walk to. We believe an important part of the Halloween experience is for everyone
to get to know their own neighbourhood better, see things in a new light and experience the
joys of running into friends and acquaintances, and making new friends, along the way.</p>

<h5>I am running out of candy / I got way too much candy!</h5>

<p>The Onslaught map just estimates the average number of children that knock on doors in each area. Some doors will see a
lot more kids than others. Take the Yaletown example from above. Most
of the action happens on the street. So while on average people can only expect a moderate number of trick-or-treaters
at their door, the ones at ground level will be <em>very</em> busy, while the ones higher up will likely just see one or two
neighbour kids from the same floor.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Secondary Suites and Taxes]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2016/10/04/secondary-suites-and-taxes/"/>
    <updated>2016-10-04T14:59:20-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2016/10/04/secondary-suites-and-taxes</id>
    <content type="html"><![CDATA[<p><a href="https://censusmapper.ca/maps/519#12/49.2597/-123.1243" target="_blank"><img  src="http://doodles.mountainmath.ca/images/secondary_suites.png" style="width:50%;float:right;margin-left:10px;"></a>
A couple of weeks ago I started thinking about secondary suites, laneway houses and taxes in the City of Vancouver. The number
of secondary suites and laneway houses has been continuously growing. Rental income
is probably one of the main reasons people choose to activate a secondary suite. What are the tax implications?</p>

<!-- more -->


<h2>Secondary Suites</h2>

<p>How many secondary suites are out there? Nobody really knows, but we have some estimates. Comparing single family properties
from the assessment roll to census counts provides one estimate. This is likely a lower bound as the census is prone to
undercount suites. Using this method, we arrive at a lower bound of 30,000 single family properties with a suite in 2011,
up from about 27000 in 2006. The <a href="https://censusmapper.ca/maps/519#12/49.2597/-123.1243">above map</a> gives a rough idea
of their location, although it also includes the roughly 2000 stratified duplex properties.</p>

<p>Of these we estimate that 7,000 had more than one suite in 2011, with a similar number in 2006. The number of laneway houses was
quite small in 2011, likely less than 400. But by now the number has grown to over 2,000.</p>

<p>In total that adds up to an estimated around 37,000 suites in the city of Vancouver in 2011. Probably more in the
recent 5 years, maybe fewer in the years between 2006 and 2011. Most of these will be operated as suites, with the main
unit serving as a principal residence of the property owner. But this also includes investment properties where each
unit, including the main unit in the house, are rented out.</p>

<p>For this post we will focus entirely on the suites. We might expand on this analysis at some later point and separate
out owner-occupied homes from investment properties. Moreover we will use the more conservative estimate of 30,000
suites. Feel free to adjust that estimate in the interactive at the bottom see how this effects the estimates we make.</p>

<h2>Income Tax</h2>

<p>Secondary suite rental income needs to be recorded on
<a href="http://www.cra-arc.gc.ca/E/pbg/tf/t776/t776-15e.pdf">CRA form T776</a> and, after claiming deductions, taxed.</p>

<p>Estimating the average suite rental income at $1,000, claiming $200 in deductions leaves us with $800 or $9,600 in
monthly taxable income. With single family homeowners generally above the median income we use a marginal tax rate of 35%
to estimate $3,360 of taxes per secondary suite, so cumulative $100,800,000 in income taxes payed on secondary suite
rental income in the City of Vancouver.</p>

<h2>Capital Gains Tax</h2>

<p>Assessing the capital gains implications is more complex. The capital gains exemption applies to a <em>housing unit</em>. If a
property with several housing units is sold, only the capital gains attributed to the unit used as principal residence
is exempt from taxation. Typically the portion of taxable gains is determined by the relative areas of the rented and
principal residence parts of the home.</p>

<p>So the question whether the portion of a house taken up by a secondary suites is exempt from capital gains essentially
boils down to the question whether or not the secondary suite counts as a &ldquo;self–contained domestic establishment
for earning rental income&rdquo; or as &ldquo;one or more rooms in the home&rdquo;. I have asked the CRA to clarify how this would apply
to someone converting a portion to a house to secondary suite or building a laneway house, to which I got the following
response.</p>

<blockquote><p>The conversion of a portion of a house that otherwise is the taxpayer’s principal residence for the purpose of earning income or the creation of a separate building or structure on land that forms part of the taxpayer’s principal residence for the purpose of earning income are examples of structural changes that would result in a deemed disposition and reacquisition of a portion of the property.</p></blockquote>

<p>Similarly, when a homeowner deactivate a suite and absorbes it into their main residence that would trigger another
<a href="http://www.cra-arc.gc.ca/tx/tchncl/ncmtx/fls/s1/f3/s1-f3-c2-eng.html#N10BCD">&ldquo;deemed disposition (and reacquisition) thereof at fair market value&rdquo;</a>.
Which then would trigger a &ldquo;taxable capital
gain attributable to the period of use of such portion of the property for income–producing purposes&rdquo;, just like it
would at a sale of the property.</p>

<p>In the case when the homeowner rents out their entire home and later moves back in again, the homeowner can, under
certain circumstances, make an election that he can maintain the primary residence status for most recent 4 years during
which the home was rented out. I have asked the CRA to clarify if a similar election could be made for a secondary suite,
when for example after four years of renting the suite is deactivated and again absorbed in the main house and the response
was that &ldquo;such an election cannot be made where there is only a partial change in use of the property.&rdquo;</p>

<p>Based on this I am fairly convinced that the portion of a home used as a secondary suite or laneway house is not exempt
from capital gains tax. Despite my best efforts I might still be reading this wrong, in which case I would love to have
an expert weight in on this.</p>

<h3>Estimating Capital Gains Generated by Suites</h3>

<p>To estimate the amount of capital gains tax based on secondary suites expected to accrue annually in the City of Vancouver
we use the inflation-adjusted land value gain of a home as a
proxy for the portion of the appreciation of the property that is not due to improvements the owner made to the home, i.e.
the portion that would be subject to capital gains tax if this wasn&rsquo;t a primary residence.</p>

<p>To compute the taxable gains for an individual property we take the difference between the current land value and the
(inflation-adjusted) present land value at the time the property was bought. To simplify things a little we will consider the
current average (over SFH with suite) land value, the average holding period (years between buy and sell), and the
average inflation-adjusted land value gains. This can be refined, but should suffice for our purposes.</p>

<p>Going back to our estimate, the current (July 2015) average land value of single family homes was $1,640,000. Suites skew toward
the east, where average land value was $1,080,000. We roughly average these and take $1,300,000 as our base value. As
average holing period we take 10 years, and we compute the average inflation-adjusted land value gain between 2005
and 2015 at 10.4% (9.7% on east side). So let&rsquo;s use 10%.</p>

<p>That gives an estimate of the annual land value gain of $850,000 over 10 years, or $85,000 on average per year.
As a sanity check, this is in line with estimates of average annual land value gain for single family properties
<a href="http://doodles.mountainmath.ca/blog/2016/01/24/work-vs-twiddling-thumbs/">we have done before</a>, although these weren&rsquo;t
inflation-adjusted.</p>

<p>Roughly estimating that on
average a secondary suite takes up about a quarter of the area of a
house, we attribute $21,250 of the $85,000 annual land value gains to the secondary suite for tax purposes.</p>

<p>Of course capital gains tax are only payable when the property sells, but the yearly average gains accumulate and eventually
properties will sell. In which case we expect capital gains taxes to be payed on $21,250 per year the suite was rented.
So if a person sells a home with a suite that was rented for the last 10 years, the person will have to pay capital gains
taxes on $212,500. On average, we expect $21,250 of taxable capital gains income per house with suite per year.</p>

<p>The way capital gains tax works is that half of the gains are taxed at the marginal tax rate. As these tend to be large
sums of money at a time, it is safe to assume that the the effective tax rate on the gains is relatively high, say 35% or
more. Some of the taxes could be deferred by e.g. transferring the gains into RRSPs and later taxed at a lower rate. But
we will ignore this, it has the effect of lowering the effective tax rate on the gains and move the tax payments into the future,
but will not effect the overall amount of capital gains declared.</p>

<p>Assuming an effective tax rate of 35% on the gains we expect on average $3,700 of taxes payed per home with suite per
year through this mechanism. With
conservatively estimated 30,000 secondary suites in Vancouver that adds up to a tidy sum of $111,000,000 for capital gains
taxes paid due to secondary suites in the City of Vancouver. Per year.</p>

<h2>To Rent or Not to Rent Out a Suite</h2>

<p>In the case of rental suites with owner-occupied main portion the suite incurs both income and capital gains tax obligations.
This begs the question what minimum rent is required
to offset the capital gains obligations in a particular year. Typically homeowners don&rsquo;t know the annual value value gains
ahead of time, so this is more of an academic exercise than a practical questions. The important takeaway is that the
capital gains exemption has the effect of dramatically lowering the cap rate for converting part of a principal residence
into a rental unit.</p>

<p>The math is quite simple, we need to compare the net rental income (rent minus deductions) to the capital gains taxes
payable due to the rental. A more comprehensive way to look at this is to look at the
CAP rate based on land value investment, in this case the net rental income (after-tax rental income minus deductions)
per land value attributed to the suite. With our standard assumptions this sits at 1.9%.</p>

<p>This we can compare to the effective tax rate on the capital gains, which is given by multiplying half of the tax rate
(as only half the gains are taxed at that rate) with the rate of land value rise, which comes in at 1.75% with our standard assumptions.</p>

<p>To conclude this calculation we define the net cap rate as the difference between the cap rate and the effective tax rate
on the capital gains. If this is positive, it is the advantageous to rent. If it is negative, leaving the property vacant
will yield higher returns.</p>

<p>More specifically if we want to understand if it was advantageous to rent out a suite in a particular year for a particular
property we can adjust the assumptions in the interactive at the bottom accordingly. For example, in the year 2015 we
saw an average land value gain of about 20%. Adjusting the rate in the interactive, and setting the holding period to 1 year,
we get a net CAP rate of -1.6%. The break-even rent, above which it is advantageous to rent out the suite, was $1,820.</p>

<h2>Taxes Collected</h2>

<p>It would be interesting to compare these estimates with actual taxes collected. But this won&rsquo;t be easy without internal
CRA data. The census for example does not break out rental income. But it does break out capital gains income. Not all
capital gains income stems from selling homes with secondary suites of course and again, the census does not break out
the sources of the capital gains income. But capital gains income is rare enough, especially on the suite-heavy east side,
to yield some information.</p>

<p><a href="https://censusmapper.ca/maps/480#11/49.2360/-123.1361" target="_blank"><img  src="http://doodles.mountainmath.ca/images/capital_gains.png" style="width:50%;float:left;margin-right:10px;"></a>
In the City of Vancouver, a total of
$830 million of net capital gains and losses was reported to the CRA in 2010,
most of which was claimed by people living on the west side. When comparing
to 2010 taxes we should adjust our calculation to the average east side single family land value of $620,000 in 2010 and
might want to assume a very conservative inflation-adjusted land value gain of 5% per year (I have no data before 2005,
but one could use sales data to estimate this better). This would yield an expected taxable annual capital gains of $10,000
per suite in each area (with expected annual taxes generated of $1,750 per suite), adding up to over one third of all
capital gains reported in the City of Vancouver that year. And that&rsquo;s not counting taxable capital gains from selling
investment properties that were not used as principal residence at all and where all the gains are taxable. Or any other
source of capital gains income.</p>

<p><a href="https://censusmapper.ca/maps/480">Eyeballing the total capital gains reported</a>  suggests that tax compliance could be improved. It seems that the
changes in requiring the reporting of a sale of a principal residence that were announced yesterday will do just that.</p>

<h2>Interactive</h2>

<p>For people interested in adjusting the assumptions made for these estimates I made a quick interactive to facilitate this.
Adjust to fit your own assumptions.</p>

<h4>Assumptions</h4>

<table style="border-spacing:1em 0;border-collapse:separate;margin-bottom:20px;">
<tr><td>Secondary Suites</td><td><input type="range" id="suite"></td><td id="suiteValue"></td></tr>
<tr><td>Average Portion of House Taken by Suite</td><td> <input type="range" id="area"></td><td id="areaValue"></td></tr>
<tr><td>Average Rent</td><td> <input type="range" id="rent"></td><td id="rentValue"></td></tr>
<tr><td>Average Rent Deductions</td><td> <input type="range" id="deductions"></td><td id="deductionsValue"></td></tr>
<tr><td>Average Marginal Tax Rate</td><td><input type="range" id="tax"></td><td id="taxValue"></td></tr>
<tr><td>Average SFH Land Value</td><td><input type="range" id="land"></td><td id="landValue"></td></tr>
<tr><td>Average SFH Holding Period</td><td><input type="range" id="years"></td><td id="yearsValue"></td></tr>
<tr><td>Average Inflation-Adjusted Land Value Gain</td><td><input type="range" id="gain"></td><td id="gainValue"></td></tr>
</table>


<h4>Computed Quantities of Interest</h4>

<table style="border-spacing:1em 0;border-collapse:separate;margin-bottom:20px;">
<tr><td>CAP Rate</td><td id="cap_rate"></td></tr>
<tr><td>Effective Cap Gains Tax Rate</td><td id="effective_tax_rate"></td></tr>
<tr><td>Net CAP Rate</td><td id="net_cap_rate"></td></tr>
<tr><td>Break-Even Rent</td><td id="minimal_rent"></td></tr>
</table>


<h4>Annual Taxes Generated</h4>

<table style="border-spacing:1em 0;border-collapse:separate;margin-bottom:20px;">
<tr><td>Annual Income Tax Generated</td><td id="income_tax"></td></tr>
<tr style="display:none;"><td>Average Annual Adjusted Total Land Value Gain</td><td id="av_lv_gain"></td></tr>
<tr><td>Annual Cap Gains Tax Generated</td><td id="cap_gains_tax"></td></tr>
<tr><td>Annual Total Tax Generated</td><td id="total_tax"></td></tr>
</table>




<div><script>
var percentageFormatter=d3.format(".1%");
var currencyFormatter=d3.format("$,.3r");
var numberFormatter=d3.format(",.0f");

var suiteValue=30000,
    rentValue=1000,
    deductionsValue=0.2,
    landValue=1300000,
    gainValue=0.1,
    yearsValue=10.0,
    areaValue=0.25,
    minimalRentValue=1000,
    taxValue=0.35;
document.getElementById('suite').value=(suiteValue-20000.0)/400.0;
document.getElementById('rent').value=(rentValue-500)/20;
document.getElementById('deductions').value=deductionsValue*100;
document.getElementById('area').value=areaValue*100;
document.getElementById('tax').value=taxValue*100;
document.getElementById('gain').value=(gainValue+0.1)/0.6*100;
document.getElementById('land').value=(landValue-200000)/20000;
document.getElementById('years').value=(yearsValue-1)*5;

function updateResults(){
   $('#suiteValue').html(numberFormatter(suiteValue));
   $('#rentValue').html(currencyFormatter(rentValue));
   $('#deductionsValue').html(percentageFormatter(deductionsValue));
   $('#areaValue').html(percentageFormatter(areaValue));
   $('#taxValue').html(percentageFormatter(taxValue));
   $('#landValue').html(currencyFormatter(landValue));
   $('#gainValue').html(percentageFormatter(gainValue));
   $('#yearsValue').html(numberFormatter(yearsValue));

   var value1=suiteValue*rentValue*(1-deductionsValue)*taxValue*12.0;
   $('#income_tax').html(currencyFormatter(value1));
   var lvGain=landValue*(1-Math.pow(1-gainValue,yearsValue))/yearsValue;
   var value2=suiteValue*taxValue*areaValue*lvGain/2.0;
   $('#av_lv_gain').html(currencyFormatter(lvGain));
   $('#cap_gains_tax').html(currencyFormatter(value2));
   $('#total_tax').html(currencyFormatter(value1+value2));
   var minimalRent=landValue*areaValue*gainValue/2*taxValue/(1-taxValue)/(1-deductionsValue)/12.0;
   $('#minimal_rent').html(currencyFormatter(minimalRent));
   var capRate=rentValue*12*(1-deductionsValue)*(1-taxValue)/(landValue*areaValue);
   $('#cap_rate').html(percentageFormatter(capRate));
   var effectiveRate=taxValue/2.0*gainValue;
   $('#effective_tax_rate').html(percentageFormatter(effectiveRate));
   $('#net_cap_rate').html(percentageFormatter(capRate-effectiveRate));
}

$('#suite').on('change',function(){
    suiteValue=parseFloat(this.value)*400.0+20000.0;
    updateResults();
});
$('#area').on('change',function(){
    areaValue=parseFloat(this.value)/100.0;
    updateResults();
});
$('#rent').on('change',function(){
    rentValue=parseFloat(this.value)*20+500;
    updateResults();
});
$('#land').on('change',function(){
    landValue=parseFloat(this.value)*20000+200000;
    updateResults();
});
$('#deductions').on('change',function(){
    deductionsValue=parseFloat(this.value)/100.0;
    updateResults();
});
$('#gain').on('change',function(){
    gainValue=parseFloat(this.value)/100.0*0.6-0.1;
    updateResults();
});
$('#years').on('change',function(){
    yearsValue=Math.round(parseFloat(this.value)/5.0 + 1.0);
    document.getElementById('years').value=(yearsValue-1)*5;
    updateResults();
});
$('#tax').on('change',function(){
    taxValue=parseFloat(this.value)/100.0;
    updateResults();
});

updateResults();
</script></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sea Level Rise]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2016/10/02/sea-level-rise/"/>
    <updated>2016-10-02T21:22:25-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2016/10/02/sea-level-rise</id>
    <content type="html"><![CDATA[<p><a href="https://mountainmath.ca/elevation/map?sea_level=10&zoom=12&lat=49.2629&lng=-123.1176" target="_blank"><img  src="http://doodles.mountainmath.ca/images/van_sea_level.png" style="width:50%;float:right;margin-left:10px;"></a>
Sea level rise comes up regularly in coastal cities. And nowadays every costal area,
<a href="http://www.env.gov.bc.ca/wsd/public_safety/flood/pdfs_word/cost_of_adaptation-final_report_oct2012.pdf">including Vancouver</a>
has their flood assessment and detailed plans on how to deal with sea level rise, although some plans are
<a href="http://www.sfu.ca/rise/entries/Prescribe-mountains.html">more interesting than others</a>.</p>

<p>The web is awash with sea level rise maps, some static, some interactive, <a href="http://geology.com/sea-level-rise/">some global ones</a>
and some <a href="https://coast.noaa.gov/slr/">national maps</a>. Data sources range from high detail LIDAR data to satellite data
and other datasets. When Mapzen put out their <a href="https://mapzen.com/blog/elevation/">global elevation tiles</a> I gave it a quick
test drive to check it out and then forgot about it. When the topic inevitably
<a href="https://twitter.com/toddsmithdesign/status/782273909265620992">bubbled up on my twitter feed</a> I decided to do some
minimal styling using Mapzen&rsquo;s <a href="https://mapzen.com/products/tangram/">ridiculously easy to use Tangram map engine</a> and
added a search bar to make it easier to jump to different locations on the globe.</p>

<p>That&rsquo;s all there is to this. Check out <a class="btn btn-default" href="https://mountainmath.ca/elevation/map?sea_level=10&zoom=12&lat=49.2629&lng=-123.1176">yet another interactive global seal level rise map</a>.</p>

<p>The preset for the sea level rise is 10m, which is a little excessive. Current predictions hover around 1m until 2100.
Adjust the slider to see how the flooded areas change depending on the simulated sea level rise.</p>

<p>The map is global, and it&rsquo;s worthwhile to compare Vancouver&rsquo;s sea level threat to that of other places, for example
<a href="https://mountainmath.ca/elevation/map?sea_level=0&amp;zoom=9&amp;lat=52.8774&amp;lng=5.5701">Holland where 21% of the country is below current sea level</a>,
not counting any future sea level rise.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Measuring Housing Affordability]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2016/09/14/measuring-housing-affordability/"/>
    <updated>2016-09-14T12:06:06-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2016/09/14/measuring-housing-affordability</id>
    <content type="html"><![CDATA[<p><a href="https://mountainmath.ca/assessment/split_map" target="_blank"><img  src="http://doodles.mountainmath.ca/images/sfh_price_2015.png" style="width:50%;float:right;margin-left:10px;"></a>
Housing affordability is a serious issue that deserves attention. Affordability is generally defined comparing incomes
to housing costs. And ideally also factoring in transportation cost, although that&rsquo;s seldom done and we will not attempt
today.</p>

<p>Recently we <a href="http://doodles.mountainmath.ca/blog/2016/08/31/incomes/">took a detailed look at income data</a>. Using what we
learned, together with our
<a href="https://mountainmath.ca/assessment/split_map">detailed data on the development of prices of single family properties in Vancouver</a>,
we turn to the never dying question of affordability of single family homes.</p>

<!-- more -->


<p><a href="https://mountainmath.ca/assessment/split_map?year=2010" target="_blank"><img  src="http://doodles.mountainmath.ca/images/sfh_price_2010.png" style="width:50%;float:left;margin-right:10px;"></a>
Let&rsquo;s go through the motions of how different choices in income data can lead to different stories. Some general choices of
what income to use is often pretty obvious. Others are more subtle and a matter of judgement. For simplicity we focus
entirely on the situation in 2010, because that&rsquo;s the last year we have detailed income data for the City of Vancouver
and we also have <a href="https://mountainmath.ca/assessment/split_map?year=2010">detailed publicly available single family housing price data</a>.</p>

<p>When talking about housing, the starting point is to look at income of (private) households (as opposed to individual income).
We may also want to consider the owner-renter split in the region we are interested in. For simplicity we will skip this.</p>

<h3>Household Income</h3>

<p>Households are as diverse as
dwelling types. If we write a story about single family housing, household income of all households is too broad to be
relevant. For example,
in the city of Vancouver there are about 75,500 single family lots, but 264,573 households. So at most 28% of households
can live in the main house on a single family lot. Taking the median household income makes no sense in this situation.
We need to narrow down the target group. In Calgary on the other hand,
59% of the dwelling stock is single detached (and there are more properties if we count the ones with suites like we
did for Vancouver), so in that case the assumption that the median household is looking to buy a single family home is
more reasonable. Although the median household probably won&rsquo;t be looking to buy the median single family home but a lower-priced one.</p>

<h3>Family Income</h3>

<p>So how should we measure the affordability of single family properties? That&rsquo;s not an easy question. A natural choice may
be to focus in on the 151,330 census families in Vancouver. Again, there are more than twice as many candidates as single
family properties. So maybe narrow it down even further an only look at the 88,515 census
families with children at home. Or the 63,790 couple families with children at home. Realistically speaking, even
going with couple families with children at home there just aren&rsquo;t enough single family properties to go around. Unless we
are willing to force out all of the roughly 45% of the occupants of the main house on single family lots that currently only have
1 or 2 people living in there. But overall, couple families with children is probably a better metric for affordability
for single family homes. Others will of course also buy single family homes, but maybe we will be less worried if
they can&rsquo;t afford one.</p>

<h3>Family with Children Income</h3>

<p>To complete the example, in 2010 the median single family property cost $848,000 (average $1,133,000) and the median
couple family with children income in private households was $92,068 (average $123,252).
That gives a dwelling value to income ratio of around 9.2, showing that the median single family property is not
affordable for the median couple family with children. By affordable we mean that with a 20% down payment the shelter
costs stay below 30% of pre-tax income, which requires a ratio of at most 6.6 assuming an interest rate of 3% and 25
years amortization.</p>

<p>If we were to more realistically assume that the median income couple family with children were to look to buy a single
family property priced at the 10 percentile level of $606,100 we get a dwelling value to income ratio of 6.6, barely
squeezing in below our affordability cutoff.</p>

<h3>Matching Income Quantiles with Housing Quantiles</h3>

<p>Another way to slice the data is to look at the household income distribution. By definition there are 37,750
single family homes more expensive than the median single family home. From the income distribution there are 44,215
households with income over $125,000. Taking $125,000 as our income we get a median dwelling value to income ratio of 6.8.
Only when throwing in some secondary suite rental income can we get to the
&lsquo;barely affordable&rsquo; 6.6 ratio. Adding rental income is double-dipping though, rental income should already be
included in our total income numbers. Assuming secondary suite rental income is correctly reported.</p>

<h3>Using Median Household Income</h3>

<p>Using the household income instead we would have gotten a ratio of 13.4, which is ridiculously unaffordable. But then
again, the notion that the median household should be able to purchase the median single family property
(or even a low-value single family property) is also ridiculous.</p>

<p><a href="https://censusmapper.ca/maps/37" target="_blank"><img  src="http://doodles.mountainmath.ca/images/local_affordability_index.png" style="width:50%;float:right;margin-left:10px;"></a>
Somewhat more reasonable is to <a href="https://censusmapper.ca/maps/37">compare household income to all housing</a>,
not just single family. This still ignores that
half of the population in Vancouver is renting, but still can yield some interesting insights if one is interested in
more detailed spatial distribution of affordability and compare it to other cities.</p>

<p>Adding a scatter plot of local affordability index by proportion of owner households shows how in Vancouver, unlike
in comparable cities, the percentage of owner households is a weak determinant of local affordability.</p>

<h3>What about Affordability Today?</h3>

<p>This analysis assumes that all these households are comfortable to max out when buying a home and that there are no other
competing significant financial obligations like heavy student loans. And, just as a reminder, we were looking at 2010.
As of 2015 the price of the median single family home has increased 67%. We don&rsquo;t have 2015 income numbers for the City of
Vancouver (yet), but Couple Family median income for Metro Vancouver has increased 13% between 2010 and 2014, the last
year with available data. Extrapolating out that trend to 2015, and assuming that whatever other income metrics we were
looking at, we get an estimated income increase by 16%. So any affordability ratio is about 1.4 times worse in 2015 compared
to the 2010 ratio. What may have been &lsquo;barely affordable&rsquo; in 2010 is clearly unaffordable in 2015.</p>

<p>So we used the detailed income data available for 2010 to get very good understanding of the affordability situation in 2010.
Then we used regional income trends to extrapolate that data to 2015 and matched it with 2015 housing data to get more up-to-date
estimates. This is generally an effective method that yields good results.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Quick Guide to Income Data]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2016/08/31/incomes/"/>
    <updated>2016-08-31T09:17:12-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2016/08/31/incomes</id>
    <content type="html"><![CDATA[<p>The news media has an extraordinarily difficult time with income data. And that&rsquo;s only partially the media&rsquo;s fault.
In general, income data is a funny beast. So I decided to give a quick overview over income data that&rsquo;s available through
Statistics Canada. To make things a little more concrete I focused on Vancouver as an example, but everything applies
equally well to any other area in Canada.</p>

<p>Most journalists I talked to care about accurate and relevant statements. If that&rsquo;s you, you will need to keep reading
and dive down the slightly wonkish income rabbit hole.</p>

<p>For those that don&rsquo;t really care, I made a
<em>quotable random income generator</em>. Just hit the &ldquo;generate&rdquo; button copy &amp; paste the result and link this post as source.
(Use at own risk!)</p>

<!-- more -->




<div class='income-generator'>
    <div class='income-choices'>
        <div class="geo"></div>
        <div class="med_av"></div>
        <div class="tax"></div>
        <div class="hh"></div>
        <div> income is </div>
        <div class="income"></div>
    </div>
    <a class="btn btn-default" style="background:orange;">Click to Generate Random Income Numbers</a>
</div>


<p>The income numbers don&rsquo;t fit the story? No problem, just play again until you get something you like!</p>

<h3>Geographic Regions</h3>

<p>The first thing to do when quoting income numbers of any sort is to decide what region to use. Seems straight forward
enough, but in reality <a href="https://twitter.com/vb_jens/status/744407354867736576">hardly ever done</a>. In the Vancouver
context, it simply comes down to deciding if one wants to
report on income for the City of Vancouver or Metro Vancouver. Both are frequently referred to as just &ldquo;Vancouver&rdquo;. Which
is just fine as long as it is clear from the context which region we are talking about. And more importantly, whatever
the income is compared to (e.g. housing price data) are taken for the same region.</p>

<h3>Base Demographics</h3>

<p>Next we have to choose a base demographic we are interested in, choose which income distribution is relevant for our context.
In some cases this choice is obvious. If we are writing a story on lone parents in the City of Vancouver, we would want
to look at the income distribution of lone parent households. If we are looking at the development of wages, we should
consider individual incomes. For a story on consumer spending we may want to look at after-tax income.</p>

<p>We may also be interested in specific type of income, for example only in investment income. Or the net capital gains
and losses. Or pension benefits. Or self-employment income.</p>

<h3>Statistic</h3>

<p>Often we would like to distill everything down to a single number. Typically we would choose the average or median
income from the distribution we are interested in, but we may also choose other statistics, for example the top quintile.
Which one we choose really depends on the story. As a rule of thumb, choose median incomes if you are interested in the
&lsquo;typical&rsquo; person or household. Choose average income if you are interested in the questions relating to the total amount
of money earned in a given area. Income quantiles are great to focus in on certain subgroups of the population.</p>

<h3>Availability</h3>

<p>Generally we also have to consider the availability of information. The census has very detailed income data in their
standard release that allow us to be very specific about what kind of incomes we are interested in. And if that&rsquo;s not
enough we can make a special request to StatsCan to narrow the incomes down to a group we are interested in, for example incomes
of renter households as was done in the <a href="http://rentalhousingindex.ca">rental housing index</a>.</p>

<p>Annual income data is available from CANSIM (Statistics Canada&rsquo;s socioeconomic database), but the geography is coarser
than in the census. Generally we can only
expect to get annual data for the whole country, provinces, census metropolitan areas, but not census
subdivisions (municipalities) or finer geographies.</p>

<h3>Sources and Comparability</h3>

<p>All income data eventually come down to CRA taxfiler data. But the devil is in the details. For the 2006 and 2011
censuses, there was a mixture between self-reporting and cross-referencing of individual level income data with CRA data.
And even self-reported data would again undergo quality control and get somewhat adjusted according to CRA data.</p>

<p>But there are important differences in the data, both on what kind of income is included and also what people are included.</p>

<p>The details are endless, many of them won&rsquo;t matter. Here are a couple to look out for:</p>

<ul>
<li>CANSIM is a comprehensive sample, census data is roughly a 1 in 5 subsample which may lead to sampling bias especially
in small geographies.</li>
<li>CENSUS data is sensitive to non-return bias. Not just no-return bias introduced by the NHS, but also by census undercounts
which, for example, were in the 10% range for the 25 to 29 year old demographic in both the 2006 and 2011 censuses.</li>
<li>CANSIM and the Census have different denominators for reporting average or median incomes. CANSIM reports on all
T1 taxfilers, as well as various family types. Some data can be broken out into age groups at
the 15 and 65 year cutoffs,
whereas Census reports only on people (15 or older) (or families or households) in &ldquo;private households&rdquo; with income greater
than zero.</li>
<li>the definition of &ldquo;private household&rdquo; changed between 2006 and 2011 censuses.</li>
<li>2011 and 2006 censuses differ slightly in what is included as income, for example
<a href="http://www12.statcan.gc.ca/census-recensement/2006/ref/dict/pop123-eng.cfm">2006 included RRSP withdrawls</a>,
<a href="https://www12.statcan.gc.ca/nhs-enm/2011/ref/dict/pop123-eng.cfm">2011 didn&rsquo;t</a> (both include pensions and RRIFs).
2011 includes net capital gains and losses as a percentage of total income in a separate category, 2006 did not
include any information on capital gains.</li>
</ul>


<p>So even when comparing CANSIM income data to census income data for the appropriate year we should expect some differences.
Or comparing 2006 to 2011 income, even if hypothetically an area had identical tax returns, we would still see differences.
Generally speaking, CANSIM average and median income estimates are lower than census estimates as it includes a larger pool
of people that are likely to have lower income.</p>

<h3>Where to get the goods?</h3>

<p><img  src="http://doodles.mountainmath.ca/images/yvr_income.png" style="width:50%;float:right;margin-left:10px;">
The latest census income numbers are available via <a href="https://www12.statcan.gc.ca/nhs-enm/2011/dp-pd/prof/index.cfm">Statistics Canada</a>.
I am biased and prefer the <a href="https://censusmapper.ca/maps/467">CensusMapper</a> interface. For 2011 data, choose any
2011 CensusMapper map, select the geographic
region you are interested in and press the &ldquo;more&rdquo; button on the popup to bring up the &ldquo;census wheel&rdquo;. Then drill into the
&ldquo;income&rdquo; section, the last NHS variable in the widget.</p>

<p>CANSIM has annual data based on taxfiler information for coarser geographies. So you won&rsquo;t be able to get data for the City of Vancouver
or neighbourhoods within the city like with census data, but you can get data for Metro Vancouver. And you can get it for
more recent years. Things get complex very fast there are
<a href="http://www5.statcan.gc.ca/cansim/a33?themeID=3868&amp;spMode=tables&amp;chunkSize=213">213 CANSIM tables with income data</a></p>

<p>At CensusMapper we are still firmly planning integrate CANSIM data into the CensusMapper interface, but their API refresh got pushed back
to sometime 2018 and we can&rsquo;t justify the extra resources to integrate CANSIM data temporarily using the old API just
to switch it over a year later.</p>

<h3>Too Abstract?</h3>

<p>Want to see how this works on an example? Just read the
<a href="http://doodles.mountainmath.ca/blog/2016/09/14/measuring-housing-affordability/">next post on using income data for housing affordability</a>.</p>

<script>
var geoData=['City of Vancouver','Metro Vancouver'];
var med_avData=['median','average'];
var taxData=['pre-tax','after-tax'];
var hhData=['individual','household','family','family with children'];
$('.income-generator .btn').on('click',function(e){
     $('.income-generator').addClass('active');
     $('.income-choices .geo').text(geoData[Math.round(Math.random())]);
     $('.income-choices .med_av').text(med_avData[Math.round(Math.random())]);
     $('.income-choices .tax').text(taxData[Math.round(Math.random())]);
     $('.income-choices .hh').text(hhData[Math.round(3.9999*Math.random()-0.5)]);
     $('.income-choices .income').text('$' + Math.round(80*Math.random()+40)+',000');
});
</script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mobi Running Stats]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2016/08/24/mobi-running-stats/"/>
    <updated>2016-08-24T09:45:54-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2016/08/24/mobi-running-stats</id>
    <content type="html"><![CDATA[<p><a href="http://mountainmath.ca/mobi#14.287582005629245/49.2742/-123.1277" target="_blank"><img  src="http://doodles.mountainmath.ca/images/mobi_main2.png"  style="width:50%;float:right;margin-left:10px;"></a>
I keep getting questions about Mobi stats these days. Rather than ansering them one by one I decided to just offer a live
view into data generated by our shadow API. I made two simple views, the most recent month of daily bike checkout counts
and the most recent week of hourly bike checkout counts. The data issues mentioned in our
<a href="http://doodles.mountainmath.ca/blog/2016/08/16/mobi-a-first-look/">previous post</a> still apply. For data geeks, here is a link to a
<a href="https://twitter.com/serialc/status/767096443165376512">very useful paper</a> that compared estimates like I make to real
usage data.</p>

<!-- more -->


<p>Apart from the usual caveats when dealing with scraped data, Mobi data comes with additional issues like duplicate stations
that need to be filtered out to get proper counts. The view into the database below filters out these and other current
known issues with Mobi data. But as this is a live view, it might not correctly deal with future unforseen issues with
Mobi data. New stations, once Mobi adds them, will automatically show up on our Mobi map and will also be counted in the
live usage graphs.</p>

<h3>Daily Usage</h3>

<p>This graphs shows the daily total counts of bikes checked out (with the usual data quality caveats) for the past month
(starting from August 12, 2016).</p>

<div style="margin:5px  0 20px 0;padding:2px;border: 1px solid black;border-radius:5px;width:100%;">
  <div id="graph_daily" style="height:200px;" data-url="https://mountainmath.ca/bike_providers/1/daily.json"></div>
</div>


<h3>Hourly Usage</h3>

<p>This graphs shows the hourly total counts of bikes checked out (with the usual data quality caveats) for the past week.</p>

<div style="margin:5px  0 20px 0;padding:2px;border: 1px solid black;border-radius:5px;width:100%;">
  <div id="graph_hourly" style="height:200px;" data-url="https://mountainmath.ca/bike_providers/1/hourly.json"></div>
</div>


<h3>Auto Updating</h3>

<p>The above graphs are dynamic, they display the latest available numbers. Feel free do come back to this page to check
how usage develops over time. If you come back in one hour, it will have the latest hourly counts. If you come back
tomorrow, it will have an additional day of data.</p>

<h3>Map Update</h3>

<p>We also thought that adding a little more context to the <a href="http://mountainmath.ca/mobi">bike share map</a> would be useful,
so we added some gentle colouring to highlight parks, retail and institutional land uses.</p>

<p>The bike infrastructure
(and land use) data comes straight from OpenStreetMap. Everyone is
welcome to help update OpenStreetMap data. If you are on a desktop and shift-click into our map it will bring up the
OpenStreetMap editor. There you can add the newest separated bike lane or make other changes (after logging in or signing
up for an account). It will take between 1 to 5 hours for changes to go live on our map, and the changes you make will
also be available to any other app relying on OpenStreetMap data.</p>

<div><script>

function graphBikeStation(selector,station_id){
  var outerHeight=$(selector).height(),
      outerWidth=$($(selector)[0].parentNode).width();
  var margin = {top: 20, right: 20, bottom: 30, left: 50},
      width = outerWidth - margin.left - margin.right,
      height = outerHeight - margin.top - margin.bottom;

  var formatDate = d3.time.format("%X");
  var x = d3.time.scale()
      .range([0, width]);

  var y = d3.scale.linear()
      .range([height, 0]);

  var xAxis = d3.svg.axis().scale(x).orient('bottom');

  var yAxis = d3.svg.axis().scale(y).orient('left').ticks(5);

  var line = d3.svg.line()
      .x(function(d) { return x(d.created_at); })
      .y(function(d) { return y(d.available_bikes); })
      .interpolate('step-after');
  var bikeArea = d3.svg.area()
      .x(function(d, i) { return x(d.created_at); })
      .y0(function(d) { return y(d.available_bikes); })
      .y1(function(d) { return height; })
      .interpolate('step-after');
  var dockArea = d3.svg.area()
      .x(function(d, i) { return x(d.created_at); })
      .y0(function(d) { return 0; })
      .y1(function(d) { return y(d.available_bikes); })
      .interpolate('step-after');


  var svg = d3.select(selector).append("svg")
      .attr("width", width + margin.left + margin.right)
      .attr("height", height + margin.top + margin.bottom)
      .append("g")
      .attr("transform", "translate(" + margin.left + "," + margin.top + ")");
  d3.json('http://mountainmath.ca/bike_providers/1/bike_stations/' + station_id + '.json?days=7',function(error,data){
  data=data[0].stations[0].statuses;
  data.forEach(function(d){type(d)});
  var last=data[data.length-1];
  var lastTime=new Date(d3.time.format.iso.parse(last.updated_at).getTime() + 5*60000);
  data.push({id:last.id,available_bikes:last.available_bikes,free_docks:last.free_docks,created_at:lastTime,updated_at:lastTime});

  x.domain(d3.extent(data, function(d) { return d.created_at; }));
  y.domain([0,data[0].available_bikes+data[0].free_docks]);

  svg.append("g")
      .attr("class", "x axis")
      .attr("transform", "translate(0," + height + ")")
      .call(xAxis);

  svg.append("g")
      .attr("class", "y axis")
      .call(yAxis);
//      .append("text")
//      .attr("transform", "rotate(-90)")
//      .attr("y", 6)
//      .attr("dy", ".71em")
//      .style("text-anchor", "end")
//      .text("Available Bikes");

  svg.append("path")
      .datum(data)
      .attr("class", "area bike")
      .style("fill",'rgba(33, 139, 51, 0.7)')
      .attr("d", bikeArea);
  svg.append("path")
      .datum(data)
      .attr("class", "area dock")
      .style("fill",'rgba(212, 10, 44, 0.7')
      .attr("d", dockArea);


  function type(d) {
    d.created_at = d3.time.format.iso.parse(d.created_at);
    d.available_bikes = +d.available_bikes;
    return d;
  }
  });
}



function bar_graph(div,shiftAxis,domainFormatter,rangeFormatter,domainLabelFormatter,rangeLabelFormatter){
    if (!domainFormatter) domainFormatter=d3.format("d");
    if (!rangeLabelFormatter) rangeLabelFormatter=rangeFormatter;
    if (!rangeFormatter)
     rangeFormatter = function (y) {
        return y;
     };
     if (!domainLabelFormatter) domainLabelFormatter=domainFormatter;

var margin = {top: 20, right: 20, bottom: 40, left: 70},
    width = parseInt(div.style("width")) - margin.left - margin.right,
    height = parseInt(div.style("height")) - margin.top - margin.bottom;

var x = d3.scale.ordinal()
    .rangeRoundBands([0, width], .1);

var y = d3.scale.linear()
    .range([height, 0]);


var xAxis = d3.svg.axis()
    .scale(x)
    .tickFormat(domainFormatter)
    .orient("bottom");


var yAxis = d3.svg.axis()
    .scale(y)
    .orient("left")
    .tickFormat(rangeFormatter)
    .ticks(5, rangeFormatter);

var svg = div.append("svg")
    .attr("width", width + margin.left + margin.right)
    .attr("height", height + margin.top + margin.bottom)
  .append("g")
    .attr("transform", "translate(" + margin.left + "," + margin.top + ")");

var data_url=div[0][0].dataset.url;

d3.json(data_url, function(error, json) {
  if (error) throw error;
  var graphData=json[0];
  var data=graphData.data;
  
  //data.forEach(function(d,i){d.date= d3.time.format.iso.parse(d.date)});
  
  var container=d3.select(div.node().parentNode);
  container.selectAll('.legend.no-margin').remove();
  var legend=container.append('div').attr('class',"legend no-margin");
  legend.append('p').html('<i style="background:'+graphData.color + '"></i>' + graphData.label +  '<span style="float:right;margin-right:10px;" id="' + graphData.class+'_value"></span>');
  
  x.domain(data.map(function(d) {return d.date }));
  y.domain([0, d3.max(data, function(d) { return d.count; })]);
  
  var domainTickValues=[];
  var skip=Math.round(60/x.rangeBand());
  if (skip<=0) skip=1;
  for (var i=0;i<x.domain().length;i++) {
    if (i % skip==0) domainTickValues.push(x.domain()[i]);
  }
  //if (x.domain().length % 5 !=0) domainTickValues.push(x.domain()[x.domain().length-1]);
  xAxis.tickValues(domainTickValues);

  var xShift=shiftAxis ?  -x.rangeBand()/2.0 * 1.1 : 0;
  
  svg.append("g")
      .attr("class", "x axis")
      .attr("transform", "translate(" + xShift + "," + height + ")")
      .call(xAxis);

  svg.append("g")
      .attr("class", "y axis")
      .call(yAxis);
//    .append("text")
//      .attr("transform", "rotate(-90)")
//      .attr("y", 6)
//      .attr("dy", ".71em")
//      .style("text-anchor", "end")
//      .text("Probability");

  svg.selectAll(".bar")
      .data(data)
    .enter().append("rect")
      .attr("class", graphData.class + " bar")
      .style("fill", graphData.color)
      .attr("x", function(d) { return x(d.date); })
      .attr("width", x.rangeBand())
      .attr("y", function(d) { return y(d.count); })
      .attr("height", function(d) { return height - y(d.count); })
      .on('mouseover',function(d){
         d3.select('#'+this.classList[0]+'_value').text(domainLabelFormatter(d.date) + ': ' + rangeLabelFormatter(d.count)) 
      }).on('click',function(d){
       d3.select('#'+this.classList[0]+'_value').text(domainLabelFormatter(d.date) + ': ' + rangeLabelFormatter(d.count)) 
      }).on('touch',function(d){
         d3.select('#'+this.classList[0]+'_value').text(domainLabelFormatter(d.date) + ': ' + rangeLabelFormatter(d.count)) 
      }).on('mouseout',function(){d3.select('#'+this.classList[0]+'_value').text('')});

      
});

}



var numberFormatter=d3.format(",");
var dateFormatter=function(d){return d};//d3.time.format("%a %I%p");//d3.time.format("%a %H:%M"); //d3.format(",");//
bar_graph(d3.select("#graph_daily"),false,dateFormatter,numberFormatter);
bar_graph(d3.select("#graph_hourly"),false,dateFormatter,numberFormatter);

graphBikeStation('#station_graph_os',1);
</script></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mobi -- a First Look]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2016/08/16/mobi-a-first-look/"/>
    <updated>2016-08-16T13:06:58-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2016/08/16/mobi-a-first-look</id>
    <content type="html"><![CDATA[<p><a href="http://mountainmath.ca/mobi#14.287582005629245/49.2742/-123.1277" target="_blank"><img  src="http://doodles.mountainmath.ca/images/mobi_main.png"  style="width:50%;float:right;margin-left:10px;"></a>
Vancouver finally has a bikeshare system. And everyone is hoping it will succeed, despite the obstacles BC&rsquo;s mandatory
helmet law poses for the system. So we are eager to find out how things are going with Mobi.</p>

<p>To set the background, consider that
<a href="http://www.seattlemet.com/articles/2016/3/21/the-rise-and-fall-and-possible-rise-again-of-pronto">Seattle&rsquo;s Pronto is getting less than 1 ride per bike per day</a>
after half a year in operation. In comparison, bike shares that are considered &lsquo;successful&rsquo; in North America get 3 to 5
rides per bike per day. Taipei&rsquo;s system, which I am particularly fond of, gets over 11 rides per bike per day.</p>

<p>So how about Mobi? It barely started, and it&rsquo;s not really fair to run the numbers right now. But we just couldn&rsquo;t hold
our curiosity back.</p>

<!-- more -->


<h3>Data</h3>

<p>First off, some caveats. Mobi does not have an official API for their system. In fact, they only provide a barely usable
<a href="https://www.mobibikes.ca">map of station statuses at the bottom of their landing page</a>. So we decided to
jump in and scrape their data to <a href="http://doodles.mountainmath.ca/blog/2016/07/26/bike-share-map/">make our own map</a>. In
absence of better alternatives, the <em>official</em> Mobi smartphone app is still not released, the map has gotten quite popular.
And in absence of an official Mobi API there are now others, like <a href="http://transitapp.com/">TransitApp</a>, that are consuming our
<a href="http://mountainmath.ca/mobi/stations">station data shadow API</a>.</p>

<p>What that means in terms of data quality is that while we get fairly accurate station bike counts at about a 1-minute
interval, there are some issues with using the data for rigorous analysis. If a bike gets checked in while another one
gets checked out at about the same time there is a good chance that we will miss it. And we can&rsquo;t distinguish rebalancing
from a group of people checking out or dropping off a bunch of bikes at the same time. And we don&rsquo;t have individual bike
data to look at travel patterns, for example what popular trip patterns are. Moreover we currently don&rsquo;t collect and store
weather data, an important variable that should be included in any bike share analysis.</p>

<p>That pretty much rules out anything but high level analysis.</p>

<h3>Station History</h3>

<p>To get an initial idea we started to look at station history. We only started recording Saturday 13th. For the fun of it
we added one day history to our <a href="https://mountainmath.ca/mobi">Mobi bike station and bike infrastructure map</a>. Drop me
a line if you are interested in longer timeframes.</p>

<p>Taking a look at the daily overall usage patterns</p>

<div style="padding:2px;border: 1px solid black;border-radius:5px;">
<div id="graph_mobi_hourly" style="height:200px;max-width:640px;" data-url="/data/mobi_hourly.json"></div>
</div>


<p>things are pretty much as expected. Nice Gaussians for the weekend usage, and some commute spikes for the weekday usage.
Squinting really hard one might want to make out a slight lunchtime boost, we will have to collect more data to confirm
that.</p>

<p>Another thing we see is that usage seems to hit a low point around 4am, so that&rsquo;s a good time to divide up the days when
looking at daily usage. Adding up the rides we get around 1400 rides a day. At around 3am we detect 490 bikes in the
stations, so that makes about 3 rides per bike per day. On average. That a pretty impressive number for a system that is
just getting off the ground. And that&rsquo;s while still in &ldquo;members only&rdquo; mode. The nice weather has helped, but there is no
getting around the fact that Mobi is off to a great start!</p>

<p>Of course not every bike is getting 3 rides. Some get more, some get less. For example, a bike parked at the
<a href="http://mountainmath.ca/mobi#17/49.27147/-123.10407">Ontario &amp; Seawall</a> station has been very popular, here is live data
on the most recent days of usage.
 <div id="station_graph_os" style="height:150px;"></div></p>

<p><a href="http://mountainmath.ca/mobi#19/49.26084/-123.11418" target="_blank"><img  src="http://doodles.mountainmath.ca/images/yukon_12.png"  style="width:50%;float:right;margin-left:10px;"></a>
On the other hand, bikes at <a href="http://mountainmath.ca/mobi#19/49.26084/-123.11418">Yukon &amp; 12th</a> have been having a hard
time to find riders. Both stations are at the
current boundary of the system, it is hard to say what makes the difference. The particular location of the least used
station is sure to get some people talking.</p>

<p>Mobi is undoubtedly carefully
analyzing their station usage and incorporating that into their strategic planning how to expand their network. And
hopefully publish a useful API for all the data geeks out there.</p>

<div><script>

function graphBikeStation(selector,station_id){
  var outerHeight=$(selector).height(),
      outerWidth=$($(selector)[0].parentNode).width();
  var margin = {top: 20, right: 20, bottom: 30, left: 50},
      width = outerWidth - margin.left - margin.right,
      height = outerHeight - margin.top - margin.bottom;

  var formatDate = d3.time.format("%X");
  var x = d3.time.scale()
      .range([0, width]);

  var y = d3.scale.linear()
      .range([height, 0]);

  var xAxis = d3.svg.axis().scale(x).orient('bottom');

  var yAxis = d3.svg.axis().scale(y).orient('left').ticks(5);

  var line = d3.svg.line()
      .x(function(d) { return x(d.created_at); })
      .y(function(d) { return y(d.available_bikes); })
      .interpolate('step-after');
  var bikeArea = d3.svg.area()
      .x(function(d, i) { return x(d.created_at); })
      .y0(function(d) { return y(d.available_bikes); })
      .y1(function(d) { return height; })
      .interpolate('step-after');
  var dockArea = d3.svg.area()
      .x(function(d, i) { return x(d.created_at); })
      .y0(function(d) { return 0; })
      .y1(function(d) { return y(d.available_bikes); })
      .interpolate('step-after');


  var svg = d3.select(selector).append("svg")
      .attr("width", width + margin.left + margin.right)
      .attr("height", height + margin.top + margin.bottom)
      .append("g")
      .attr("transform", "translate(" + margin.left + "," + margin.top + ")");
  d3.json('http://mountainmath.ca/bike_providers/1/bike_stations/' + station_id + '.json?days=7',function(error,data){
  data=data[0].stations[0].statuses;
  data.forEach(function(d){type(d)});
  var last=data[data.length-1];
  var lastTime=new Date(d3.time.format.iso.parse(last.updated_at).getTime() + 5*60000);
  data.push({id:last.id,available_bikes:last.available_bikes,free_docks:last.free_docks,created_at:lastTime,updated_at:lastTime});

  x.domain(d3.extent(data, function(d) { return d.created_at; }));
  y.domain([0,data[0].available_bikes+data[0].free_docks]);

  svg.append("g")
      .attr("class", "x axis")
      .attr("transform", "translate(0," + height + ")")
      .call(xAxis);

  svg.append("g")
      .attr("class", "y axis")
      .call(yAxis);
//      .append("text")
//      .attr("transform", "rotate(-90)")
//      .attr("y", 6)
//      .attr("dy", ".71em")
//      .style("text-anchor", "end")
//      .text("Available Bikes");

  svg.append("path")
      .datum(data)
      .attr("class", "area bike")
      .style("fill",'rgba(33, 139, 51, 0.7)')
      .attr("d", bikeArea);
  svg.append("path")
      .datum(data)
      .attr("class", "area dock")
      .style("fill",'rgba(212, 10, 44, 0.7')
      .attr("d", dockArea);


  function type(d) {
    d.created_at = d3.time.format.iso.parse(d.created_at);
    d.available_bikes = +d.available_bikes;
    return d;
  }
  });
}



function bar_graph(div,shiftAxis,domainFormatter,rangeFormatter,domainLabelFormatter,rangeLabelFormatter){
    if (!domainFormatter) domainFormatter=d3.format("d");
    if (!rangeLabelFormatter) rangeLabelFormatter=rangeFormatter;
    if (!rangeFormatter)
     rangeFormatter = function (y) {
        return y;
     };
     if (!domainLabelFormatter) domainLabelFormatter=domainFormatter;

var margin = {top: 20, right: 20, bottom: 40, left: 70},
    width = parseInt(div.style("width")) - margin.left - margin.right,
    height = parseInt(div.style("height")) - margin.top - margin.bottom;

var x = d3.scale.ordinal()
    .rangeRoundBands([0, width], .1);

var y = d3.scale.linear()
    .range([height, 0]);


var xAxis = d3.svg.axis()
    .scale(x)
    .tickFormat(domainFormatter)
    .orient("bottom");


var yAxis = d3.svg.axis()
    .scale(y)
    .orient("left")
    .tickFormat(rangeFormatter)
    .ticks(5, rangeFormatter);

var svg = div.append("svg")
    .attr("width", width + margin.left + margin.right)
    .attr("height", height + margin.top + margin.bottom)
  .append("g")
    .attr("transform", "translate(" + margin.left + "," + margin.top + ")");

var data_url=div[0][0].dataset.url;

d3.json(data_url, function(error, json) {
  if (error) throw error;
  var graphData=json[0];
  var data=graphData.data;
  
  data.forEach(function(d,i){d.date= d3.time.format.iso.parse(d.date)});
  
  var container=d3.select(div.node().parentNode);
  container.selectAll('.legend.no-margin').remove();
  var legend=container.append('div').attr('class',"legend no-margin");
  legend.append('p').html('<i style="background:'+graphData.color + '"></i>' + graphData.label +  '<span style="float:right;margin-right:10px;" id="' + graphData.class+'_value"></span>');
  
  x.domain(data.map(function(d) {return d.date }));
  y.domain([0, d3.max(data, function(d) { return d.count; })]);
  
  var domainTickValues=[];
  var skip=Math.round(60/x.rangeBand());
  if (skip<=0) skip=1;
  for (var i=0;i<x.domain().length;i++) {
    if (i % skip==0) domainTickValues.push(x.domain()[i]);
  }
  //if (x.domain().length % 5 !=0) domainTickValues.push(x.domain()[x.domain().length-1]);
  xAxis.tickValues(domainTickValues);

  var xShift=shiftAxis ?  -x.rangeBand()/2.0 * 1.1 : 0;
  
  svg.append("g")
      .attr("class", "x axis")
      .attr("transform", "translate(" + xShift + "," + height + ")")
      .call(xAxis);

  svg.append("g")
      .attr("class", "y axis")
      .call(yAxis);
//    .append("text")
//      .attr("transform", "rotate(-90)")
//      .attr("y", 6)
//      .attr("dy", ".71em")
//      .style("text-anchor", "end")
//      .text("Probability");

  svg.selectAll(".bar")
      .data(data)
    .enter().append("rect")
      .attr("class", graphData.class + " bar")
      .style("fill", graphData.color)
      .attr("x", function(d) { return x(d.date); })
      .attr("width", x.rangeBand())
      .attr("y", function(d) { return y(d.count); })
      .attr("height", function(d) { return height - y(d.count); })
      .on('mouseover',function(d){
         d3.select('#'+this.classList[0]+'_value').text(domainLabelFormatter(d.date) + ': ' + rangeLabelFormatter(d.count)) 
      }).on('click',function(d){
       d3.select('#'+this.classList[0]+'_value').text(domainLabelFormatter(d.date) + ': ' + rangeLabelFormatter(d.count)) 
      }).on('touch',function(d){
         d3.select('#'+this.classList[0]+'_value').text(domainLabelFormatter(d.date) + ': ' + rangeLabelFormatter(d.count)) 
      }).on('mouseout',function(){d3.select('#'+this.classList[0]+'_value').text('')});

      
});

}



var numberFormatter=d3.format(",");
var dateFormatter=d3.time.format("%a %I%p");//d3.time.format("%a %H:%M"); //d3.format(",");//
bar_graph(d3.select("#graph_mobi_hourly"),true,dateFormatter,numberFormatter);

graphBikeStation('#station_graph_os',1);
</script></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What's up with RT?]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2016/08/04/rt/"/>
    <updated>2016-08-04T13:18:51-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2016/08/04/rt</id>
    <content type="html"><![CDATA[<p>RT is Vancouver&rsquo;s zoning for duplexes. Over time, various areas have been zoned to allow duplexes. Examples are
Kits Point, much of Point Grey Road reaching up to Broadway, much of Granview-Woodlands, parts of Mount Pleasant and many
other areas.</p>

<p><a href="https://mountainmath.ca/map/assessment?filter=[zone_RT,residential]&zoom=13&lat=49.245&lng=-123.1166&layer=4&mapBase=2" target="_blank"><img  src="http://doodles.mountainmath.ca/images/rt_teardowns.png" style="width:50%;float:right;margin-left:10px;"></a>
Recently I have had some interesting conversations <a href="https://twitter.com/fixbced/status/748196970783637504">on Twitter regarding RM-6</a>
and over BBQ dinner about RT-7. Then the
<a href="http://vancouver.ca/home-property-development/grandview-woodland-community-plan.aspx">Granview-Woodland plan</a>
passed by council, and it contains a curious provision of reducing the outright FSR for the
RT-zoned properties from 0.6 to 0.5.</p>

<p>All of which got me thinking. What is RT supposed to accomplish, how does the diverse RT-zoning rules influence development
and how is RT overall performing?</p>

<!-- more -->


<p>To make things complicated many RT zoning rules contain provisions to allow for higher FSR, and more than two units,
under the &ldquo;heritage preservation&rdquo; program. Most people like the multi-plex developments that come out of this process,
but the road there is quite adurous. Permitting takes a long time and is marred by uncertainty. Those projects are
done by small developers, that are ill-equipped to deal with risky and drawn-out rezoning processes.</p>

<p>These would be great projects carried out by small developers that lead to gentle and affordable density,
as this kind of re-development does not require land-assembly and does not lead
to crazy land-value lifts that require CACs to claw back some of that value rise
<a href="http://doodles.mountainmath.ca/blog/2016/04/01/on-dirt-and-houses/">as we explained before</a>.</p>

<p>We have some ideas what a refreshed RT (and RS) should look like, and there are
<a href="https://pricetags.wordpress.com/2016/07/29/open-letter-on-the-downzoning-of-grandview-woodland-rt/">some efforts to push for changes</a>.
We leave the details of this to the experts and take a little field expedition to
see how the different flavours of RT (and RM) perform in data.</p>

<h3>Why RT?</h3>

<p>One central question to ask is: What is the purpose of RT (or any) zoning? The initial idea was to allow higher density
than RS, with two stratified properties on one lot. But since the creation of RT the RS zoning has undergone significant
changes and allows, in many cases, for higher FSR and higher unit count, although not stratified. In much of RS three
units are allowed on each lot, the main house, a secondary suite and a laneway house.</p>

<p><a href="https://mountainmath.ca/map/assessment?filter=[zone_RT_RS_FSD,residential]&zoom=13&lat=49.245&lng=-123.1166&layer=5&mapBase=2" target="_blank"><img  src="http://doodles.mountainmath.ca/images/rs_rt_land.png" style="width:50%;float:left;margin-right:10px;"></a>
So how does RT perform in the wild? There seems to be little effect RT vs RS zoning has on land values. The
<a href="http://mountainmath.ca/map/assessment?filter=[zone_RT_RS_FSD,residential]&amp;zoom=13&amp;lat=49.245&amp;lng=-123.1166&amp;layer=6&amp;mapBase=2">boundaries between RS and RT</a>
can&rsquo;t be discerned from a
<a href="https://mountainmath.ca/map/assessment?filter=[zone_RT_RS_FSD,residential]&amp;zoom=13&amp;lat=49.245&amp;lng=-123.1166&amp;layer=5&amp;mapBase=2">land value map of all residential properties in RS, RT (and First Shaugnessey) zones</a>.</p>

<p>How good are RT lots at realizing &ldquo;zone capacity&rdquo;, that is how many of the historically SFH get turned over into duplexes,
or in some cases multi-plexes (through the heritage presercation program)?
That depends as the following graph shows.</p>

<div style="margin:10px 50px;padding:5px;border: 1px solid black;border-radius:5px;">
<div id="graph_sfh" style="height:200px;max-width:640px;" data-url="/data/zone_sfh.json"></div>
</div>


<p><a href="https://mountainmath.ca/map/assessment?filter=[zone_RT]&zoom=13&lat=49.2581&lng=-123.1166&layer=20&mapBase=2" target="_blank"><img  src="http://doodles.mountainmath.ca/images/types_rt.png" style="width:50%;float:left;margin-right:10px;"></a>
We can also study this by mapping out
<a href="https://mountainmath.ca/map/assessment?filter=[zone_RT]&amp;zoom=13&amp;lat=49.2581&amp;lng=-123.1166&amp;layer=20&amp;mapBase=2">all residential lots in RT zones</a>,
and color them depending if they are single family lots, duplexes or multi-plexes.</p>

<p>Some RT areas are essentially indistinguishable from RS areas, they are almost entirely comprised of single family lots.
A good example is the
<a href="https://mountainmath.ca/map/assessment?filter=[zone_RT-4,residential]&amp;zoom=14&amp;lat=49.2733&amp;lng=-123.0646&amp;layer=20&amp;mapBase=2">RT-4, most of which is in Grandview-Woodlands</a>.
And being in RT rathern than RS they often don&rsquo;t even get the benefits of a laneway house. Coach houses, which are legal
in many RT areas and could be stratified, come with such onerous side setbacks that they are very hard to build on
regular lots.</p>

<p>There is a lot of untapped &ldquo;zoned capacity&rdquo;. Similarly, some of the
newer RM zones show little appetite for realizing &ldquo;zoned capacity&rdquo;, possibly due to the added difficulty of having to
assemble lots to do so.</p>

<p>One can argue about whether this is good or bad. Or one can look at the variation between the different types of RT and RM
zones to see what causes the difference.</p>

<h3>Downzoning</h3>

<p>To understand how downzoning works we want to consider two different types on analysis. One is to look at what happened
after RS zone was changed to reduce site coverage in the 1980 in response to concerns about &lsquo;monster homes&rsquo;. We ran
an analysis using LIDAR data to understand the effect on the physical form of SFH and found that while site coverage
indeed decreased sharply, the <a href="http://doodles.mountainmath.ca/blog/2016/03/05/physical-sfh-form-over-time/">bulk of the building remained unchanged</a>.
and the rule change seems to have done little in easing concerns about &lsquo;monster homes&rsquo;, it simply changed some of the
parameters determining what &lsquo;monster homes&rsquo; look like.</p>

<p>Another way to look at the matter is to compare how re-development happened in difference zones. This is very hard, since
there are many factors other than zoning that determine if a building gets re-developed. To get some idea we compiled two
numbers for each of the RS, RT and RM zones (ignoring some of the delicacies in the zoning code and lumping together all
sub-zones with the same leading number. So for example we lumped RT-4, RT-4A, RT-4N and RT-4AN into one category we simply
label &ldquo;RT-4&rdquo;.</p>

<p>First we check how many residential properties got re-developed since 2000.</p>

<div style="margin:10px 50px;padding:5px;border: 1px solid black;border-radius:5px;">
<div id="graph_redevelopment" style="height:200px;max-width:640px;" data-url="/data/zone_redevelopment.json"></div>
</div>


<p>Next we take a look what percentage of the existing residential stock is in immediate danger of being torn down, using the
<a href="http://doodles.mountainmath.ca/blog/2016/01/18/redevelopment/">methodology developed earlier</a>.</p>

<div style="margin:10px 50px;padding:5px;border: 1px solid black;border-radius:5px;">
<div id="graph_teardown" style="height:200px;max-width:640px;" data-url="/data/zone_teardowns.json"></div>
</div>


<p>While there is some correspondence between re-development activity and ratio of teardowns, there are a number of notable
exceptions. RT-1 and RM-9 stand out, but these are
<a href="https://mountainmath.ca/map/assessment?filter=[zoneE_RM-9_RT-1]&amp;zoom=14&amp;lat=49.2146&amp;lng=-123.1282&amp;layer=5&amp;mapBase=2">oddball cases with just a few properties</a>.</p>

<p><a href="https://mountainmath.ca/map/assessment?filter=[zone_RT,years_2000]&zoom=13&lat=49.2581&lng=-123.1166&layer=20&mapBase=2" target="_blank"><img  src="http://doodles.mountainmath.ca/images/new_types_rt.png" style="width:50%;float:right;margin-left:10px;"></a>
We can also map just <a href="https://mountainmath.ca/map/assessment?filter=[zone_RT,years_2000]&amp;zoom=13&amp;lat=49.2581&amp;lng=-123.1166&amp;layer=20&amp;mapBase=2">residential properties in RT that were re-developed since 2000</a>
and colour them by SFH, Duplex and Multi-plex status. We can clearly see how some RT areas, like RT-7, don&rsquo;t see much
re-development, others, like RT-6 see mostly multi-plexes being developed. Some zones, like RT-10, 11, 12 are too new
to be judged on development happening since 2000. For example, zooming in on
<a href="http://mountainmath.ca/map/assessment?filter=[zone_RT-10,residential,years_2009]&amp;zoom=15&amp;lat=49.2485&amp;lng=-123.0734&amp;layer=20&amp;mapBase=2">developments in RT-10 since 2009 paints a very different picture</a>.</p>

<p>There is lots of stuff to explore, but for today I want to look at RT-7 and RT-6 in more detail.</p>

<h4>RT-7</h4>

<p><a href="https://mountainmath.ca/map/assessment?filter=[zone_RT-7,residential]&zoom=15&lat=49.2617&lng=-123.1654&layer=20&mapBase=2" target="_blank"><img  src="http://doodles.mountainmath.ca/images/rt-7.png" style="width:50%;float:left;margin-right:10px;"></a>
A much more interesting case is RT-7, with 35% of properties teardowns but only 4.1% of properties re-developed since 2000.
<a href="https://mountainmath.ca/map/assessment?filter=[zone_RT-7,residential]&amp;zoom=15&amp;lat=49.2617&amp;lng=-123.1654&amp;layer=4&amp;mapBase=2">Looking at the map</a>
we see that RT-7 is comprised of two pockets on the west side, and the teardown candidates stand out in red and orange.
Filtering further to see what
<a href="https://mountainmath.ca/map/assessment?filter=[zone_RT-7,residential,years_2000]&amp;zoom=15&amp;lat=49.2617&amp;lng=-123.1654&amp;layer=20&amp;mapBase=2">has been re-developed since 2000</a>
we see that, considering the size of the two pockets, re-development favours the eastern pocket near 16th and Arbutus. We
can clearly see that that the eastern pocket has an overall more valuable building stock, although it is not clear if that
is due to higher rates of re-development or for other reasons, for example the presence of some slightly larger lots. We
also note that re-development does produce duplex units and even some multi-plex.</p>

<p>So what is going on here? Looking at the <a href="http://former.vancouver.ca/commsvcs/BYLAWS/zoning/rt-7.pdf">RT-7 zoning</a> we
see that the area has been downzoned to 0.4 FSR as was rencently pointed out to me, which can conditionally be upzoned
to 0.6 FSR. Additionally, there are caps on the number of units per hectar to further restrict density.</p>

<h4>RT-6</h4>

<p><a href="https://mountainmath.ca/map/assessment?filter=[zone_RT-6,residential]&zoom=16&lat=49.2606&lng=-123.1097&layer=20&mapBase=2" target="_blank"><img  src="http://doodles.mountainmath.ca/images/rt-6.png" style="width:50%;float:right;margin-left:10px;"></a>
Another interesting example is RT-6. RT-6 has seen modest levels of re-develpment and has a <a href="https://mountainmath.ca/map/assessment?filter=[zone_RT-6,residential]&amp;zoom=16&amp;lat=49.2606&amp;lng=-123.1097&amp;layer=4&amp;mapBase=2">relatively healthy building
stock</a>.
What&rsquo;s even more interesting is that it contains
<a href="https://mountainmath.ca/map/assessment?filter=[zone_RT-6,residential]&amp;zoom=16&amp;lat=49.2597&amp;lng=-123.1101&amp;layer=20&amp;mapBase=2">many multi-plexes</a>.
And more importantly, <a href="https://mountainmath.ca/map/assessment?filter=[zone_RT-6,residential,years_2000]&amp;zoom=16&amp;lat=49.2597&amp;lng=-123.1101&amp;layer=20&amp;mapBase=2">developments since 2000 have mostly produced multi-plexes</a>.</p>

<p>Prime examples of the <em>gentle density</em> that we keep hearing about. I would say that something is working very well here.</p>

<p>So what&rsquo;s the difference? In contrast to RT-7 <a href="http://former.vancouver.ca/commsvcs/BYLAWS/zoning/rt-6.pdf">RT-6 zoning</a> allows for 0.6 FSR
outright, conditionally increased to 0.75. But there are other important differences too. The RT-7 lots are typically
smaller with many at about 340m&sup2; compared to the 580m&sup2; typical RT-6 lots.
(Although RT-7 also contains some 580m&sup2; lots).</p>

<h3>Conclusion</h3>

<p>Does downzoning work? It depends what the goal is. Looking at the RT-7 example, downzoning has slowed re-development compared
to other areas in the city, but it also lead to a deterioration in building stock in RT-7. This is a stop-gap measure,
eventually that lower value building stock will get re-developed.</p>

<p>The combination of larger lots and the heritage retention program in the RT-6 zoning seems to work in producing
gentle density, except that the permitting process takes too long and it is not immediately clear what purpose the
heritage preservation has that allows stripping the building down to the studs and possibly moving it to the front and
then building an infill in the back. There must be a better way to deal with concerns behind
heritage preservation (not much is &ldquo;preserved&rdquo; in this process) and at the same time cut down on the time it
takes to jump through all the permit hoops involved.</p>

<p>It is clear that RS and RT (and RM) zoning would hugely profit from a clearer vision what these zonings should accomplish
and by using data to benchmark how these targets are met.</p>

<div><script>

function bar_graph(div,shiftAxis,domainFormatter,rangeFormatter,domainLabelFormatter,rangeLabelFormatter){
    if (!domainFormatter) domainFormatter=d3.format("d");
    if (!rangeLabelFormatter) rangeLabelFormatter=rangeFormatter;
    if (!rangeFormatter)
     rangeFormatter = function (y) {
        return y;
     };
     if (!domainLabelFormatter) domainLabelFormatter=domainFormatter;

var margin = {top: 20, right: 20, bottom: 40, left: 70},
    width = parseInt(div.style("width")) - margin.left - margin.right,
    height = parseInt(div.style("height")) - margin.top - margin.bottom;

var x = d3.scale.ordinal()
    .rangeRoundBands([0, width], .1);

var y = d3.scale.linear()
    .range([height, 0]);


var xAxis = d3.svg.axis()
    .scale(x)
    .tickFormat(domainFormatter)
    .orient("bottom");


var yAxis = d3.svg.axis()
    .scale(y)
    .orient("left")
    .tickFormat(rangeFormatter)
    .ticks(5, rangeFormatter);

var svg = div.append("svg")
    .attr("width", width + margin.left + margin.right)
    .attr("height", height + margin.top + margin.bottom)
  .append("g")
    .attr("transform", "translate(" + margin.left + "," + margin.top + ")");

var data_url=div[0][0].dataset.url;

d3.json(data_url, function(error, json) {
  if (error) throw error;
  var graphData=json[0];
  var data=graphData.data;
  
  var container=d3.select(div.node().parentNode);
  container.selectAll('.legend.no-margin').remove();
  var legend=container.append('div').attr('class',"legend no-margin");
  legend.append('p').html('<i style="background:'+graphData.color + '"></i>' + graphData.label +  '<span style="float:right;margin-right:10px;" id="' + graphData.class+'_value"></span>');
  
  x.domain(data.map(function(d) { return d.date }));
  y.domain([0, d3.max(data, function(d) { return d.count; })]);
  
  var domainTickValues=[];
  var skip=Math.round(40/x.rangeBand());
  if (skip<=0) skip=1;
  for (var i=0;i<x.domain().length;i++) {
    if (i % skip==0) domainTickValues.push(x.domain()[i]);
  }
  if (x.domain().length % 5 !=0) domainTickValues.push(x.domain()[x.domain().length-1]);
  xAxis.tickValues(domainTickValues);

  var xShift=shiftAxis ?  x.rangeBand()/2.0 * 1.1 : 0;
  
  svg.append("g")
      .attr("class", "x axis")
      .attr("transform", "translate(" + xShift + "," + height + ")")
      .call(xAxis);

  svg.append("g")
      .attr("class", "y axis")
      .call(yAxis);
//    .append("text")
//      .attr("transform", "rotate(-90)")
//      .attr("y", 6)
//      .attr("dy", ".71em")
//      .style("text-anchor", "end")
//      .text("Probability");

  svg.selectAll(".bar")
      .data(data)
    .enter().append("rect")
      .attr("class", graphData.class + " bar")
      .style("fill", graphData.color)
      .attr("x", function(d) { return x(d.date); })
      .attr("width", x.rangeBand())
      .attr("y", function(d) { return y(d.count); })
      .attr("height", function(d) { return height - y(d.count); })
      .on('mouseover',function(d){
         d3.select('#'+this.classList[0]+'_value').text(domainLabelFormatter(d.date) + ': ' + rangeLabelFormatter(d.count)) 
      }).on('click',function(d){
       d3.select('#'+this.classList[0]+'_value').text(domainLabelFormatter(d.date) + ': ' + rangeLabelFormatter(d.count)) 
      }).on('touch',function(d){
         d3.select('#'+this.classList[0]+'_value').text(domainLabelFormatter(d.date) + ': ' + rangeLabelFormatter(d.count)) 
      }).on('mouseout',function(){d3.select('#'+this.classList[0]+'_value').text('')});

      
});

}



var percentageFormatter=d3.format(".1%");
var textFormatter=function(d){return d};
var teardownLabelFormatter=function(d){return percentageFormatter(d) + " teardowns"};
var sfhLabelFormatter=function(d){return percentageFormatter(d) + " SFH"};
var redeveopmentLabelFormatter=function(d){return percentageFormatter(d) + " built since 2000"};
bar_graph(d3.select("#graph_redevelopment"),false,textFormatter,percentageFormatter,textFormatter,redeveopmentLabelFormatter);
bar_graph(d3.select("#graph_teardown"),false,textFormatter,percentageFormatter,textFormatter,teardownLabelFormatter);
bar_graph(d3.select("#graph_sfh"),false,textFormatter,percentageFormatter,textFormatter,sfhLabelFormatter);
</script></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bike Share Map]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2016/07/26/bike-share-map/"/>
    <updated>2016-07-26T15:12:06-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2016/07/26/bike-share-map</id>
    <content type="html"><![CDATA[<p><a href="https://mountainmath.ca/mobi" target="_blank"><img  src="http://doodles.mountainmath.ca/images/bike-share-image-large.png"  style="width:50%;float:right;margin-left:10px;"></a>
It is no secret that we at MountainMath like bikes. And maps. And open data and sharing. We guess you know where
this is going.</p>

<p>Vancouver has finally gotten a bike share system, and we are loving it. So we took the occasion to take our
<a href="http://doodles.mountainmath.ca/blog/2016/05/16/my-global-bike-map/">old bike infrastructure maps</a>, polished them up a
bit using <a href="https://mapzen.com/blog/targeted-editing-cycleways/">Mapzen&rsquo;s bike map style</a> and adapted it for our purposes.</p>

<p>The result is our <a href="https://mountainmath.ca/mobi" class="btn btn-primary">Vancouver Bike Share Map</a>. (Fair
warning. While this map works great on your iOS and Android phone, it may not work on old desktop computers.)</p>

<p>Add it to your phone home screen, and it will be right at your fingertips when you need it!</p>

<!-- more -->


<p>And we threw the <a href="https://www.mobibikes.ca/">Mobi Bike Share</a> station data on top. That last part turned out a little
more messy than expected, the API that was <a href="https://bikeshare-research.org/#bssid:vancouver">linked at the Bike Share Research website</a>
is broken, and the Mobi redirects are malformed and no guesswork would yield a working API. Luckily
the <a href="https://twitter.com/oobr">bike share map wizard</a> on
Twitter <a href="https://twitter.com/oobr/status/756211668141547520">had the answer</a> how to tease out the station data. And some
of the stations are duplicate, so it took some time to clean up the data properly.</p>

<p>We tried to keep our map as simple as possible. This iteration highlights three types of infrastructure, separated, bike lanes and
shared lanes. The map has some hill-shading for reference, and at high zoom level it shows some bike points-of-interest.
The rest is kept clean and simple.</p>

<p>For the stations, we weren&rsquo;t fans of the icons and presentation used on many other maps. We decided on a simple
donut-style presentation to visualize available bikes to check out and empty slots to return them. This is the most crucial
information for a bike share user. Where can I check out a bike, and where can I return one. There is nothing more frustrating
than having to go to a meeting and being unable to check the bike back into a station because it is full. The map gives
a quick visual guide for this, although the Mobi data lags quite a bit right now. Hopefully that will change in the future
once they get their API up and running.</p>

<p>On touch/hover the bike stations expand to give exact counts and the station name. Station sizes vary and counts can be
useful at times. We opted to keep the icon size independent of station size, trading added information for a cleaner
presentation by only revealing it on user interaction.</p>

<p>This map focuses on the bike share user. If you are more interested in stats and overview of various bike share systems
you want to head over to <a href="http://bikes.oobrien.com">Oliver O&#8217;Brien&rsquo;s excellent bike share map</a>.</p>

<h3>Bike Infrastructure</h3>

<p>The bike data we are using comes straight out of <a href="http://www.openstreetmap.org/search?query=vancouver%2C%20bc#map=12/49.2497/-123.1193">OpenStreetMap</a>.
That has some disadvantages as it can be less accurate
as the city bike data. But it also has a huge advantage. Anyone can edit OpenStreetMap to fix incorrect or missing
infrastructure designations. We kept some of the targeted editing capabilities intact on our map, if you view it on desktop
and <em>shift-click</em> anywhere, it will take you right into the OpenStreetMap editor at the position you clicked so you can
edit the infrastructure there.</p>

<p>If you are planning on helping out and improve OpenStreetMap bike data, you may want to read the
<a href="https://mapzen.com/blog/targeted-editing-cycleways/">excellent targeted editing post from Mapzen</a> and use their
<a href="https://mapzen-data.github.io/te-bike-lrm-mapzen/#point0lat=49.2820&amp;point0lng=-123.1204&amp;point1lat=49.2708&amp;point1lng=-123.1341&amp;mode=bicycle">map to brouse OSM tags</a>.
You may notice the similarity to our map, we borrowed heavily from that one. Updates you make will take between 1 to 4
hours before they percolate through into our map.</p>

<p>Data in OpenStreetMap is automatically accessible to other services too, so improving OSM will help out everyone. And not
just by making the maps better, routing gets better too!</p>

<p>And the other big advantage of OpenStreetMap is that our map is automatically global. Right now we still focus on
Vancouver, and we restrict the search function to Vancouver addresses. But in principle the infrastructure part of the
map works for anywhere on the planet.</p>

<h3>Next Steps</h3>

<p>Adding bike routing is an obvious next step. And there are lots of other refinements we can think of.</p>

<p>Hill shading has some issues right now, only some
hill aspects are visible right now. We may have to add some colour to hill shading to visualize all hill aspects better,
but that requires care to ensure the map retains it&rsquo;s clean looks.</p>

<p>The next step in the map evolution is to make a multi-modal map, toghet with multi-modal routing. The map will highlight
infrastructure based on what modes are preferred, and routing will do routing for these modes.</p>

<p>Using the great work of the <a href="https://bikeshare-research.org">Bike Share Research website</a> we can also parse the feeds
for all global bike share systems registered there and expand the bike share map to other systems around the world.</p>

<h3>Feedback</h3>

<p>Got ideas how to make the map better? Want some pointers how to adapt this map for your own purposes? Send us a tweet
or a message!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mixing Data]]></title>
    <link href="http://doodles.mountainmath.ca/blog/2016/07/06/mixing-data/"/>
    <updated>2016-07-06T09:19:04-07:00</updated>
    <id>http://doodles.mountainmath.ca/blog/2016/07/06/mixing-data</id>
    <content type="html"><![CDATA[<p>Census data is very rich and with <a href="https://censusmapper.ca">CensusMapper</a> we now have about 1 billion data points right at
our fingertips. And we have managed to open up some of our interfaces for everyone to <a href="http://doodles.mountainmath.ca/blog/2016/05/04/census-mapping-for-everyone/">explore data and make their own maps
and freely share them</a>.</p>

<p>Things really get interesting when one mixes custom data with census data. While, at this point, these are not part of
the freely available CensusMapper functionality we still wanted to share what can be done.</p>

<p>At CensusMapper we have developed three basic ways to rapidly mix custom data with census data. So this is really three
blog posts in one.</p>

<!-- more -->


<h3>1. Overlay Mapping</h3>

<p>First up, advanced users can upload custom datasets and map them on top of census data.
<a href="http://doodles.mountainmath.ca/images/restaurants_2.png"><img  src="http://doodles.mountainmath.ca/images/restaurants_2.png" style="width:50%;float:right;margin-left:10px;"></a>
For example, we took a
<a href="http://data.vancouver.ca/datacatalogue/businessLicence.htm">business license dataset</a> from the City of Vancouver open
data catalogue, filtered it by the <em>BusinessType</em> field to only include businesses starting with &ldquo;Restaurant&rdquo; or
&ldquo;Liquor Establishment&rdquo; and uploaded them to CensusMapper to map it on top of census data. We have used a map
for <em>median age</em> that was <a href="https://twitter.com/jofu_/status/750564269796823041">recently created using CensusMapper&rsquo;s free public interface</a>
(have you made <a href="https://censusmapper.ca/maps/new">your own CensusMapper map</a> yet?), we have faded out areas outside of
Vancouver and coloured <em>Liquor Establishments</em> in red and <em>Restaurants</em> in blue.</p>

<p>Giving a visual impression of your own dataset in relation to census data is the first step to location analysis.</p>

<h3>2. Populate Custom Data with Census Data</h3>

<p>Next
up is to populate your own dataset with census data for further analysis. For the restaurants, we may be interested in
attaching population estimates in 5 minute walking distance from each location. We might also be interested in specific
age brackets, or numbers of recent immigrants
from specific countries that we may want to target with a new restaurant, or maybe even     income data.</p>

<p>This can be a time consuming and painful process,
but we have automated this at CensusMapper.</p>

<p>To showcase how this works we will show an example using elementary school catchment areas in the City of Vancouver. The
areas we have (from the <a href="http://data.vancouver.ca/datacatalogue/publicPlaces.htm">Vancouver Open Data Catalogue</a>) are
quite out of date, but for the purpose of this example they work as we will compare them to 2011 census data. We will look at the
<a href="https://censusmapper.ca/maps/419">school aged population</a> in each catchment.</p>

<!--
The general census release data does not fit our task perfectly, the census splits by age in early May 2011 and not by
year born and it does not have fine enough age brackets to estimating accurate school catchment numbers.
[BC Stats](http://www.bcstats.gov.bc.ca/StatisticsBySubject/Demography/PopulationEstimates.aspx) has finer age brackets
computed to school district (not catchment) boundaries, but their estimates are ridiculously far off of census numbers
when using matching age brackets and years that their usefulness is highly questionable. 
-->


<p><a href="http://doodles.mountainmath.ca/images/e-schools.png"><img  src="http://doodles.mountainmath.ca/images/e-schools.png" style="width:50%;float:left;margin-right:10px;"></a>
Using the visual overlay we notice that the catchment areas do fit boundaries of Dissemination Areas shown on the map
reasonably well, with some exceptions. The same cannot be said for Census Tracts, we can be reasonably confident that
Dissemination Area data is fairly accurate.</p>

<p>Next we use the built-in CensusMapper functionality to automatically populate the catchment areas with the census
data we are interested
in. When Dissemination Areas don&rsquo;t line up with the catchment boundaries we go down to Dissemination Blocks to estimate
how many children live on what side of the catchment boundary. We
<a href="http://doodles.mountainmath.ca/blog/2016/04/06/tod/">previously explained this process in more detail</a>, the result is
a spreadsheet with the population data by age for each catchment area.</p>

<div id='schools'></div>


<div><script src="http://doodles.mountainmath.ca/javascripts/colorbrewer.js" charset="utf-8"></script></div>


<div><script src="http://doodles.mountainmath.ca/javascripts/school_bar_graph.js" charset="utf-8"></script></div>


<p>Here we show the results by school, the select element can be used to select any school of interest. The whole process
of populating the school data with census data just required uploading the catchment boundaries and selecting which
variables to attach.</p>

<h3>3. Custom Census Data Mapping</h3>

<p>Sometimes it is not practical to map custom data on CensusMapper. Maybe the custom data is too sensitive to be uploaded
to CensusMapper servers. Or it is quite complex and is better mapped separately. So we created an API to pull in
census data from CensusMapper to easily show census data on custom maps. And dynamically mix in your own data. As an
example we mix census data with data from BCAssessment, again obtained through the
<a href="http://vancouver.ca/your-government/open-data-catalogue.aspx">Vancouver Open Data Catalogue</a> (and enriched with
<a href="http://www.metrovancouver.org/data">open data from Metro Vancouver</a>).
For demonstration purposes take Dissemination Area
geographies and Dwelling Characteristic data from CensusMapper and mash it up with our
<a href="http://mountainmath.ca/map/assessment?zoom=14&amp;lat=49.2604&amp;lng=-123.1417&amp;layer=14&amp;mapBase=2">processed assessment data</a>
to explore the <a href="http://doodles.mountainmath.ca/blog/2016/06/17/sdh-zoning-and-land-use/">differences in how single family properties are classified</a>.</p>

<p><a href="https://mountainmath.ca/census_mix/map?mapBase=2&layer=0" target="_blank"><img  src="http://doodles.mountainmath.ca/images/sfh_unit_count.png" style="width:50%;float:right;margin-left:10px;"></a>
For example we can <a href="https://mountainmath.ca/census_mix/map?mapBase=2&amp;layer=0">compare BC Assessment single family lot count to Stats Canada unit count</a>
in the dissemination areas
that are exclusively made up of single family lots. This gives an indication of how many suites and laneway houses there
are in those areas. The census is prone to undercount units, but still does a better job at estimating them than other data sources,
like the city or BC Assessment.</p>

<p>One of the reasons why census unit counts come up higher than other methods is that the census also counts illegal units,
which naturally are not part of other official government counts. There are different reasons why a suite may be illegal:
<a href="https://mountainmath.ca/census_mix/map?mapBase=2&layer=5" target="_blank"><img  src="http://doodles.mountainmath.ca/images/illegal_units.png" style="width:50%;float:left;margin-right:10px;"></a>
It could simply be that the owner has not made the effort to register it. Or the suite may not be up to code.
And in some cases, a property may have more than one suite in the main building, which is illegal in the City of Vancouver.
The latter ones we can pick out in census data, since a house with two secondary suites &ndash; so three dwelling units in one building in
total &ndash; is classified as being an &ldquo;Apartment, building that has fewer than five storeys&rdquo;. So, in census dissemination areas that
only have duplex or single family lots as residential land uses based on assessment and land use data, we can look for
how many dwelling units the census places in an &ldquo;Apartment, building that has fewer than five storeys&rdquo;. And
<a href="https://mountainmath.ca/census_mix/map?mapBase=2&amp;layer=5">map them</a>.</p>
]]></content>
  </entry>
  
</feed>
